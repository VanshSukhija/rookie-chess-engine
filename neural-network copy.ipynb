{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa9c307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I760138/Vansh/personal/chess-bot/java-chess-engine/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_types = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "}\n",
    "\n",
    "scale = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fen(fen):\n",
    "    planes = np.zeros((12, 8, 8), dtype=np.float32)\n",
    "    parts = fen.split()\n",
    "    board_rows = parts[0].split('/')\n",
    "    for r, row in enumerate(board_rows):\n",
    "        f = 0\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                f += int(char)\n",
    "            elif char in piece_types:\n",
    "                idx = piece_types[char]\n",
    "                planes[idx, r, f] = 1\n",
    "                f += 1\n",
    "    flat = planes.flatten()\n",
    "\n",
    "    # Side to move\n",
    "    stm = 1.0 if parts[1] == 'w' else 0.0\n",
    "\n",
    "    # Castling rights\n",
    "    castling = [1.0 if x in parts[2] else 0.0 for x in 'KQkq']\n",
    "\n",
    "    # En passant\n",
    "    ep = [0.0] * 8\n",
    "    if parts[3] != '-':\n",
    "        file = ord(parts[3][0]) - ord('a')\n",
    "        ep[file] = 1.0\n",
    "\n",
    "    return np.concatenate([flat, [stm], castling, ep])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x / scale))\n",
    "\n",
    "def inverse_sigmoid(y):\n",
    "    y = np.clip(y, 1e-7, 1 - 1e-7)  # Avoid division by zero\n",
    "    return -scale * np.log((1 / y) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74bce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./db/train_aa...\n",
      "Loaded 828968 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2205237.5000 - mae: 329.7458 - val_loss: 1818333.6250 - val_mae: 371.1371\n",
      "Epoch 2/10\n",
      "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1676420.5000 - mae: 339.9630 - val_loss: 1719112.0000 - val_mae: 343.9999\n",
      "Epoch 3/10\n",
      "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1582131.8750 - mae: 320.1330 - val_loss: 1701763.2500 - val_mae: 338.5207\n",
      "Epoch 4/10\n",
      "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1556969.2500 - mae: 313.8789 - val_loss: 1695735.6250 - val_mae: 335.4497\n",
      "Epoch 5/10\n",
      "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1549267.1250 - mae: 312.1643 - val_loss: 1693860.5000 - val_mae: 335.4548\n",
      "Epoch 6/10\n",
      "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1496831.3750 - mae: 307.2703 - val_loss: 1690985.5000 - val_mae: 333.1010\n",
      "Epoch 7/10\n",
      "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1520779.0000 - mae: 308.7988 - val_loss: 1687164.8750 - val_mae: 331.7563\n",
      "Epoch 8/10\n",
      "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1437839.8750 - mae: 302.4566 - val_loss: 1686639.1250 - val_mae: 330.6684\n",
      "Epoch 9/10\n",
      "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1419036.0000 - mae: 300.9637 - val_loss: 1687460.7500 - val_mae: 332.1004\n",
      "Epoch 10/10\n",
      "\u001b[1m648/648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1427551.1250 - mae: 299.9112 - val_loss: 1682097.8750 - val_mae: 329.1455\n",
      "Processing ./db/train_ab...\n",
      "Loaded 855730 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1262983.5000 - mae: 286.5764 - val_loss: 1718711.3750 - val_mae: 391.8853\n",
      "Epoch 2/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1219704.1250 - mae: 280.2350 - val_loss: 1716756.5000 - val_mae: 396.8416\n",
      "Epoch 3/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1182888.5000 - mae: 277.6334 - val_loss: 1711268.0000 - val_mae: 399.4804\n",
      "Epoch 4/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1129605.2500 - mae: 274.5161 - val_loss: 1698848.1250 - val_mae: 399.0073\n",
      "Epoch 5/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1127361.8750 - mae: 273.2963 - val_loss: 1712404.0000 - val_mae: 405.2570\n",
      "Epoch 6/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1099791.6250 - mae: 272.3582 - val_loss: 1707919.7500 - val_mae: 408.8015\n",
      "Epoch 7/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1094618.6250 - mae: 271.7451 - val_loss: 1715997.1250 - val_mae: 412.1843\n",
      "Epoch 8/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1067672.8750 - mae: 270.9901 - val_loss: 1719241.6250 - val_mae: 416.3167\n",
      "Epoch 9/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1063871.1250 - mae: 270.3744 - val_loss: 1720081.0000 - val_mae: 419.7867\n",
      "Epoch 10/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1053397.2500 - mae: 271.2050 - val_loss: 1733875.3750 - val_mae: 423.2213\n",
      "Processing ./db/train_ac...\n",
      "Loaded 856545 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1273928.6250 - mae: 302.4698 - val_loss: 1562799.3750 - val_mae: 394.5993\n",
      "Epoch 2/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1159577.3750 - mae: 291.0447 - val_loss: 1567751.3750 - val_mae: 397.9274\n",
      "Epoch 3/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1122565.0000 - mae: 286.5715 - val_loss: 1577329.8750 - val_mae: 408.8835\n",
      "Epoch 4/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1121941.1250 - mae: 286.8712 - val_loss: 1571420.5000 - val_mae: 403.1685\n",
      "Epoch 5/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1079346.0000 - mae: 282.0213 - val_loss: 1583207.1250 - val_mae: 411.5996\n",
      "Epoch 6/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1075578.6250 - mae: 283.2018 - val_loss: 1589206.0000 - val_mae: 411.3857\n",
      "Epoch 7/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1058090.2500 - mae: 281.3730 - val_loss: 1593708.6250 - val_mae: 415.4781\n",
      "Epoch 8/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1049008.0000 - mae: 281.6849 - val_loss: 1602864.1250 - val_mae: 423.3425\n",
      "Epoch 9/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1001995.0000 - mae: 278.0630 - val_loss: 1622127.7500 - val_mae: 433.7705\n",
      "Epoch 10/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 993205.4375 - mae: 278.4275 - val_loss: 1621044.2500 - val_mae: 433.0815\n",
      "Processing ./db/train_ad...\n",
      "Loaded 853551 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1299757.5000 - mae: 309.7024 - val_loss: 1181271.6250 - val_mae: 289.9516\n",
      "Epoch 2/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1254237.3750 - mae: 301.6229 - val_loss: 1185021.1250 - val_mae: 291.7058\n",
      "Epoch 3/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1173577.5000 - mae: 295.0667 - val_loss: 1189992.5000 - val_mae: 290.2624\n",
      "Epoch 4/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1153035.5000 - mae: 292.1440 - val_loss: 1191095.6250 - val_mae: 293.7336\n",
      "Epoch 5/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1152921.5000 - mae: 292.9473 - val_loss: 1195361.2500 - val_mae: 294.8698\n",
      "Epoch 6/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1103554.2500 - mae: 289.6069 - val_loss: 1203176.6250 - val_mae: 300.4832\n",
      "Epoch 7/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1055155.6250 - mae: 288.3291 - val_loss: 1212934.5000 - val_mae: 299.4492\n",
      "Epoch 8/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1016876.1875 - mae: 284.5430 - val_loss: 1218881.8750 - val_mae: 302.4993\n",
      "Epoch 9/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 989821.9375 - mae: 284.0053 - val_loss: 1232620.7500 - val_mae: 306.3835\n",
      "Epoch 10/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 945759.0000 - mae: 281.8656 - val_loss: 1239291.3750 - val_mae: 307.6017\n",
      "Processing ./db/train_ae...\n",
      "Loaded 865711 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1021905.4375 - mae: 298.6249 - val_loss: 1219250.1250 - val_mae: 314.4951\n",
      "Epoch 2/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 929489.6250 - mae: 278.0474 - val_loss: 1229825.2500 - val_mae: 315.3961\n",
      "Epoch 3/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 846838.5625 - mae: 269.5949 - val_loss: 1236183.5000 - val_mae: 317.6505\n",
      "Epoch 4/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 847291.2500 - mae: 270.0342 - val_loss: 1240068.5000 - val_mae: 317.2117\n",
      "Epoch 5/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 780776.1875 - mae: 264.0262 - val_loss: 1245176.0000 - val_mae: 318.1056\n",
      "Epoch 6/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 742217.8750 - mae: 260.5391 - val_loss: 1249195.3750 - val_mae: 320.2389\n",
      "Epoch 7/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 711255.3125 - mae: 259.5159 - val_loss: 1263838.1250 - val_mae: 323.0540\n",
      "Epoch 8/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 692005.6875 - mae: 258.6161 - val_loss: 1282295.1250 - val_mae: 326.5674\n",
      "Epoch 9/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 651154.0000 - mae: 255.8752 - val_loss: 1309184.0000 - val_mae: 332.6989\n",
      "Epoch 10/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 626724.6875 - mae: 252.8183 - val_loss: 1294712.7500 - val_mae: 333.3246\n",
      "Processing ./db/train_af...\n",
      "Loaded 864060 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1050579.5000 - mae: 320.6670 - val_loss: 1839537.8750 - val_mae: 426.5535\n",
      "Epoch 2/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 880159.3750 - mae: 284.5495 - val_loss: 1826337.2500 - val_mae: 418.7205\n",
      "Epoch 3/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 811897.3125 - mae: 273.0760 - val_loss: 1823474.6250 - val_mae: 416.9259\n",
      "Epoch 4/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 777965.8125 - mae: 270.4626 - val_loss: 1825601.1250 - val_mae: 417.9141\n",
      "Epoch 5/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 744466.6875 - mae: 267.9903 - val_loss: 1835183.3750 - val_mae: 426.9707\n",
      "Epoch 6/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 694110.3125 - mae: 263.5034 - val_loss: 1845987.7500 - val_mae: 429.4211\n",
      "Epoch 7/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 686350.0625 - mae: 262.6243 - val_loss: 1855100.3750 - val_mae: 435.0388\n",
      "Epoch 8/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 637651.1250 - mae: 260.1444 - val_loss: 1879959.0000 - val_mae: 441.0624\n",
      "Epoch 9/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 607959.7500 - mae: 258.7094 - val_loss: 1891983.6250 - val_mae: 441.6237\n",
      "Epoch 10/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 593892.5000 - mae: 259.6103 - val_loss: 1913343.6250 - val_mae: 450.0839\n",
      "Processing ./db/train_ag...\n",
      "Loaded 849520 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1565178.3750 - mae: 343.7374 - val_loss: 1545769.3750 - val_mae: 347.0403\n",
      "Epoch 2/10\n",
      "\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1308645.7500 - mae: 321.0830 - val_loss: 1549177.1250 - val_mae: 348.3767\n",
      "Epoch 3/10\n",
      "\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1223236.0000 - mae: 314.8570 - val_loss: 1550214.7500 - val_mae: 349.6140\n",
      "Epoch 4/10\n",
      "\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1169745.3750 - mae: 310.4547 - val_loss: 1560283.5000 - val_mae: 350.4266\n",
      "Epoch 5/10\n",
      "\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1067477.3750 - mae: 303.5132 - val_loss: 1583103.8750 - val_mae: 354.1121\n",
      "Epoch 6/10\n",
      "\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1019079.0000 - mae: 298.9962 - val_loss: 1575418.6250 - val_mae: 356.9981\n",
      "Epoch 7/10\n",
      "\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 963575.2500 - mae: 296.6215 - val_loss: 1608223.5000 - val_mae: 358.9221\n",
      "Epoch 8/10\n",
      "\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 888581.3125 - mae: 291.1070 - val_loss: 1633559.1250 - val_mae: 365.7406\n",
      "Epoch 9/10\n",
      "\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 898635.8750 - mae: 293.4140 - val_loss: 1641838.0000 - val_mae: 368.4969\n",
      "Epoch 10/10\n",
      "\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 817086.0625 - mae: 287.2655 - val_loss: 1675010.3750 - val_mae: 373.0522\n",
      "Processing ./db/train_ah...\n",
      "Loaded 855740 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1487213.3750 - mae: 346.3154 - val_loss: 1394593.5000 - val_mae: 329.7167\n",
      "Epoch 2/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1232729.3750 - mae: 315.9617 - val_loss: 1385819.7500 - val_mae: 323.9595\n",
      "Epoch 3/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1107900.0000 - mae: 304.7827 - val_loss: 1385909.3750 - val_mae: 327.7339\n",
      "Epoch 4/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1039360.1875 - mae: 298.5930 - val_loss: 1393946.6250 - val_mae: 327.5018\n",
      "Epoch 5/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 983751.1875 - mae: 295.1733 - val_loss: 1406225.0000 - val_mae: 326.7641\n",
      "Epoch 6/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 911607.3125 - mae: 289.0863 - val_loss: 1412669.6250 - val_mae: 330.3607\n",
      "Epoch 7/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 866137.7500 - mae: 285.4894 - val_loss: 1420144.3750 - val_mae: 331.4210\n",
      "Epoch 8/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 806272.5000 - mae: 280.5938 - val_loss: 1440782.7500 - val_mae: 333.0932\n",
      "Epoch 9/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 766810.6250 - mae: 278.5554 - val_loss: 1454219.6250 - val_mae: 336.6882\n",
      "Epoch 10/10\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 714071.5625 - mae: 273.5835 - val_loss: 1463737.0000 - val_mae: 339.0555\n",
      "Processing ./db/train_ai...\n",
      "Loaded 851857 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1407627.6250 - mae: 336.0110 - val_loss: 1266949.8750 - val_mae: 321.3905\n",
      "Epoch 2/10\n",
      "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1120444.5000 - mae: 306.1557 - val_loss: 1255418.5000 - val_mae: 318.3145\n",
      "Epoch 3/10\n",
      "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1073821.1250 - mae: 301.1504 - val_loss: 1252201.6250 - val_mae: 317.5011\n",
      "Epoch 4/10\n",
      "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 930859.3125 - mae: 288.9467 - val_loss: 1262275.8750 - val_mae: 321.3696\n",
      "Epoch 5/10\n",
      "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 879072.6250 - mae: 283.1421 - val_loss: 1263407.0000 - val_mae: 322.1075\n",
      "Epoch 6/10\n",
      "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 852816.4375 - mae: 281.4073 - val_loss: 1268514.0000 - val_mae: 322.1715\n",
      "Epoch 7/10\n",
      "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 761577.7500 - mae: 273.7679 - val_loss: 1281129.0000 - val_mae: 327.7488\n",
      "Epoch 8/10\n",
      "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 728543.4375 - mae: 271.3482 - val_loss: 1299559.7500 - val_mae: 328.7433\n",
      "Epoch 9/10\n",
      "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 683476.6250 - mae: 267.5632 - val_loss: 1310285.3750 - val_mae: 331.2041\n",
      "Epoch 10/10\n",
      "\u001b[1m666/666\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 636907.9375 - mae: 262.4288 - val_loss: 1331510.5000 - val_mae: 335.5551\n",
      "Processing ./db/train_aj...\n",
      "Loaded 865327 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1216396.1250 - mae: 316.1252 - val_loss: 985316.3125 - val_mae: 284.3725\n",
      "Epoch 2/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1001396.0000 - mae: 292.7839 - val_loss: 982395.6875 - val_mae: 281.9197\n",
      "Epoch 3/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 913720.4375 - mae: 285.2165 - val_loss: 979528.3750 - val_mae: 283.6422\n",
      "Epoch 4/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 820212.4375 - mae: 276.4585 - val_loss: 988340.3125 - val_mae: 284.0123\n",
      "Epoch 5/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 785151.9375 - mae: 273.3993 - val_loss: 993885.6875 - val_mae: 285.0966\n",
      "Epoch 6/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 720548.0625 - mae: 267.4935 - val_loss: 998333.0625 - val_mae: 287.6833\n",
      "Epoch 7/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 670882.1250 - mae: 264.9363 - val_loss: 1005336.5625 - val_mae: 287.4069\n",
      "Epoch 8/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 620123.9375 - mae: 259.2855 - val_loss: 1022822.4375 - val_mae: 290.5310\n",
      "Epoch 9/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 587125.1250 - mae: 257.1414 - val_loss: 1033812.5625 - val_mae: 294.8855\n",
      "Epoch 10/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 567896.6250 - mae: 254.8224 - val_loss: 1044455.5000 - val_mae: 295.1239\n",
      "Processing ./db/train_ak...\n",
      "Loaded 863973 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1203230.2500 - mae: 320.5474 - val_loss: 1320274.0000 - val_mae: 322.3017\n",
      "Epoch 2/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 949929.9375 - mae: 294.9217 - val_loss: 1315022.5000 - val_mae: 322.4677\n",
      "Epoch 3/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 889805.1875 - mae: 286.9369 - val_loss: 1319896.8750 - val_mae: 321.1522\n",
      "Epoch 4/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 801577.1875 - mae: 278.4299 - val_loss: 1336535.8750 - val_mae: 326.2344\n",
      "Epoch 5/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 728197.8750 - mae: 272.2100 - val_loss: 1328080.6250 - val_mae: 324.4720\n",
      "Epoch 6/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 686105.3125 - mae: 268.2244 - val_loss: 1349285.6250 - val_mae: 328.3302\n",
      "Epoch 7/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 645811.8125 - mae: 264.2883 - val_loss: 1340747.6250 - val_mae: 327.8883\n",
      "Epoch 8/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 623418.9375 - mae: 261.9205 - val_loss: 1362913.5000 - val_mae: 330.5729\n",
      "Epoch 9/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 596603.8125 - mae: 258.1414 - val_loss: 1368514.3750 - val_mae: 332.2979\n",
      "Epoch 10/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 535315.0625 - mae: 252.7178 - val_loss: 1381574.1250 - val_mae: 334.1472\n",
      "Processing ./db/train_al...\n",
      "Loaded 860435 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1357243.1250 - mae: 333.8499 - val_loss: 1381309.2500 - val_mae: 326.5072\n",
      "Epoch 2/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1085615.6250 - mae: 307.9448 - val_loss: 1383080.6250 - val_mae: 323.9095\n",
      "Epoch 3/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 985186.0000 - mae: 296.9041 - val_loss: 1390887.2500 - val_mae: 325.1855\n",
      "Epoch 4/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 928368.3125 - mae: 291.8618 - val_loss: 1397191.6250 - val_mae: 325.6082\n",
      "Epoch 5/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 858307.4375 - mae: 285.9225 - val_loss: 1393680.3750 - val_mae: 328.6924\n",
      "Epoch 6/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 809595.0000 - mae: 281.3530 - val_loss: 1403714.8750 - val_mae: 330.0412\n",
      "Epoch 7/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 735746.1875 - mae: 275.4424 - val_loss: 1404845.7500 - val_mae: 331.7417\n",
      "Epoch 8/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 706640.0000 - mae: 270.9796 - val_loss: 1425230.2500 - val_mae: 334.1993\n",
      "Epoch 9/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 650285.8125 - mae: 266.3114 - val_loss: 1418662.8750 - val_mae: 339.3230\n",
      "Epoch 10/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 647218.0625 - mae: 265.6783 - val_loss: 1424141.5000 - val_mae: 339.3900\n",
      "Processing ./db/train_am...\n",
      "Loaded 859558 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m672/672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1428270.2500 - mae: 337.9487 - val_loss: 1126482.3750 - val_mae: 302.3739\n",
      "Epoch 2/10\n",
      "\u001b[1m672/672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1157547.8750 - mae: 313.2791 - val_loss: 1122336.0000 - val_mae: 301.2073\n",
      "Epoch 3/10\n",
      "\u001b[1m672/672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 968079.2500 - mae: 297.1349 - val_loss: 1125468.7500 - val_mae: 300.8434\n",
      "Epoch 4/10\n",
      "\u001b[1m672/672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 929023.3125 - mae: 294.0959 - val_loss: 1130745.3750 - val_mae: 302.2711\n",
      "Epoch 5/10\n",
      "\u001b[1m672/672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 838555.7500 - mae: 285.4102 - val_loss: 1143363.2500 - val_mae: 303.9044\n",
      "Epoch 6/10\n",
      "\u001b[1m672/672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 774143.6875 - mae: 280.3195 - val_loss: 1151898.3750 - val_mae: 305.0314\n",
      "Epoch 7/10\n",
      "\u001b[1m672/672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 719260.9375 - mae: 274.6503 - val_loss: 1172562.0000 - val_mae: 307.1357\n",
      "Epoch 8/10\n",
      "\u001b[1m672/672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 708192.6250 - mae: 273.1360 - val_loss: 1181173.1250 - val_mae: 308.5739\n",
      "Epoch 9/10\n",
      "\u001b[1m672/672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 653434.7500 - mae: 267.7422 - val_loss: 1200169.7500 - val_mae: 311.1396\n",
      "Epoch 10/10\n",
      "\u001b[1m672/672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 629917.2500 - mae: 264.8358 - val_loss: 1207147.6250 - val_mae: 313.0615\n",
      "Processing ./db/train_an...\n",
      "Loaded 861663 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1299400.5000 - mae: 331.9188 - val_loss: 1365353.2500 - val_mae: 326.1349\n",
      "Epoch 2/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1069515.6250 - mae: 306.8108 - val_loss: 1367314.7500 - val_mae: 323.5611\n",
      "Epoch 3/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 916931.5000 - mae: 291.9287 - val_loss: 1369595.1250 - val_mae: 325.9518\n",
      "Epoch 4/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 843310.3125 - mae: 286.4107 - val_loss: 1375557.7500 - val_mae: 326.8775\n",
      "Epoch 5/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 790181.6250 - mae: 280.6303 - val_loss: 1385560.1250 - val_mae: 329.0578\n",
      "Epoch 6/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 762541.4375 - mae: 279.2426 - val_loss: 1396860.1250 - val_mae: 329.6743\n",
      "Epoch 7/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 717596.9375 - mae: 272.1192 - val_loss: 1415988.6250 - val_mae: 333.2983\n",
      "Epoch 8/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 667349.6250 - mae: 269.5799 - val_loss: 1424778.7500 - val_mae: 337.5288\n",
      "Epoch 9/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 635742.8750 - mae: 266.2497 - val_loss: 1444071.7500 - val_mae: 336.4614\n",
      "Epoch 10/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 620035.9375 - mae: 263.4249 - val_loss: 1459302.3750 - val_mae: 339.7874\n",
      "Processing ./db/train_ao...\n",
      "Loaded 862178 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1235588.0000 - mae: 316.4654 - val_loss: 1248510.1250 - val_mae: 317.5323\n",
      "Epoch 2/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 944126.0000 - mae: 289.6398 - val_loss: 1236114.3750 - val_mae: 312.4978\n",
      "Epoch 3/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 833311.5625 - mae: 279.0045 - val_loss: 1231548.0000 - val_mae: 312.1908\n",
      "Epoch 4/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 792389.6250 - mae: 275.1950 - val_loss: 1234141.1250 - val_mae: 313.1226\n",
      "Epoch 5/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 768382.0625 - mae: 271.6080 - val_loss: 1240763.8750 - val_mae: 313.5800\n",
      "Epoch 6/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 690799.0000 - mae: 264.4695 - val_loss: 1249693.2500 - val_mae: 314.4411\n",
      "Epoch 7/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 658974.5625 - mae: 261.6175 - val_loss: 1256990.1250 - val_mae: 315.7708\n",
      "Epoch 8/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 616283.1250 - mae: 257.0612 - val_loss: 1267852.5000 - val_mae: 318.4965\n",
      "Epoch 9/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 602158.3750 - mae: 256.2850 - val_loss: 1278323.7500 - val_mae: 319.8654\n",
      "Epoch 10/10\n",
      "\u001b[1m674/674\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 544520.3750 - mae: 249.9937 - val_loss: 1287626.0000 - val_mae: 324.0732\n",
      "Processing ./db/train_ap...\n",
      "Loaded 868720 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1346651.7500 - mae: 330.1125 - val_loss: 1420467.1250 - val_mae: 317.3369\n",
      "Epoch 2/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1056506.6250 - mae: 305.2467 - val_loss: 1418652.1250 - val_mae: 316.6369\n",
      "Epoch 3/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 936375.3125 - mae: 294.2878 - val_loss: 1421697.2500 - val_mae: 318.1632\n",
      "Epoch 4/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 904467.6875 - mae: 290.8880 - val_loss: 1419814.0000 - val_mae: 322.2581\n",
      "Epoch 5/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 845445.0625 - mae: 284.2158 - val_loss: 1422902.6250 - val_mae: 318.6201\n",
      "Epoch 6/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 767896.5000 - mae: 278.3744 - val_loss: 1433050.0000 - val_mae: 322.5065\n",
      "Epoch 7/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 751699.5000 - mae: 277.3731 - val_loss: 1457566.8750 - val_mae: 322.3017\n",
      "Epoch 8/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 704050.8125 - mae: 272.4279 - val_loss: 1454564.5000 - val_mae: 324.8474\n",
      "Epoch 9/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 669962.0000 - mae: 269.6975 - val_loss: 1479747.7500 - val_mae: 327.0968\n",
      "Epoch 10/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 628310.5000 - mae: 265.6359 - val_loss: 1476994.7500 - val_mae: 329.6714\n",
      "Processing ./db/train_aq...\n",
      "Loaded 857470 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1402290.7500 - mae: 339.3393 - val_loss: 1909338.5000 - val_mae: 357.4131\n",
      "Epoch 2/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1067972.1250 - mae: 309.4039 - val_loss: 1908998.6250 - val_mae: 358.5557\n",
      "Epoch 3/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 968528.6250 - mae: 298.8637 - val_loss: 1908296.2500 - val_mae: 356.5787\n",
      "Epoch 4/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 892092.1250 - mae: 292.6399 - val_loss: 1918917.6250 - val_mae: 357.8004\n",
      "Epoch 5/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 842739.0000 - mae: 287.1672 - val_loss: 1925627.3750 - val_mae: 359.0282\n",
      "Epoch 6/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 748032.1875 - mae: 280.3618 - val_loss: 1933890.6250 - val_mae: 361.5625\n",
      "Epoch 7/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 720716.0000 - mae: 276.1907 - val_loss: 1944583.2500 - val_mae: 362.2002\n",
      "Epoch 8/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 714011.7500 - mae: 274.5320 - val_loss: 1950039.5000 - val_mae: 363.6601\n",
      "Epoch 9/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 655265.1875 - mae: 268.1339 - val_loss: 1962431.6250 - val_mae: 364.1041\n",
      "Epoch 10/10\n",
      "\u001b[1m670/670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 625953.7500 - mae: 265.0584 - val_loss: 1971520.8750 - val_mae: 366.0027\n",
      "Processing ./db/train_ar...\n",
      "Loaded 857826 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1293210.6250 - mae: 322.9558 - val_loss: 1271055.7500 - val_mae: 320.5952\n",
      "Epoch 2/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1060462.3750 - mae: 302.0061 - val_loss: 1271862.6250 - val_mae: 319.3912\n",
      "Epoch 3/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 958896.1875 - mae: 293.1535 - val_loss: 1274090.6250 - val_mae: 321.8115\n",
      "Epoch 4/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 897132.5625 - mae: 289.0967 - val_loss: 1280690.8750 - val_mae: 319.8430\n",
      "Epoch 5/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 858785.5625 - mae: 284.7375 - val_loss: 1284989.6250 - val_mae: 323.7559\n",
      "Epoch 6/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 776672.9375 - mae: 279.3682 - val_loss: 1300143.0000 - val_mae: 326.2152\n",
      "Epoch 7/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 753177.5625 - mae: 274.9706 - val_loss: 1309726.3750 - val_mae: 326.3183\n",
      "Epoch 8/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 707468.5000 - mae: 270.5915 - val_loss: 1323245.0000 - val_mae: 328.1040\n",
      "Epoch 9/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 711379.7500 - mae: 270.6853 - val_loss: 1338328.8750 - val_mae: 330.2059\n",
      "Epoch 10/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 647529.0625 - mae: 264.6434 - val_loss: 1352229.7500 - val_mae: 332.0846\n",
      "Processing ./db/train_as...\n",
      "Loaded 862741 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1249304.2500 - mae: 322.1264 - val_loss: 1053073.3750 - val_mae: 292.0436\n",
      "Epoch 2/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 992235.7500 - mae: 298.7973 - val_loss: 1049236.6250 - val_mae: 289.7361\n",
      "Epoch 3/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 890636.5000 - mae: 287.7126 - val_loss: 1051617.3750 - val_mae: 289.9270\n",
      "Epoch 4/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 806028.8750 - mae: 280.6780 - val_loss: 1055277.3750 - val_mae: 289.2800\n",
      "Epoch 5/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 783519.3125 - mae: 278.0708 - val_loss: 1064981.1250 - val_mae: 289.6202\n",
      "Epoch 6/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 723062.4375 - mae: 271.6633 - val_loss: 1076666.8750 - val_mae: 292.8375\n",
      "Epoch 7/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 729877.2500 - mae: 271.6197 - val_loss: 1082163.3750 - val_mae: 292.4514\n",
      "Epoch 8/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 668195.2500 - mae: 265.6465 - val_loss: 1083308.5000 - val_mae: 293.6688\n",
      "Epoch 9/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 641255.6250 - mae: 262.1404 - val_loss: 1091452.0000 - val_mae: 296.1592\n",
      "Epoch 10/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 607119.8125 - mae: 258.8339 - val_loss: 1103450.0000 - val_mae: 297.5992\n",
      "Processing ./db/train_at...\n",
      "Loaded 861206 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1241763.6250 - mae: 321.5992 - val_loss: 855677.5625 - val_mae: 281.7971\n",
      "Epoch 2/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 961765.6875 - mae: 296.8773 - val_loss: 858883.7500 - val_mae: 281.4249\n",
      "Epoch 3/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 903339.5625 - mae: 292.6454 - val_loss: 869417.5625 - val_mae: 282.3139\n",
      "Epoch 4/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 854079.1250 - mae: 286.2306 - val_loss: 872349.6250 - val_mae: 283.1204\n",
      "Epoch 5/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 794282.9375 - mae: 280.5479 - val_loss: 881773.5000 - val_mae: 284.1137\n",
      "Epoch 6/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 741847.2500 - mae: 276.1644 - val_loss: 896337.1875 - val_mae: 285.3621\n",
      "Epoch 7/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 709364.9375 - mae: 273.3616 - val_loss: 913586.5625 - val_mae: 287.3766\n",
      "Epoch 8/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 686554.9375 - mae: 270.9846 - val_loss: 919597.8125 - val_mae: 289.3467\n",
      "Epoch 9/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 685039.6875 - mae: 270.7739 - val_loss: 928536.8125 - val_mae: 289.2036\n",
      "Epoch 10/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 622740.7500 - mae: 264.6981 - val_loss: 948581.0000 - val_mae: 293.3755\n",
      "Processing ./db/train_au...\n",
      "Loaded 866483 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 901305.5000 - mae: 295.3035 - val_loss: 973874.4375 - val_mae: 299.9507\n",
      "Epoch 2/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 743483.8750 - mae: 277.6342 - val_loss: 969231.7500 - val_mae: 295.8439\n",
      "Epoch 3/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 679134.3125 - mae: 271.3802 - val_loss: 967723.3125 - val_mae: 297.2414\n",
      "Epoch 4/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 651651.3125 - mae: 267.5598 - val_loss: 969403.4375 - val_mae: 298.1603\n",
      "Epoch 5/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 619216.1250 - mae: 264.9166 - val_loss: 973025.6250 - val_mae: 298.9425\n",
      "Epoch 6/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 614406.6250 - mae: 262.9560 - val_loss: 980581.6875 - val_mae: 301.0776\n",
      "Epoch 7/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 578410.4375 - mae: 260.9793 - val_loss: 984946.7500 - val_mae: 301.2989\n",
      "Epoch 8/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 577226.0625 - mae: 259.2234 - val_loss: 991108.5000 - val_mae: 303.1397\n",
      "Epoch 9/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 556022.4375 - mae: 256.5688 - val_loss: 1001267.1875 - val_mae: 307.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 555730.5625 - mae: 256.4855 - val_loss: 1007401.1250 - val_mae: 308.7160\n",
      "Processing ./db/train_av...\n",
      "Loaded 860847 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 912473.5625 - mae: 302.2599 - val_loss: 734402.4375 - val_mae: 284.5560\n",
      "Epoch 2/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 793078.5000 - mae: 285.4251 - val_loss: 735635.4375 - val_mae: 286.1825\n",
      "Epoch 3/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 742961.6875 - mae: 281.1282 - val_loss: 738024.1250 - val_mae: 286.0009\n",
      "Epoch 4/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 672468.2500 - mae: 276.0100 - val_loss: 744678.7500 - val_mae: 289.7079\n",
      "Epoch 5/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 671204.0625 - mae: 274.1418 - val_loss: 748616.6250 - val_mae: 287.9314\n",
      "Epoch 6/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 650540.2500 - mae: 272.7402 - val_loss: 753108.4375 - val_mae: 289.8515\n",
      "Epoch 7/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 636593.0000 - mae: 270.9381 - val_loss: 762274.9375 - val_mae: 290.2231\n",
      "Epoch 8/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 626851.1875 - mae: 269.0622 - val_loss: 767391.5625 - val_mae: 291.4204\n",
      "Epoch 9/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595121.7500 - mae: 265.9072 - val_loss: 778582.3750 - val_mae: 294.7162\n",
      "Epoch 10/10\n",
      "\u001b[1m673/673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 577496.0625 - mae: 264.9397 - val_loss: 783744.1875 - val_mae: 293.4493\n",
      "Processing ./db/train_aw...\n",
      "Loaded 867543 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 794738.3125 - mae: 286.4022 - val_loss: 836450.7500 - val_mae: 280.2323\n",
      "Epoch 2/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 652740.3125 - mae: 267.1714 - val_loss: 823096.0625 - val_mae: 279.4885\n",
      "Epoch 3/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 620505.0625 - mae: 262.2040 - val_loss: 816925.0625 - val_mae: 278.7952\n",
      "Epoch 4/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 576975.8125 - mae: 256.7491 - val_loss: 817165.4375 - val_mae: 278.8312\n",
      "Epoch 5/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 563366.1875 - mae: 254.5625 - val_loss: 820446.0000 - val_mae: 279.9140\n",
      "Epoch 6/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 556878.9375 - mae: 253.0831 - val_loss: 827788.1875 - val_mae: 282.2668\n",
      "Epoch 7/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 529954.4375 - mae: 250.4452 - val_loss: 830091.2500 - val_mae: 282.2886\n",
      "Epoch 8/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 511216.6562 - mae: 249.0572 - val_loss: 834833.1875 - val_mae: 283.1929\n",
      "Epoch 9/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 509328.7812 - mae: 247.6187 - val_loss: 852161.6875 - val_mae: 285.3403\n",
      "Epoch 10/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 501825.5312 - mae: 247.4514 - val_loss: 855574.3750 - val_mae: 285.5459\n",
      "Processing ./db/train_ax...\n",
      "Loaded 877933 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 768118.3750 - mae: 282.3513 - val_loss: 746890.8125 - val_mae: 274.2172\n",
      "Epoch 2/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 671261.9375 - mae: 270.4705 - val_loss: 745381.8750 - val_mae: 274.1847\n",
      "Epoch 3/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 627036.7500 - mae: 265.5099 - val_loss: 745444.3125 - val_mae: 274.2106\n",
      "Epoch 4/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 621338.1250 - mae: 263.5958 - val_loss: 751459.6250 - val_mae: 275.6888\n",
      "Epoch 5/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 590086.3750 - mae: 260.5903 - val_loss: 752347.7500 - val_mae: 276.4739\n",
      "Epoch 6/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 566368.4375 - mae: 258.1575 - val_loss: 768832.1250 - val_mae: 277.6509\n",
      "Epoch 7/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 558658.1875 - mae: 257.8194 - val_loss: 758844.0000 - val_mae: 278.5937\n",
      "Epoch 8/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 558722.1875 - mae: 257.0739 - val_loss: 780476.0000 - val_mae: 279.1531\n",
      "Epoch 9/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 549955.2500 - mae: 255.1742 - val_loss: 774028.8750 - val_mae: 280.8130\n",
      "Epoch 10/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 521434.7812 - mae: 253.0382 - val_loss: 789404.7500 - val_mae: 282.4270\n",
      "Processing ./db/train_ay...\n",
      "Loaded 872588 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 832261.7500 - mae: 292.2652 - val_loss: 2030923.5000 - val_mae: 275.0927\n",
      "Epoch 2/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 708631.8750 - mae: 274.6666 - val_loss: 2051649.5000 - val_mae: 274.8127\n",
      "Epoch 3/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 679096.7500 - mae: 270.3215 - val_loss: 2057971.3750 - val_mae: 274.3856\n",
      "Epoch 4/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 628381.1875 - mae: 265.2069 - val_loss: 2101962.2500 - val_mae: 274.2959\n",
      "Epoch 5/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 628527.3750 - mae: 263.2493 - val_loss: 2148012.7500 - val_mae: 278.0339\n",
      "Epoch 6/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 631016.0000 - mae: 262.3524 - val_loss: 2220083.5000 - val_mae: 275.3016\n",
      "Epoch 7/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 597234.0000 - mae: 259.7515 - val_loss: 2266093.0000 - val_mae: 277.2303\n",
      "Epoch 8/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 583995.3125 - mae: 258.1638 - val_loss: 2392045.5000 - val_mae: 277.1732\n",
      "Epoch 9/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 562734.9375 - mae: 256.0217 - val_loss: 2426571.5000 - val_mae: 279.0595\n",
      "Epoch 10/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 569862.5000 - mae: 255.3174 - val_loss: 2558027.7500 - val_mae: 280.5906\n",
      "Processing ./db/train_az...\n",
      "Loaded 867056 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 953795.0625 - mae: 292.7548 - val_loss: 831077.3125 - val_mae: 284.6032\n",
      "Epoch 2/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 699267.8125 - mae: 273.5462 - val_loss: 824299.8750 - val_mae: 283.5400\n",
      "Epoch 3/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 678167.0000 - mae: 270.0141 - val_loss: 824480.1875 - val_mae: 283.3206\n",
      "Epoch 4/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 653711.8750 - mae: 266.1927 - val_loss: 825263.3750 - val_mae: 284.0302\n",
      "Epoch 5/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 614812.1250 - mae: 263.3402 - val_loss: 826941.6875 - val_mae: 286.0209\n",
      "Epoch 6/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 620740.3125 - mae: 262.1092 - val_loss: 834426.6875 - val_mae: 286.5622\n",
      "Epoch 7/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 590802.1250 - mae: 260.2750 - val_loss: 834699.1250 - val_mae: 286.5574\n",
      "Epoch 8/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 593924.1875 - mae: 259.6824 - val_loss: 840215.6875 - val_mae: 288.6627\n",
      "Epoch 9/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 564711.6875 - mae: 256.2710 - val_loss: 843819.2500 - val_mae: 289.5320\n",
      "Epoch 10/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 534742.0000 - mae: 253.7151 - val_loss: 850580.7500 - val_mae: 289.7380\n",
      "Processing ./db/train_ba...\n",
      "Loaded 866626 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 772500.4375 - mae: 280.6715 - val_loss: 772383.5000 - val_mae: 279.4951\n",
      "Epoch 2/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 682102.5000 - mae: 269.0821 - val_loss: 777399.8125 - val_mae: 280.0045\n",
      "Epoch 3/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 632595.1875 - mae: 264.4443 - val_loss: 797869.6875 - val_mae: 280.4583\n",
      "Epoch 4/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 591638.2500 - mae: 260.1854 - val_loss: 799264.8125 - val_mae: 281.4375\n",
      "Epoch 5/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 559507.1875 - mae: 256.9695 - val_loss: 780642.8125 - val_mae: 281.7668\n",
      "Epoch 6/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 576152.9375 - mae: 258.5268 - val_loss: 781025.6875 - val_mae: 284.7967\n",
      "Epoch 7/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 551074.7500 - mae: 255.6652 - val_loss: 805709.3750 - val_mae: 284.6898\n",
      "Epoch 8/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 529128.5000 - mae: 252.5723 - val_loss: 829247.1250 - val_mae: 286.0434\n",
      "Epoch 9/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 505681.5938 - mae: 251.0062 - val_loss: 784181.5000 - val_mae: 285.6051\n",
      "Epoch 10/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 515339.0625 - mae: 250.3088 - val_loss: 785027.9375 - val_mae: 286.7932\n",
      "Processing ./db/train_bb...\n",
      "Loaded 876956 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 722037.9375 - mae: 276.7091 - val_loss: 771550.1250 - val_mae: 281.0167\n",
      "Epoch 2/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 648061.8125 - mae: 264.4430 - val_loss: 770493.9375 - val_mae: 280.9391\n",
      "Epoch 3/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 581676.9375 - mae: 258.2340 - val_loss: 773066.4375 - val_mae: 280.8041\n",
      "Epoch 4/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 555448.5000 - mae: 255.2956 - val_loss: 774898.6875 - val_mae: 282.6510\n",
      "Epoch 5/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 540129.6250 - mae: 255.2171 - val_loss: 780097.1250 - val_mae: 283.7669\n",
      "Epoch 6/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 514272.0625 - mae: 251.0656 - val_loss: 781562.1875 - val_mae: 284.8915\n",
      "Epoch 7/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 513316.5625 - mae: 251.1447 - val_loss: 787861.0625 - val_mae: 285.7005\n",
      "Epoch 8/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 509398.8125 - mae: 249.0610 - val_loss: 791057.5625 - val_mae: 287.3481\n",
      "Epoch 9/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 500203.4375 - mae: 249.1863 - val_loss: 794890.2500 - val_mae: 289.5155\n",
      "Epoch 10/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 484784.0000 - mae: 247.8538 - val_loss: 797934.3750 - val_mae: 288.8297\n",
      "Processing ./db/train_bc...\n",
      "Loaded 874929 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 814557.0625 - mae: 289.7384 - val_loss: 940031.0000 - val_mae: 296.1242\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 683414.5000 - mae: 273.8229 - val_loss: 937730.8750 - val_mae: 295.5785\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 657391.8125 - mae: 269.9991 - val_loss: 941854.5625 - val_mae: 297.0486\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 632882.6250 - mae: 267.3430 - val_loss: 944216.8125 - val_mae: 299.1599\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 619841.0625 - mae: 265.0360 - val_loss: 949013.6250 - val_mae: 298.8106\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 594819.0625 - mae: 262.7003 - val_loss: 954562.0625 - val_mae: 299.3013\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 557039.3125 - mae: 259.3770 - val_loss: 960848.5000 - val_mae: 301.2531\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 563409.9375 - mae: 260.5353 - val_loss: 971034.6875 - val_mae: 301.7984\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 550966.3125 - mae: 257.2699 - val_loss: 979689.4375 - val_mae: 304.5225\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 526262.3125 - mae: 256.4270 - val_loss: 990304.0000 - val_mae: 307.5139\n",
      "Processing ./db/train_bd...\n",
      "Loaded 874045 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 752345.1875 - mae: 285.1851 - val_loss: 867657.6875 - val_mae: 305.9734\n",
      "Epoch 2/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 653707.3750 - mae: 269.4530 - val_loss: 860943.6875 - val_mae: 304.4922\n",
      "Epoch 3/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 629021.4375 - mae: 267.5513 - val_loss: 863193.5625 - val_mae: 304.4068\n",
      "Epoch 4/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 576881.3750 - mae: 260.4999 - val_loss: 864367.9375 - val_mae: 306.5560\n",
      "Epoch 5/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 572786.0625 - mae: 259.0898 - val_loss: 867430.0000 - val_mae: 304.5619\n",
      "Epoch 6/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 547648.6875 - mae: 256.0583 - val_loss: 872427.4375 - val_mae: 306.2277\n",
      "Epoch 7/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 547927.3125 - mae: 254.4297 - val_loss: 875130.8750 - val_mae: 307.5862\n",
      "Epoch 8/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 526028.2500 - mae: 253.7553 - val_loss: 879613.0000 - val_mae: 307.8820\n",
      "Epoch 9/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 517993.6250 - mae: 251.7164 - val_loss: 885840.0000 - val_mae: 310.8174\n",
      "Epoch 10/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 481578.5938 - mae: 249.1716 - val_loss: 900442.9375 - val_mae: 315.0136\n",
      "Processing ./db/train_be...\n",
      "Loaded 870330 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 810052.8125 - mae: 287.8364 - val_loss: 755515.3125 - val_mae: 265.5044\n",
      "Epoch 2/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 711990.6250 - mae: 274.1337 - val_loss: 755859.3125 - val_mae: 267.1101\n",
      "Epoch 3/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 669974.3125 - mae: 269.6907 - val_loss: 759790.2500 - val_mae: 267.0386\n",
      "Epoch 4/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 653832.4375 - mae: 266.7156 - val_loss: 763746.8125 - val_mae: 268.4313\n",
      "Epoch 5/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 629220.8125 - mae: 265.7767 - val_loss: 768707.7500 - val_mae: 268.3466\n",
      "Epoch 6/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 625120.6250 - mae: 265.0247 - val_loss: 776705.3125 - val_mae: 270.7331\n",
      "Epoch 7/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 613904.3125 - mae: 263.8186 - val_loss: 781102.5625 - val_mae: 269.9140\n",
      "Epoch 8/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 584216.2500 - mae: 261.2918 - val_loss: 786269.4375 - val_mae: 270.9908\n",
      "Epoch 9/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 579216.1250 - mae: 261.0148 - val_loss: 794611.9375 - val_mae: 273.2159\n",
      "Epoch 10/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 557670.1250 - mae: 258.4323 - val_loss: 804739.3750 - val_mae: 274.6242\n",
      "Processing ./db/train_bf...\n",
      "Loaded 878842 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 901380.8125 - mae: 288.3422 - val_loss: 602368.9375 - val_mae: 273.4498\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 704674.2500 - mae: 272.9985 - val_loss: 597426.5625 - val_mae: 272.4281\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 679193.2500 - mae: 269.1932 - val_loss: 599235.6875 - val_mae: 272.7979\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 597972.4375 - mae: 263.7392 - val_loss: 598919.8125 - val_mae: 273.4552\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 573792.2500 - mae: 261.6051 - val_loss: 602426.3125 - val_mae: 273.8298\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 558104.3750 - mae: 259.6599 - val_loss: 604202.8125 - val_mae: 274.0418\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 551216.6875 - mae: 257.8565 - val_loss: 605946.1875 - val_mae: 273.7458\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 565709.3750 - mae: 258.2038 - val_loss: 610275.3125 - val_mae: 274.3853\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 533244.8125 - mae: 254.2095 - val_loss: 614676.8125 - val_mae: 276.3114\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 511909.6875 - mae: 253.3197 - val_loss: 617798.2500 - val_mae: 276.1414\n",
      "Processing ./db/train_bg...\n",
      "Loaded 870913 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 732699.6875 - mae: 278.7319 - val_loss: 752105.6875 - val_mae: 291.9765\n",
      "Epoch 2/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 647006.5000 - mae: 267.6109 - val_loss: 744432.8750 - val_mae: 289.7279\n",
      "Epoch 3/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 629738.9375 - mae: 263.5620 - val_loss: 744311.8125 - val_mae: 290.4943\n",
      "Epoch 4/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 609330.6875 - mae: 261.6929 - val_loss: 744675.0000 - val_mae: 291.8878\n",
      "Epoch 5/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595356.4375 - mae: 259.7975 - val_loss: 748032.0000 - val_mae: 292.9093\n",
      "Epoch 6/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 571535.3750 - mae: 257.0538 - val_loss: 753853.0625 - val_mae: 294.4213\n",
      "Epoch 7/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 563984.6875 - mae: 256.1722 - val_loss: 760576.6875 - val_mae: 296.3014\n",
      "Epoch 8/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 539411.1875 - mae: 254.6199 - val_loss: 763882.0625 - val_mae: 297.2824\n",
      "Epoch 9/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 513206.9062 - mae: 253.2391 - val_loss: 772511.4375 - val_mae: 298.7442\n",
      "Epoch 10/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 508489.0000 - mae: 252.3594 - val_loss: 778615.7500 - val_mae: 300.9629\n",
      "Processing ./db/train_bh...\n",
      "Loaded 869590 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 769430.0000 - mae: 289.5831 - val_loss: 946842.6250 - val_mae: 286.0826\n",
      "Epoch 2/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 699597.6875 - mae: 276.5557 - val_loss: 945160.1250 - val_mae: 285.3959\n",
      "Epoch 3/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 667614.1875 - mae: 269.4483 - val_loss: 944647.6875 - val_mae: 285.3531\n",
      "Epoch 4/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 635508.5625 - mae: 266.5907 - val_loss: 948102.6250 - val_mae: 285.6023\n",
      "Epoch 5/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 590781.8750 - mae: 263.0843 - val_loss: 950716.8125 - val_mae: 286.7024\n",
      "Epoch 6/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 605802.5625 - mae: 263.1501 - val_loss: 955693.0625 - val_mae: 288.5119\n",
      "Epoch 7/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 585891.9375 - mae: 259.8210 - val_loss: 961561.0000 - val_mae: 290.7878\n",
      "Epoch 8/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 577042.6250 - mae: 260.1812 - val_loss: 964447.3750 - val_mae: 289.8699\n",
      "Epoch 9/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 558563.0625 - mae: 259.2466 - val_loss: 972731.6875 - val_mae: 291.2479\n",
      "Epoch 10/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 550254.0000 - mae: 257.6053 - val_loss: 976838.9375 - val_mae: 293.4106\n",
      "Processing ./db/train_bi...\n",
      "Loaded 867420 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 782339.1875 - mae: 283.6884 - val_loss: 827904.6250 - val_mae: 285.0651\n",
      "Epoch 2/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 711387.9375 - mae: 269.3036 - val_loss: 824646.6875 - val_mae: 285.1528\n",
      "Epoch 3/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 649102.2500 - mae: 264.8265 - val_loss: 823093.0625 - val_mae: 287.2261\n",
      "Epoch 4/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 615713.7500 - mae: 261.0682 - val_loss: 823381.8750 - val_mae: 286.5845\n",
      "Epoch 5/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 616032.3125 - mae: 260.5068 - val_loss: 827481.1250 - val_mae: 287.4766\n",
      "Epoch 6/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 606275.7500 - mae: 259.7278 - val_loss: 831162.3750 - val_mae: 288.9830\n",
      "Epoch 7/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 569675.1875 - mae: 256.5369 - val_loss: 833816.5625 - val_mae: 291.0545\n",
      "Epoch 8/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 581438.6875 - mae: 256.9552 - val_loss: 839700.1875 - val_mae: 296.0141\n",
      "Epoch 9/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 563338.7500 - mae: 255.1669 - val_loss: 844224.1250 - val_mae: 293.5147\n",
      "Epoch 10/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 574856.7500 - mae: 256.0489 - val_loss: 847608.2500 - val_mae: 294.8112\n",
      "Processing ./db/train_bj...\n",
      "Loaded 864981 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1024152.4375 - mae: 286.6374 - val_loss: 858494.8125 - val_mae: 288.9950\n",
      "Epoch 2/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 674197.6250 - mae: 269.6065 - val_loss: 853338.3125 - val_mae: 288.2820\n",
      "Epoch 3/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 642626.4375 - mae: 265.7525 - val_loss: 852808.0625 - val_mae: 289.0939\n",
      "Epoch 4/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 626331.8125 - mae: 263.0605 - val_loss: 854403.5625 - val_mae: 287.9651\n",
      "Epoch 5/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 598189.3750 - mae: 260.3386 - val_loss: 856030.9375 - val_mae: 289.2530\n",
      "Epoch 6/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 600054.3125 - mae: 259.8524 - val_loss: 859144.0625 - val_mae: 291.0623\n",
      "Epoch 7/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 577653.6250 - mae: 256.5290 - val_loss: 862451.3750 - val_mae: 289.9131\n",
      "Epoch 8/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 567503.8125 - mae: 255.5693 - val_loss: 866449.4375 - val_mae: 292.4805\n",
      "Epoch 9/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 546221.5625 - mae: 254.7790 - val_loss: 870447.0000 - val_mae: 292.5713\n",
      "Epoch 10/10\n",
      "\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 561207.1875 - mae: 255.2969 - val_loss: 875406.1250 - val_mae: 292.8960\n",
      "Processing ./db/train_bk...\n",
      "Loaded 876431 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 735486.8750 - mae: 273.4691 - val_loss: 731781.7500 - val_mae: 283.9579\n",
      "Epoch 2/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 678229.4375 - mae: 265.7183 - val_loss: 729543.1875 - val_mae: 283.8380\n",
      "Epoch 3/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 643549.0000 - mae: 261.1665 - val_loss: 731727.6250 - val_mae: 285.2635\n",
      "Epoch 4/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 599156.3125 - mae: 257.4975 - val_loss: 734745.6250 - val_mae: 285.9087\n",
      "Epoch 5/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 585080.0625 - mae: 255.6425 - val_loss: 736686.3125 - val_mae: 286.9698\n",
      "Epoch 6/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 587845.6250 - mae: 255.8961 - val_loss: 737565.8750 - val_mae: 287.1568\n",
      "Epoch 7/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 567302.3750 - mae: 252.8580 - val_loss: 741642.0625 - val_mae: 288.6460\n",
      "Epoch 8/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 565023.7500 - mae: 253.8760 - val_loss: 746515.0625 - val_mae: 289.4921\n",
      "Epoch 9/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 555344.9375 - mae: 252.3275 - val_loss: 753510.2500 - val_mae: 290.7719\n",
      "Epoch 10/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 535290.8125 - mae: 250.4774 - val_loss: 757655.1250 - val_mae: 293.0981\n",
      "Processing ./db/train_bl...\n",
      "Loaded 870986 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 950900.5000 - mae: 303.1571 - val_loss: 701563.6875 - val_mae: 274.5293\n",
      "Epoch 2/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 818976.0000 - mae: 289.5325 - val_loss: 701254.9375 - val_mae: 272.9067\n",
      "Epoch 3/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 766837.6875 - mae: 284.2807 - val_loss: 702461.6250 - val_mae: 273.3677\n",
      "Epoch 4/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 759714.7500 - mae: 282.4781 - val_loss: 703128.9375 - val_mae: 274.2382\n",
      "Epoch 5/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 722486.0000 - mae: 279.0700 - val_loss: 706051.3750 - val_mae: 274.2448\n",
      "Epoch 6/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 704008.0625 - mae: 276.6407 - val_loss: 707198.6875 - val_mae: 275.0983\n",
      "Epoch 7/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 663004.5625 - mae: 273.9304 - val_loss: 711380.5000 - val_mae: 276.2419\n",
      "Epoch 8/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 639768.2500 - mae: 273.0557 - val_loss: 713271.8125 - val_mae: 276.8976\n",
      "Epoch 9/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 657262.0625 - mae: 272.7625 - val_loss: 719445.4375 - val_mae: 278.8637\n",
      "Epoch 10/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 639536.5625 - mae: 270.5517 - val_loss: 720894.8125 - val_mae: 279.3351\n",
      "Processing ./db/train_bm...\n",
      "Loaded 868095 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 890510.3125 - mae: 297.5579 - val_loss: 832101.9375 - val_mae: 288.2147\n",
      "Epoch 2/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 780044.0000 - mae: 282.4648 - val_loss: 832744.8750 - val_mae: 288.2050\n",
      "Epoch 3/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 727217.7500 - mae: 276.6752 - val_loss: 836032.6875 - val_mae: 290.0796\n",
      "Epoch 4/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 702492.0000 - mae: 274.6071 - val_loss: 841459.8125 - val_mae: 289.5992\n",
      "Epoch 5/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 699068.0625 - mae: 274.3219 - val_loss: 845314.6250 - val_mae: 290.7621\n",
      "Epoch 6/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 677947.9375 - mae: 272.5654 - val_loss: 850574.1250 - val_mae: 289.5727\n",
      "Epoch 7/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 660455.5625 - mae: 269.4016 - val_loss: 855338.1250 - val_mae: 292.0483\n",
      "Epoch 8/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 632883.0000 - mae: 269.2782 - val_loss: 865112.2500 - val_mae: 295.3482\n",
      "Epoch 9/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 646309.1250 - mae: 269.1884 - val_loss: 868652.0625 - val_mae: 293.4555\n",
      "Epoch 10/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 622644.7500 - mae: 267.4196 - val_loss: 875423.4375 - val_mae: 294.8138\n",
      "Processing ./db/train_bn...\n",
      "Loaded 873690 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 791589.1250 - mae: 286.2533 - val_loss: 587294.6250 - val_mae: 258.0972\n",
      "Epoch 2/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 705860.5000 - mae: 272.2819 - val_loss: 583305.7500 - val_mae: 257.1278\n",
      "Epoch 3/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 654799.8750 - mae: 266.5363 - val_loss: 582279.6250 - val_mae: 257.1548\n",
      "Epoch 4/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 644802.7500 - mae: 264.7474 - val_loss: 583796.3125 - val_mae: 258.2668\n",
      "Epoch 5/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 623282.6250 - mae: 262.9471 - val_loss: 584958.6250 - val_mae: 259.7239\n",
      "Epoch 6/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 593382.4375 - mae: 259.5472 - val_loss: 587831.2500 - val_mae: 259.8277\n",
      "Epoch 7/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 575645.5625 - mae: 257.3599 - val_loss: 591748.4375 - val_mae: 260.5827\n",
      "Epoch 8/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 573516.3750 - mae: 258.3330 - val_loss: 593509.5000 - val_mae: 262.1591\n",
      "Epoch 9/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 579786.1875 - mae: 258.8806 - val_loss: 599373.6250 - val_mae: 262.0344\n",
      "Epoch 10/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 563086.1250 - mae: 256.4821 - val_loss: 601694.1875 - val_mae: 262.9473\n",
      "Processing ./db/train_bo...\n",
      "Loaded 879173 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 718947.1250 - mae: 271.9205 - val_loss: 721640.5000 - val_mae: 284.8146\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 635212.8125 - mae: 261.8250 - val_loss: 723117.6250 - val_mae: 287.0912\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 642336.2500 - mae: 260.3899 - val_loss: 726597.4375 - val_mae: 289.0037\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 578255.6250 - mae: 254.4924 - val_loss: 727731.2500 - val_mae: 287.3944\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 586523.8125 - mae: 255.1449 - val_loss: 735793.0625 - val_mae: 289.6666\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 545207.0000 - mae: 251.7406 - val_loss: 741012.0000 - val_mae: 290.9992\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 562917.1875 - mae: 252.9487 - val_loss: 746211.0000 - val_mae: 293.4821\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 527794.9375 - mae: 249.9091 - val_loss: 755182.3125 - val_mae: 296.2606\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 543215.9375 - mae: 251.8360 - val_loss: 762157.8750 - val_mae: 295.9163\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 522839.0000 - mae: 249.6746 - val_loss: 769037.0000 - val_mae: 296.8942\n",
      "Processing ./db/train_bp...\n",
      "Loaded 872904 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 844058.3125 - mae: 291.3455 - val_loss: 918289.1250 - val_mae: 292.6512\n",
      "Epoch 2/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 752819.4375 - mae: 279.4422 - val_loss: 914656.7500 - val_mae: 293.2450\n",
      "Epoch 3/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 737594.1250 - mae: 277.7457 - val_loss: 917663.2500 - val_mae: 293.2812\n",
      "Epoch 4/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 723856.1875 - mae: 277.2689 - val_loss: 919737.9375 - val_mae: 293.6883\n",
      "Epoch 5/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 698588.5000 - mae: 274.6314 - val_loss: 925650.6875 - val_mae: 295.8596\n",
      "Epoch 6/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 684280.0000 - mae: 274.3441 - val_loss: 930556.4375 - val_mae: 296.3878\n",
      "Epoch 7/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 660493.0625 - mae: 271.5112 - val_loss: 936832.2500 - val_mae: 298.1640\n",
      "Epoch 8/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 658166.2500 - mae: 272.4310 - val_loss: 941779.6250 - val_mae: 298.5689\n",
      "Epoch 9/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 640002.1875 - mae: 270.3687 - val_loss: 950404.4375 - val_mae: 300.5102\n",
      "Epoch 10/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 631272.1875 - mae: 268.7105 - val_loss: 956297.3125 - val_mae: 302.0019\n",
      "Processing ./db/train_bq...\n",
      "Loaded 872327 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 716400.8750 - mae: 281.8440 - val_loss: 781897.1875 - val_mae: 283.7409\n",
      "Epoch 2/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 639852.4375 - mae: 268.9163 - val_loss: 783711.5625 - val_mae: 283.5003\n",
      "Epoch 3/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 626425.0625 - mae: 267.6664 - val_loss: 784954.5000 - val_mae: 283.3797\n",
      "Epoch 4/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 609194.1875 - mae: 265.0851 - val_loss: 791736.3750 - val_mae: 284.9070\n",
      "Epoch 5/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 590302.5625 - mae: 263.4300 - val_loss: 796685.7500 - val_mae: 285.9865\n",
      "Epoch 6/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 594720.1250 - mae: 263.7344 - val_loss: 802008.3125 - val_mae: 286.3281\n",
      "Epoch 7/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 564195.0625 - mae: 261.0576 - val_loss: 809097.6250 - val_mae: 287.8733\n",
      "Epoch 8/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 546314.3750 - mae: 258.4301 - val_loss: 817205.3750 - val_mae: 289.6704\n",
      "Epoch 9/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 531819.8750 - mae: 257.6184 - val_loss: 821432.8750 - val_mae: 290.2009\n",
      "Epoch 10/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 523893.9688 - mae: 256.6431 - val_loss: 829017.1250 - val_mae: 291.1526\n",
      "Processing ./db/train_br...\n",
      "Loaded 879441 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 756363.5000 - mae: 275.7673 - val_loss: 640380.6250 - val_mae: 267.5061\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 673928.5625 - mae: 265.7537 - val_loss: 634770.4375 - val_mae: 267.6473\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 643168.5000 - mae: 261.9842 - val_loss: 635530.5000 - val_mae: 267.9136\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 611059.8750 - mae: 259.5891 - val_loss: 634115.8750 - val_mae: 266.8993\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 598838.4375 - mae: 257.6879 - val_loss: 637179.7500 - val_mae: 269.6972\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 587298.3750 - mae: 259.0027 - val_loss: 641518.0000 - val_mae: 271.6277\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 573377.1250 - mae: 256.3858 - val_loss: 643310.0000 - val_mae: 270.2144\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 559085.4375 - mae: 255.2149 - val_loss: 648201.0000 - val_mae: 272.4605\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 545301.8125 - mae: 254.4379 - val_loss: 652104.0625 - val_mae: 273.3994\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 517765.3438 - mae: 252.3639 - val_loss: 659161.1250 - val_mae: 275.2863\n",
      "Processing ./db/train_bs...\n",
      "Loaded 883824 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 722771.8125 - mae: 276.4916 - val_loss: 685461.6250 - val_mae: 278.4753\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 663655.3125 - mae: 268.2626 - val_loss: 681690.8125 - val_mae: 277.3328\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 616981.6875 - mae: 263.4976 - val_loss: 681366.2500 - val_mae: 277.4604\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 602693.3125 - mae: 262.5250 - val_loss: 682228.2500 - val_mae: 277.2043\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 575424.4375 - mae: 259.6005 - val_loss: 683972.0000 - val_mae: 277.5994\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 567731.8750 - mae: 258.2705 - val_loss: 687593.4375 - val_mae: 279.7773\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 551180.8125 - mae: 257.4253 - val_loss: 690457.5625 - val_mae: 279.6127\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 558231.5625 - mae: 257.3203 - val_loss: 695914.5000 - val_mae: 280.5623\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 548114.0625 - mae: 257.0860 - val_loss: 700597.1875 - val_mae: 281.2939\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 514756.5938 - mae: 253.6930 - val_loss: 704712.6875 - val_mae: 283.0455\n",
      "Processing ./db/train_bt...\n",
      "Loaded 879158 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 713718.7500 - mae: 278.1254 - val_loss: 766762.9375 - val_mae: 299.6065\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 646441.9375 - mae: 267.2294 - val_loss: 761786.5625 - val_mae: 297.6081\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 607183.6875 - mae: 262.5565 - val_loss: 764415.3125 - val_mae: 299.2635\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 612135.7500 - mae: 262.7098 - val_loss: 765878.9375 - val_mae: 298.9751\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 584497.5000 - mae: 260.3336 - val_loss: 768032.9375 - val_mae: 298.6999\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 592009.5000 - mae: 259.2434 - val_loss: 772187.0625 - val_mae: 300.6468\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 583506.8125 - mae: 259.4687 - val_loss: 776054.4375 - val_mae: 301.8617\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 560632.5000 - mae: 257.1645 - val_loss: 782400.9375 - val_mae: 304.2961\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 537291.4375 - mae: 255.3324 - val_loss: 786241.0625 - val_mae: 303.9886\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 541123.5000 - mae: 255.4820 - val_loss: 793722.5625 - val_mae: 306.7802\n",
      "Processing ./db/train_bu...\n",
      "Loaded 874926 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 759056.9375 - mae: 283.5453 - val_loss: 761037.6250 - val_mae: 293.0861\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 691533.0000 - mae: 272.4603 - val_loss: 761891.6875 - val_mae: 289.9631\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 688419.6875 - mae: 270.9650 - val_loss: 766323.1250 - val_mae: 292.6322\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 670050.8750 - mae: 268.8627 - val_loss: 771319.2500 - val_mae: 290.6384\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 630918.5000 - mae: 265.1640 - val_loss: 775274.0625 - val_mae: 292.4213\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 606846.7500 - mae: 262.6842 - val_loss: 781068.6875 - val_mae: 293.8528\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 581336.5625 - mae: 261.4277 - val_loss: 787235.8125 - val_mae: 294.3309\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 581975.5000 - mae: 261.6642 - val_loss: 793542.0000 - val_mae: 295.3107\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 574154.6875 - mae: 259.4996 - val_loss: 799259.9375 - val_mae: 297.6458\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 576359.6250 - mae: 260.4926 - val_loss: 805919.8750 - val_mae: 298.3300\n",
      "Processing ./db/train_bv...\n",
      "Loaded 876601 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 730883.6250 - mae: 278.7542 - val_loss: 650707.6250 - val_mae: 268.5427\n",
      "Epoch 2/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 633748.8750 - mae: 265.9573 - val_loss: 646995.4375 - val_mae: 266.9530\n",
      "Epoch 3/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 615154.8750 - mae: 263.8736 - val_loss: 647129.4375 - val_mae: 266.8187\n",
      "Epoch 4/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 597588.1875 - mae: 260.2112 - val_loss: 648593.3125 - val_mae: 267.4383\n",
      "Epoch 5/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 569288.0625 - mae: 258.0941 - val_loss: 651302.0000 - val_mae: 268.0704\n",
      "Epoch 6/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 560015.0625 - mae: 256.6387 - val_loss: 654124.1250 - val_mae: 269.3562\n",
      "Epoch 7/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 559545.5000 - mae: 256.0565 - val_loss: 657292.8125 - val_mae: 269.3080\n",
      "Epoch 8/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 571007.0625 - mae: 257.0589 - val_loss: 662477.1875 - val_mae: 269.3055\n",
      "Epoch 9/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 536531.1250 - mae: 253.5143 - val_loss: 666705.5000 - val_mae: 271.5621\n",
      "Epoch 10/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 538976.3750 - mae: 254.0078 - val_loss: 670281.8750 - val_mae: 271.8309\n",
      "Processing ./db/train_bw...\n",
      "Loaded 878723 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 699008.0625 - mae: 278.2367 - val_loss: 799442.8125 - val_mae: 277.1262\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 625193.4375 - mae: 266.6377 - val_loss: 796008.7500 - val_mae: 275.7914\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 626192.1875 - mae: 265.8006 - val_loss: 795507.2500 - val_mae: 275.2112\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 585230.4375 - mae: 260.4269 - val_loss: 797185.4375 - val_mae: 276.4944\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 585247.4375 - mae: 260.3216 - val_loss: 797862.6250 - val_mae: 277.5322\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 533772.9375 - mae: 255.5115 - val_loss: 799433.6875 - val_mae: 278.4596\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 554729.0625 - mae: 257.8201 - val_loss: 799944.2500 - val_mae: 278.5673\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 539004.3125 - mae: 255.6138 - val_loss: 804213.8125 - val_mae: 280.4404\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 520483.8438 - mae: 254.5256 - val_loss: 808646.3750 - val_mae: 281.4367\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 541826.8125 - mae: 255.9076 - val_loss: 815032.0625 - val_mae: 280.5922\n",
      "Processing ./db/train_bx...\n",
      "Loaded 879530 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 750768.0000 - mae: 281.1308 - val_loss: 852883.6875 - val_mae: 298.0900\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 680872.9375 - mae: 270.7744 - val_loss: 851345.8125 - val_mae: 297.7959\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 639495.8750 - mae: 267.3581 - val_loss: 852971.7500 - val_mae: 298.4799\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 618177.6875 - mae: 264.9104 - val_loss: 855710.6875 - val_mae: 299.5056\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 603900.8125 - mae: 262.7615 - val_loss: 858828.2500 - val_mae: 300.5927\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 597788.0000 - mae: 262.5389 - val_loss: 864948.4375 - val_mae: 300.3510\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 585041.6875 - mae: 260.8260 - val_loss: 870386.1875 - val_mae: 302.2007\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 569025.8750 - mae: 259.5345 - val_loss: 872649.1250 - val_mae: 302.3712\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 567223.2500 - mae: 259.4352 - val_loss: 880715.0000 - val_mae: 303.6996\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 563943.6250 - mae: 257.5061 - val_loss: 885220.0625 - val_mae: 304.0022\n",
      "Processing ./db/train_by...\n",
      "Loaded 881272 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 714120.8125 - mae: 274.5353 - val_loss: 742453.4375 - val_mae: 278.8599\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 629109.3125 - mae: 262.5000 - val_loss: 740967.9375 - val_mae: 278.2249\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 615926.1250 - mae: 260.6325 - val_loss: 743083.5625 - val_mae: 278.0120\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 584350.7500 - mae: 257.5790 - val_loss: 746974.9375 - val_mae: 279.5940\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 591088.6875 - mae: 257.7023 - val_loss: 751421.9375 - val_mae: 280.3569\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 572874.3125 - mae: 256.1118 - val_loss: 756194.4375 - val_mae: 282.3493\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 574463.5000 - mae: 254.8096 - val_loss: 759663.3750 - val_mae: 281.9537\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 557382.3125 - mae: 254.1677 - val_loss: 766236.3750 - val_mae: 282.9522\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 543889.4375 - mae: 253.0588 - val_loss: 770821.0625 - val_mae: 283.7028\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 515784.0938 - mae: 251.0867 - val_loss: 776219.5625 - val_mae: 284.9552\n",
      "Processing ./db/train_bz...\n",
      "Loaded 879370 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 721583.6250 - mae: 267.1184 - val_loss: 652573.1250 - val_mae: 269.9868\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 582747.5625 - mae: 257.6429 - val_loss: 649792.1875 - val_mae: 270.6180\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 585369.4375 - mae: 257.1277 - val_loss: 648892.6250 - val_mae: 270.0096\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 526408.5625 - mae: 253.7719 - val_loss: 649665.4375 - val_mae: 269.6823\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 524021.5312 - mae: 252.7225 - val_loss: 651217.4375 - val_mae: 269.1566\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 515406.3125 - mae: 250.4335 - val_loss: 654526.5625 - val_mae: 269.6546\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 511912.5938 - mae: 249.4601 - val_loss: 656603.8750 - val_mae: 271.7254\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 497204.0312 - mae: 247.9030 - val_loss: 659783.2500 - val_mae: 274.1187\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 499242.0000 - mae: 248.3354 - val_loss: 662932.9375 - val_mae: 271.7462\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 476438.7812 - mae: 245.9754 - val_loss: 665089.8125 - val_mae: 274.3280\n",
      "Processing ./db/train_ca...\n",
      "Loaded 877968 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 716371.6250 - mae: 277.7064 - val_loss: 813896.7500 - val_mae: 276.1396\n",
      "Epoch 2/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 671276.1875 - mae: 268.7291 - val_loss: 812626.1875 - val_mae: 276.4255\n",
      "Epoch 3/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 613132.4375 - mae: 263.9832 - val_loss: 812691.8750 - val_mae: 275.6813\n",
      "Epoch 4/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 621021.3125 - mae: 263.0403 - val_loss: 814056.1875 - val_mae: 276.2812\n",
      "Epoch 5/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 613352.8125 - mae: 262.2019 - val_loss: 816911.5625 - val_mae: 277.2436\n",
      "Epoch 6/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 618771.5625 - mae: 262.5590 - val_loss: 820563.0000 - val_mae: 277.9338\n",
      "Epoch 7/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 566877.8125 - mae: 256.8283 - val_loss: 824947.8750 - val_mae: 279.6481\n",
      "Epoch 8/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 588252.3125 - mae: 259.5449 - val_loss: 829396.0000 - val_mae: 280.5087\n",
      "Epoch 9/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 563637.7500 - mae: 257.4525 - val_loss: 835489.0000 - val_mae: 281.3805\n",
      "Epoch 10/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 534451.0000 - mae: 255.4731 - val_loss: 842453.0000 - val_mae: 282.3361\n",
      "Processing ./db/train_cb...\n",
      "Loaded 875647 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 806373.2500 - mae: 286.6139 - val_loss: 840942.2500 - val_mae: 285.0912\n",
      "Epoch 2/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 742801.1250 - mae: 278.4525 - val_loss: 837051.5625 - val_mae: 284.7166\n",
      "Epoch 3/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 700218.5000 - mae: 273.4055 - val_loss: 837822.4375 - val_mae: 286.1487\n",
      "Epoch 4/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 662281.6875 - mae: 270.2013 - val_loss: 837901.3125 - val_mae: 286.1943\n",
      "Epoch 5/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 673548.5000 - mae: 270.4060 - val_loss: 841080.7500 - val_mae: 286.9674\n",
      "Epoch 6/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 635773.3750 - mae: 267.5174 - val_loss: 844803.5000 - val_mae: 288.5627\n",
      "Epoch 7/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 629491.2500 - mae: 267.4092 - val_loss: 848160.9375 - val_mae: 289.6389\n",
      "Epoch 8/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 623372.5625 - mae: 267.0829 - val_loss: 852388.8750 - val_mae: 290.3967\n",
      "Epoch 9/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 597768.9375 - mae: 265.4840 - val_loss: 858795.6250 - val_mae: 292.5588\n",
      "Epoch 10/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 601939.0000 - mae: 264.5818 - val_loss: 862325.9375 - val_mae: 293.0103\n",
      "Processing ./db/train_cc...\n",
      "Loaded 873812 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 758900.3750 - mae: 283.6190 - val_loss: 710545.6250 - val_mae: 280.5772\n",
      "Epoch 2/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 683927.1875 - mae: 272.4839 - val_loss: 707875.0625 - val_mae: 278.5598\n",
      "Epoch 3/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 648176.0000 - mae: 267.9554 - val_loss: 707706.5000 - val_mae: 278.5620\n",
      "Epoch 4/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 624019.2500 - mae: 264.5376 - val_loss: 709436.8750 - val_mae: 279.9244\n",
      "Epoch 5/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 601495.6875 - mae: 261.7497 - val_loss: 710855.5000 - val_mae: 279.6387\n",
      "Epoch 6/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 584434.3125 - mae: 261.2772 - val_loss: 713327.5000 - val_mae: 279.4021\n",
      "Epoch 7/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 599402.3125 - mae: 261.3407 - val_loss: 716763.1250 - val_mae: 280.5450\n",
      "Epoch 8/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 545154.7500 - mae: 257.4261 - val_loss: 719281.1250 - val_mae: 280.3596\n",
      "Epoch 9/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 562598.0625 - mae: 257.8801 - val_loss: 724599.2500 - val_mae: 283.5236\n",
      "Epoch 10/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 563720.3750 - mae: 258.9087 - val_loss: 729232.4375 - val_mae: 282.9338\n",
      "Processing ./db/train_cd...\n",
      "Loaded 877154 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 722868.9375 - mae: 276.3952 - val_loss: 663134.0000 - val_mae: 264.0063\n",
      "Epoch 2/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 623097.8125 - mae: 265.9206 - val_loss: 663427.8125 - val_mae: 263.7881\n",
      "Epoch 3/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 613850.8750 - mae: 262.7240 - val_loss: 665344.5625 - val_mae: 264.5735\n",
      "Epoch 4/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 587787.0625 - mae: 260.2001 - val_loss: 667986.9375 - val_mae: 265.3623\n",
      "Epoch 5/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595230.1875 - mae: 260.8943 - val_loss: 672276.4375 - val_mae: 265.9371\n",
      "Epoch 6/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 587640.4375 - mae: 259.1626 - val_loss: 675357.1875 - val_mae: 266.7980\n",
      "Epoch 7/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 540523.9375 - mae: 254.7717 - val_loss: 679561.1875 - val_mae: 268.4846\n",
      "Epoch 8/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 579330.3125 - mae: 258.1105 - val_loss: 682045.8125 - val_mae: 267.8878\n",
      "Epoch 9/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 536268.9375 - mae: 253.4888 - val_loss: 686455.8750 - val_mae: 268.7182\n",
      "Epoch 10/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 525331.7500 - mae: 254.2016 - val_loss: 691909.1250 - val_mae: 270.0394\n",
      "Processing ./db/train_ce...\n",
      "Loaded 880793 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 760618.6250 - mae: 276.8215 - val_loss: 769140.6875 - val_mae: 272.1203\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 671615.6875 - mae: 267.9825 - val_loss: 766621.0000 - val_mae: 272.5917\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 662356.1250 - mae: 266.7686 - val_loss: 768329.6875 - val_mae: 273.5613\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 636788.8125 - mae: 265.0234 - val_loss: 770609.3750 - val_mae: 274.4013\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 632149.0625 - mae: 264.6491 - val_loss: 772518.0000 - val_mae: 274.7323\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 618146.0625 - mae: 262.3543 - val_loss: 776762.0625 - val_mae: 276.9864\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 604117.0625 - mae: 261.9291 - val_loss: 779474.0000 - val_mae: 276.5455\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 565981.4375 - mae: 259.1954 - val_loss: 784204.7500 - val_mae: 277.8010\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 570348.5000 - mae: 259.7828 - val_loss: 787271.3125 - val_mae: 278.9155\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 560098.5625 - mae: 258.4144 - val_loss: 790206.0625 - val_mae: 278.8330\n",
      "Processing ./db/train_cf...\n",
      "Loaded 879641 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 768692.0000 - mae: 282.9037 - val_loss: 1033974.0000 - val_mae: 317.0968\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 667669.9375 - mae: 270.2672 - val_loss: 1031011.5000 - val_mae: 316.5764\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 662651.6875 - mae: 268.6850 - val_loss: 1036120.3750 - val_mae: 320.5699\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 614229.8125 - mae: 264.9990 - val_loss: 1035422.1875 - val_mae: 319.6568\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 622730.4375 - mae: 265.7968 - val_loss: 1038193.9375 - val_mae: 318.9391\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 638993.6875 - mae: 265.9474 - val_loss: 1042301.8125 - val_mae: 320.3951\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 599711.7500 - mae: 262.2915 - val_loss: 1049655.7500 - val_mae: 322.4917\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 592208.3125 - mae: 261.7859 - val_loss: 1055380.3750 - val_mae: 324.3691\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 576253.1875 - mae: 260.5103 - val_loss: 1059217.7500 - val_mae: 325.0089\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 574067.2500 - mae: 260.3836 - val_loss: 1063849.1250 - val_mae: 325.1208\n",
      "Processing ./db/train_cg...\n",
      "Loaded 882150 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 970057.9375 - mae: 285.0746 - val_loss: 751419.2500 - val_mae: 276.5045\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 682107.9375 - mae: 272.1400 - val_loss: 750190.6250 - val_mae: 275.9588\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 633741.3750 - mae: 268.1622 - val_loss: 749997.0625 - val_mae: 275.9391\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 643612.1875 - mae: 267.8505 - val_loss: 752845.8125 - val_mae: 274.8872\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 589352.3125 - mae: 263.1700 - val_loss: 752325.5000 - val_mae: 275.1248\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 567413.1250 - mae: 261.2263 - val_loss: 756233.6875 - val_mae: 275.1348\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 573222.1250 - mae: 260.4628 - val_loss: 759083.5000 - val_mae: 276.3035\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 567255.6250 - mae: 258.3066 - val_loss: 760965.8750 - val_mae: 276.0456\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 535056.0000 - mae: 256.4552 - val_loss: 766057.8125 - val_mae: 276.8774\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 538154.6250 - mae: 256.6558 - val_loss: 769085.4375 - val_mae: 277.8241\n",
      "Processing ./db/train_ch...\n",
      "Loaded 882837 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 806792.8125 - mae: 282.0040 - val_loss: 707742.0000 - val_mae: 275.7954\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 764004.0625 - mae: 275.9883 - val_loss: 706655.0000 - val_mae: 277.4985\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 734602.3125 - mae: 273.3097 - val_loss: 707167.5625 - val_mae: 276.8196\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 689847.1250 - mae: 270.0978 - val_loss: 708910.8125 - val_mae: 277.3187\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 671102.3125 - mae: 268.1322 - val_loss: 712378.0625 - val_mae: 277.9990\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 649400.7500 - mae: 265.8481 - val_loss: 716998.5625 - val_mae: 279.0007\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 632343.8125 - mae: 265.2800 - val_loss: 723117.6250 - val_mae: 280.0450\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 633967.5000 - mae: 265.1349 - val_loss: 725677.5000 - val_mae: 279.8595\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 625957.5625 - mae: 263.1613 - val_loss: 731747.4375 - val_mae: 283.4770\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 617913.8125 - mae: 263.6187 - val_loss: 737045.1875 - val_mae: 282.2170\n",
      "Processing ./db/train_ci...\n",
      "Loaded 885710 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 847698.1875 - mae: 279.3009 - val_loss: 630297.3750 - val_mae: 264.4014\n",
      "Epoch 2/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 679096.6250 - mae: 267.8834 - val_loss: 618936.6875 - val_mae: 264.0652\n",
      "Epoch 3/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 611922.3125 - mae: 262.4299 - val_loss: 616906.1875 - val_mae: 263.9712\n",
      "Epoch 4/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 622108.3750 - mae: 262.5455 - val_loss: 615376.9375 - val_mae: 263.5440\n",
      "Epoch 5/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 614224.5625 - mae: 260.8250 - val_loss: 617493.6250 - val_mae: 264.2375\n",
      "Epoch 6/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595847.3750 - mae: 259.1277 - val_loss: 618734.7500 - val_mae: 264.8789\n",
      "Epoch 7/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 596092.0000 - mae: 258.6282 - val_loss: 622538.2500 - val_mae: 265.9912\n",
      "Epoch 8/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 591815.1250 - mae: 258.5204 - val_loss: 625403.3750 - val_mae: 267.4472\n",
      "Epoch 9/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 566184.5625 - mae: 256.7162 - val_loss: 628429.2500 - val_mae: 267.2420\n",
      "Epoch 10/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 583650.8125 - mae: 258.2262 - val_loss: 629330.3125 - val_mae: 266.5530\n",
      "Processing ./db/train_cj...\n",
      "Loaded 887500 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 711559.2500 - mae: 273.4012 - val_loss: 686949.4375 - val_mae: 281.6512\n",
      "Epoch 2/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 617896.4375 - mae: 261.9768 - val_loss: 683372.8750 - val_mae: 280.5769\n",
      "Epoch 3/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 610497.6875 - mae: 260.3968 - val_loss: 683542.8750 - val_mae: 281.1546\n",
      "Epoch 4/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 604886.0625 - mae: 258.4576 - val_loss: 687200.3125 - val_mae: 282.5537\n",
      "Epoch 5/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 566876.4375 - mae: 256.7683 - val_loss: 689851.8125 - val_mae: 283.6155\n",
      "Epoch 6/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 582934.6250 - mae: 256.7899 - val_loss: 691643.1250 - val_mae: 283.6223\n",
      "Epoch 7/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 549463.5000 - mae: 253.9077 - val_loss: 695815.8750 - val_mae: 284.0743\n",
      "Epoch 8/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 559128.7500 - mae: 254.2562 - val_loss: 699736.0000 - val_mae: 285.5137\n",
      "Epoch 9/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 542058.2500 - mae: 253.7228 - val_loss: 704042.3750 - val_mae: 286.7147\n",
      "Epoch 10/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 541263.4375 - mae: 252.9076 - val_loss: 709696.5000 - val_mae: 288.6256\n",
      "Processing ./db/train_ck...\n",
      "Loaded 881943 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 806060.3125 - mae: 274.8371 - val_loss: 691272.1875 - val_mae: 273.9764\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 667815.2500 - mae: 264.0698 - val_loss: 690928.0625 - val_mae: 274.0146\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 651672.8750 - mae: 262.9187 - val_loss: 691731.0625 - val_mae: 278.2536\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 644314.8750 - mae: 262.0665 - val_loss: 693115.4375 - val_mae: 275.3318\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 621681.0000 - mae: 259.7316 - val_loss: 695753.6250 - val_mae: 277.0846\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 602418.0625 - mae: 258.9888 - val_loss: 700126.0000 - val_mae: 278.7001\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 596179.7500 - mae: 257.5747 - val_loss: 705969.0625 - val_mae: 282.6573\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 578733.6250 - mae: 257.2545 - val_loss: 710155.9375 - val_mae: 280.1324\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 552566.3125 - mae: 253.8721 - val_loss: 714639.8750 - val_mae: 282.3459\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 548806.2500 - mae: 254.2613 - val_loss: 719595.1875 - val_mae: 281.8748\n",
      "Processing ./db/train_cl...\n",
      "Loaded 883037 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 714211.8750 - mae: 272.5934 - val_loss: 683282.3125 - val_mae: 276.6579\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 636860.8125 - mae: 263.2158 - val_loss: 684259.8750 - val_mae: 277.0327\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 606466.8750 - mae: 260.5721 - val_loss: 687799.5625 - val_mae: 276.8432\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 589122.1250 - mae: 259.1959 - val_loss: 692710.5625 - val_mae: 278.4604\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 560231.3125 - mae: 256.0883 - val_loss: 697921.1875 - val_mae: 279.2869\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 548549.1250 - mae: 254.5958 - val_loss: 703592.6250 - val_mae: 279.7101\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 548806.0000 - mae: 255.6429 - val_loss: 711085.5625 - val_mae: 280.8304\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 530307.8125 - mae: 253.8130 - val_loss: 720277.9375 - val_mae: 281.4834\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 541063.3750 - mae: 254.3263 - val_loss: 728726.4375 - val_mae: 283.4012\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 520314.1875 - mae: 253.0104 - val_loss: 735390.0625 - val_mae: 283.5970\n",
      "Processing ./db/train_cm...\n",
      "Loaded 880163 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 738679.8750 - mae: 277.5800 - val_loss: 629068.6250 - val_mae: 263.6104\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 640496.8750 - mae: 264.8734 - val_loss: 627496.0625 - val_mae: 264.6903\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 645578.3125 - mae: 264.5337 - val_loss: 627504.0000 - val_mae: 265.2690\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 625486.2500 - mae: 263.6735 - val_loss: 628776.9375 - val_mae: 265.9825\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 633235.6875 - mae: 264.0475 - val_loss: 630703.0000 - val_mae: 265.8938\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595155.9375 - mae: 260.0933 - val_loss: 634098.0625 - val_mae: 266.3840\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 588849.1250 - mae: 259.9039 - val_loss: 637864.3750 - val_mae: 267.7040\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 571389.1250 - mae: 258.4455 - val_loss: 640665.5000 - val_mae: 268.2399\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 561410.3125 - mae: 258.2663 - val_loss: 643857.8125 - val_mae: 269.1212\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 567342.8750 - mae: 258.6694 - val_loss: 647996.3750 - val_mae: 269.2877\n",
      "Processing ./db/train_cn...\n",
      "Loaded 880379 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 780330.7500 - mae: 283.3045 - val_loss: 639882.5000 - val_mae: 265.5899\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 702276.3125 - mae: 272.8844 - val_loss: 639381.5625 - val_mae: 266.6516\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 649225.6875 - mae: 268.3853 - val_loss: 642914.4375 - val_mae: 267.9783\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 635930.8125 - mae: 266.5299 - val_loss: 646225.2500 - val_mae: 268.7766\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 619396.5000 - mae: 266.1934 - val_loss: 648770.6875 - val_mae: 269.0703\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 605554.9375 - mae: 263.7227 - val_loss: 654714.2500 - val_mae: 270.7904\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 603574.5000 - mae: 264.6628 - val_loss: 658870.3125 - val_mae: 271.2468\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 581224.1250 - mae: 262.2932 - val_loss: 661339.5625 - val_mae: 271.6017\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 566272.6250 - mae: 260.9751 - val_loss: 666806.1875 - val_mae: 272.2442\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 561611.5000 - mae: 261.1563 - val_loss: 670217.0625 - val_mae: 273.3268\n",
      "Processing ./db/train_co...\n",
      "Loaded 880758 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 783808.3750 - mae: 281.7433 - val_loss: 660731.2500 - val_mae: 270.9827\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 695717.3125 - mae: 272.3802 - val_loss: 655763.5000 - val_mae: 268.6016\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 653488.1875 - mae: 267.6711 - val_loss: 654752.1875 - val_mae: 269.8007\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 663521.6250 - mae: 267.9221 - val_loss: 657883.5625 - val_mae: 271.3704\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 623510.5000 - mae: 265.0085 - val_loss: 659629.7500 - val_mae: 271.5433\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 620852.0000 - mae: 263.6153 - val_loss: 661210.5000 - val_mae: 273.6241\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 596692.6875 - mae: 263.2964 - val_loss: 664628.1875 - val_mae: 272.7347\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 609522.6250 - mae: 263.0287 - val_loss: 668272.1875 - val_mae: 273.9155\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 600684.7500 - mae: 262.2779 - val_loss: 670094.8125 - val_mae: 274.5975\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 582048.3125 - mae: 261.5542 - val_loss: 674569.4375 - val_mae: 275.4313\n",
      "Processing ./db/train_cp...\n",
      "Loaded 884859 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 747247.6250 - mae: 276.9313 - val_loss: 816395.0000 - val_mae: 270.9955\n",
      "Epoch 2/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595769.7500 - mae: 265.5876 - val_loss: 809331.1875 - val_mae: 269.8374\n",
      "Epoch 3/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 565058.8125 - mae: 262.3597 - val_loss: 810723.5000 - val_mae: 270.1911\n",
      "Epoch 4/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 543961.0000 - mae: 260.3574 - val_loss: 816913.3125 - val_mae: 270.3728\n",
      "Epoch 5/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 550879.9375 - mae: 259.9553 - val_loss: 825246.9375 - val_mae: 271.0096\n",
      "Epoch 6/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 520562.3125 - mae: 256.9115 - val_loss: 826273.8125 - val_mae: 270.7876\n",
      "Epoch 7/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 533512.7500 - mae: 258.7195 - val_loss: 834886.9375 - val_mae: 273.2148\n",
      "Epoch 8/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 521534.4062 - mae: 257.0053 - val_loss: 845296.0625 - val_mae: 272.0880\n",
      "Epoch 9/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 507057.5312 - mae: 255.3280 - val_loss: 856795.5625 - val_mae: 277.9547\n",
      "Epoch 10/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 497211.3438 - mae: 255.3014 - val_loss: 860788.0625 - val_mae: 273.6167\n",
      "Processing ./db/train_cq...\n",
      "Loaded 875134 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 690743.5000 - mae: 273.9709 - val_loss: 661805.2500 - val_mae: 272.1185\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 648746.7500 - mae: 266.0873 - val_loss: 660849.5000 - val_mae: 272.0019\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 604506.3750 - mae: 262.0435 - val_loss: 661277.5000 - val_mae: 273.1241\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 623704.1875 - mae: 261.7810 - val_loss: 663887.1250 - val_mae: 273.5004\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 587226.7500 - mae: 259.2009 - val_loss: 665346.0625 - val_mae: 274.3015\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 577686.3125 - mae: 258.3021 - val_loss: 668166.3125 - val_mae: 273.8772\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 565826.0625 - mae: 258.2150 - val_loss: 671929.5000 - val_mae: 275.7568\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 548908.5000 - mae: 257.2023 - val_loss: 675548.4375 - val_mae: 276.4560\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 549068.6250 - mae: 256.1776 - val_loss: 678888.4375 - val_mae: 277.0590\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 567206.6875 - mae: 257.6672 - val_loss: 684437.6875 - val_mae: 276.9668\n",
      "Processing ./db/train_cr...\n",
      "Loaded 874970 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 763685.1250 - mae: 280.8324 - val_loss: 651137.0625 - val_mae: 268.3837\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 692049.0625 - mae: 272.4595 - val_loss: 652496.8125 - val_mae: 269.4412\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 668481.2500 - mae: 270.1788 - val_loss: 654091.8125 - val_mae: 269.3894\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 655766.5625 - mae: 268.5050 - val_loss: 658317.7500 - val_mae: 270.5733\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 634842.0000 - mae: 266.5490 - val_loss: 661861.8750 - val_mae: 274.3974\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 609498.1875 - mae: 265.2291 - val_loss: 663869.1875 - val_mae: 272.8173\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 622623.0000 - mae: 265.2329 - val_loss: 667218.9375 - val_mae: 273.3695\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 621869.1875 - mae: 265.0790 - val_loss: 667405.1875 - val_mae: 273.1051\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 590910.7500 - mae: 262.9238 - val_loss: 673404.2500 - val_mae: 276.5500\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 591386.2500 - mae: 263.1361 - val_loss: 674833.6875 - val_mae: 276.2272\n",
      "Processing ./db/train_cs...\n",
      "Loaded 879748 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 822593.8125 - mae: 286.2552 - val_loss: 694552.0625 - val_mae: 264.3768\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 708558.3750 - mae: 276.1538 - val_loss: 693850.3125 - val_mae: 263.8204\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 702372.8750 - mae: 274.3838 - val_loss: 696731.0625 - val_mae: 263.0402\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 689387.8750 - mae: 272.2856 - val_loss: 695705.6875 - val_mae: 264.3414\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 674952.7500 - mae: 270.7986 - val_loss: 701716.8750 - val_mae: 264.6448\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 636922.5000 - mae: 268.4461 - val_loss: 705445.8750 - val_mae: 265.6736\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 646745.1250 - mae: 269.3807 - val_loss: 705712.8750 - val_mae: 266.1891\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 637126.5625 - mae: 267.3413 - val_loss: 712070.8125 - val_mae: 266.8671\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 599893.0000 - mae: 265.8598 - val_loss: 716324.7500 - val_mae: 267.8400\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 617145.5625 - mae: 266.2169 - val_loss: 720149.3750 - val_mae: 267.8440\n",
      "Processing ./db/train_ct...\n",
      "Loaded 883696 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 628017.3750 - mae: 266.7042 - val_loss: 689696.1250 - val_mae: 272.8014\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 586202.0625 - mae: 258.4078 - val_loss: 687965.5625 - val_mae: 272.0574\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 578176.0000 - mae: 257.7411 - val_loss: 689177.8125 - val_mae: 273.7643\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 533995.0000 - mae: 253.8895 - val_loss: 692386.0625 - val_mae: 273.8061\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 536120.1875 - mae: 252.8888 - val_loss: 693785.0000 - val_mae: 275.3986\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 515117.7812 - mae: 251.7583 - val_loss: 694735.0625 - val_mae: 276.5863\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 534807.2500 - mae: 253.0982 - val_loss: 698155.8125 - val_mae: 275.4709\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 510575.3125 - mae: 251.2715 - val_loss: 700565.3125 - val_mae: 275.8368\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 509738.3125 - mae: 250.8519 - val_loss: 705234.9375 - val_mae: 277.6391\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 506707.2188 - mae: 251.4868 - val_loss: 709621.0625 - val_mae: 277.5352\n",
      "Processing ./db/train_cu...\n",
      "Loaded 881247 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 743455.5625 - mae: 278.2842 - val_loss: 833886.5625 - val_mae: 290.3353\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 678804.3125 - mae: 270.8685 - val_loss: 833976.3750 - val_mae: 289.5995\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 671445.2500 - mae: 269.4427 - val_loss: 836478.0000 - val_mae: 290.9839\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 652852.0000 - mae: 268.4539 - val_loss: 840123.8125 - val_mae: 291.5009\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 620366.3750 - mae: 263.9008 - val_loss: 844864.0000 - val_mae: 294.3976\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 658231.1875 - mae: 268.5727 - val_loss: 850469.8125 - val_mae: 293.1367\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 635079.0000 - mae: 265.3469 - val_loss: 853754.7500 - val_mae: 294.7009\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 607358.5000 - mae: 263.4688 - val_loss: 859480.9375 - val_mae: 297.1059\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 614721.6875 - mae: 264.3692 - val_loss: 863730.5625 - val_mae: 296.7154\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 606285.5625 - mae: 263.5497 - val_loss: 868803.2500 - val_mae: 297.5252\n",
      "Processing ./db/train_cv...\n",
      "Loaded 879183 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 815264.2500 - mae: 283.2758 - val_loss: 731128.3750 - val_mae: 278.5623\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 726393.6875 - mae: 274.2923 - val_loss: 728510.4375 - val_mae: 279.5715\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 673602.1875 - mae: 270.3643 - val_loss: 736221.5000 - val_mae: 299.8413\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 675221.5000 - mae: 273.1336 - val_loss: 731358.3125 - val_mae: 282.7773\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 672251.3125 - mae: 270.0950 - val_loss: 734664.5000 - val_mae: 280.8726\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 652339.8750 - mae: 268.5487 - val_loss: 736313.8125 - val_mae: 282.2673\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 641496.6875 - mae: 267.6396 - val_loss: 740740.6250 - val_mae: 282.7175\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 623935.7500 - mae: 265.7334 - val_loss: 741378.8125 - val_mae: 284.3403\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 620653.0000 - mae: 266.0000 - val_loss: 745128.1250 - val_mae: 284.4739\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 607408.3750 - mae: 264.4851 - val_loss: 749934.1875 - val_mae: 285.5267\n",
      "Processing ./db/train_cw...\n",
      "Loaded 882602 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 850291.9375 - mae: 287.4359 - val_loss: 738544.0000 - val_mae: 274.8593\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 747375.5000 - mae: 276.9769 - val_loss: 741801.5625 - val_mae: 275.7187\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 726487.3750 - mae: 276.0507 - val_loss: 746586.9375 - val_mae: 276.7239\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 718954.4375 - mae: 274.8810 - val_loss: 752496.4375 - val_mae: 277.3453\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 674977.6250 - mae: 272.3681 - val_loss: 755689.0000 - val_mae: 278.6786\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 641566.1875 - mae: 269.6743 - val_loss: 759354.8125 - val_mae: 278.3482\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 643250.1875 - mae: 268.6338 - val_loss: 763743.1250 - val_mae: 280.3400\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 649795.0625 - mae: 270.5883 - val_loss: 767170.3750 - val_mae: 281.1390\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 621224.6250 - mae: 266.8771 - val_loss: 772319.3750 - val_mae: 283.0452\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 615523.8125 - mae: 266.7421 - val_loss: 774123.3125 - val_mae: 282.4357\n",
      "Processing ./db/train_cx...\n",
      "Loaded 885179 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 657622.2500 - mae: 270.7046 - val_loss: 793827.7500 - val_mae: 283.6465\n",
      "Epoch 2/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 587419.2500 - mae: 260.7640 - val_loss: 787468.0625 - val_mae: 284.6529\n",
      "Epoch 3/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 571026.0625 - mae: 258.7046 - val_loss: 788176.8750 - val_mae: 283.7799\n",
      "Epoch 4/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 588566.9375 - mae: 259.5421 - val_loss: 789242.4375 - val_mae: 284.5397\n",
      "Epoch 5/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 567255.3750 - mae: 258.0120 - val_loss: 792202.6250 - val_mae: 284.2895\n",
      "Epoch 6/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 544018.1875 - mae: 255.1796 - val_loss: 796181.9375 - val_mae: 288.0143\n",
      "Epoch 7/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 531230.6875 - mae: 253.5308 - val_loss: 798981.2500 - val_mae: 286.8524\n",
      "Epoch 8/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 538612.5000 - mae: 254.2460 - val_loss: 802903.7500 - val_mae: 287.3803\n",
      "Epoch 9/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 515800.1250 - mae: 252.3233 - val_loss: 807737.6875 - val_mae: 288.0144\n",
      "Epoch 10/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 506965.2188 - mae: 251.0413 - val_loss: 810508.6250 - val_mae: 287.7800\n",
      "Processing ./db/train_cy...\n",
      "Loaded 878837 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 696499.8125 - mae: 276.1182 - val_loss: 721738.3125 - val_mae: 282.5804\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 687428.0625 - mae: 273.6166 - val_loss: 723041.8750 - val_mae: 282.9844\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 625662.3125 - mae: 269.2127 - val_loss: 724425.9375 - val_mae: 283.0711\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 640658.2500 - mae: 269.6313 - val_loss: 728075.2500 - val_mae: 282.9327\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 613071.3750 - mae: 266.0086 - val_loss: 730819.1250 - val_mae: 284.2677\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 607833.5625 - mae: 266.1029 - val_loss: 735937.5625 - val_mae: 285.9483\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 614463.6875 - mae: 265.9084 - val_loss: 740537.0625 - val_mae: 286.9880\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 593471.8750 - mae: 265.1133 - val_loss: 744012.1250 - val_mae: 287.9091\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 604573.1875 - mae: 265.3893 - val_loss: 749565.3125 - val_mae: 288.3564\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 586859.1250 - mae: 264.4417 - val_loss: 755109.2500 - val_mae: 288.9552\n",
      "Processing ./db/train_cz...\n",
      "Loaded 887218 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 697963.7500 - mae: 275.8376 - val_loss: 631381.1875 - val_mae: 259.9178\n",
      "Epoch 2/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 654968.6875 - mae: 267.3175 - val_loss: 628070.6875 - val_mae: 259.5648\n",
      "Epoch 3/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 629292.1250 - mae: 265.5271 - val_loss: 628720.0625 - val_mae: 260.1625\n",
      "Epoch 4/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 614728.3125 - mae: 263.2061 - val_loss: 630470.4375 - val_mae: 260.8936\n",
      "Epoch 5/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 591009.6875 - mae: 261.2414 - val_loss: 631879.9375 - val_mae: 260.2281\n",
      "Epoch 6/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 587546.6250 - mae: 260.7467 - val_loss: 633823.0000 - val_mae: 261.3290\n",
      "Epoch 7/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 598646.5625 - mae: 262.3054 - val_loss: 634623.3750 - val_mae: 261.8527\n",
      "Epoch 8/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 544452.0000 - mae: 256.8628 - val_loss: 637579.8125 - val_mae: 263.0338\n",
      "Epoch 9/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 563072.0625 - mae: 259.5179 - val_loss: 640338.1250 - val_mae: 263.4104\n",
      "Epoch 10/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 567710.6875 - mae: 258.6924 - val_loss: 642946.7500 - val_mae: 263.3624\n",
      "Processing ./db/train_da...\n",
      "Loaded 886974 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 716941.3125 - mae: 277.0005 - val_loss: 786908.1875 - val_mae: 276.1228\n",
      "Epoch 2/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 643295.3750 - mae: 267.1520 - val_loss: 785121.6250 - val_mae: 276.7933\n",
      "Epoch 3/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 658558.1250 - mae: 268.5476 - val_loss: 785788.3750 - val_mae: 277.1571\n",
      "Epoch 4/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 601417.9375 - mae: 263.4673 - val_loss: 787291.8750 - val_mae: 277.1340\n",
      "Epoch 5/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 604991.6250 - mae: 264.1848 - val_loss: 789294.5625 - val_mae: 277.4949\n",
      "Epoch 6/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 600214.1875 - mae: 263.3000 - val_loss: 790742.5625 - val_mae: 277.0894\n",
      "Epoch 7/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 599686.0625 - mae: 263.6014 - val_loss: 792630.3125 - val_mae: 278.7519\n",
      "Epoch 8/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 576974.8125 - mae: 261.3371 - val_loss: 795284.0625 - val_mae: 280.6898\n",
      "Epoch 9/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 558606.6250 - mae: 260.6773 - val_loss: 798020.0000 - val_mae: 281.1527\n",
      "Epoch 10/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 545822.8750 - mae: 259.5039 - val_loss: 801044.9375 - val_mae: 281.4597\n",
      "Processing ./db/train_db...\n",
      "Loaded 886622 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 730514.5000 - mae: 275.0307 - val_loss: 781036.3750 - val_mae: 290.6246\n",
      "Epoch 2/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 658852.0000 - mae: 266.5129 - val_loss: 773407.6875 - val_mae: 284.7849\n",
      "Epoch 3/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 650954.5000 - mae: 264.9750 - val_loss: 774007.5000 - val_mae: 285.1547\n",
      "Epoch 4/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 602113.9375 - mae: 261.7654 - val_loss: 778516.9375 - val_mae: 286.0371\n",
      "Epoch 5/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 599445.2500 - mae: 261.4699 - val_loss: 782747.8125 - val_mae: 286.4206\n",
      "Epoch 6/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 597354.2500 - mae: 261.8290 - val_loss: 790907.6250 - val_mae: 287.9838\n",
      "Epoch 7/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595985.3750 - mae: 261.2331 - val_loss: 797854.3750 - val_mae: 289.8317\n",
      "Epoch 8/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 566585.6250 - mae: 258.1599 - val_loss: 807610.9375 - val_mae: 289.8221\n",
      "Epoch 9/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 577433.1250 - mae: 259.6471 - val_loss: 815271.2500 - val_mae: 291.3628\n",
      "Epoch 10/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 560968.7500 - mae: 258.4952 - val_loss: 825242.8125 - val_mae: 292.3102\n",
      "Processing ./db/train_dc...\n",
      "Loaded 881802 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 659452.7500 - mae: 271.5244 - val_loss: 906974.0000 - val_mae: 302.6091\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 657264.5625 - mae: 266.5106 - val_loss: 905322.5625 - val_mae: 301.6841\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 594975.8750 - mae: 261.3052 - val_loss: 908852.1875 - val_mae: 302.6054\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595440.1250 - mae: 261.0663 - val_loss: 914169.8125 - val_mae: 302.5413\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595691.6250 - mae: 261.1176 - val_loss: 916787.2500 - val_mae: 304.2182\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 560036.0625 - mae: 257.6783 - val_loss: 922555.7500 - val_mae: 305.8988\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 553139.6875 - mae: 257.8086 - val_loss: 930206.9375 - val_mae: 307.3524\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 555007.1250 - mae: 257.1762 - val_loss: 936052.5625 - val_mae: 306.4729\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 535526.8125 - mae: 256.0059 - val_loss: 939466.3750 - val_mae: 310.0626\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 542812.0000 - mae: 255.9357 - val_loss: 944570.8125 - val_mae: 309.2652\n",
      "Processing ./db/train_dd...\n",
      "Loaded 884871 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 724905.5625 - mae: 277.9346 - val_loss: 641384.5000 - val_mae: 271.0875\n",
      "Epoch 2/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 667398.6875 - mae: 269.6762 - val_loss: 636784.8750 - val_mae: 270.8868\n",
      "Epoch 3/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 628481.3125 - mae: 264.4352 - val_loss: 636403.8750 - val_mae: 272.3548\n",
      "Epoch 4/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 618305.5625 - mae: 263.2689 - val_loss: 638469.4375 - val_mae: 272.0606\n",
      "Epoch 5/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 615683.0000 - mae: 262.7165 - val_loss: 639545.5625 - val_mae: 273.3051\n",
      "Epoch 6/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 605150.5625 - mae: 261.8646 - val_loss: 642445.6875 - val_mae: 274.1494\n",
      "Epoch 7/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 586224.1250 - mae: 260.7354 - val_loss: 648282.0625 - val_mae: 274.6549\n",
      "Epoch 8/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 592305.1875 - mae: 262.1328 - val_loss: 648998.8125 - val_mae: 275.0416\n",
      "Epoch 9/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 561396.7500 - mae: 258.7444 - val_loss: 653056.5625 - val_mae: 277.8214\n",
      "Epoch 10/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 564971.5000 - mae: 259.3470 - val_loss: 660345.3750 - val_mae: 280.2100\n",
      "Processing ./db/train_de...\n",
      "Loaded 884068 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 668251.5625 - mae: 272.9227 - val_loss: 753707.7500 - val_mae: 271.9043\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 604182.5000 - mae: 263.6600 - val_loss: 752393.4375 - val_mae: 271.6464\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 581531.5000 - mae: 261.1008 - val_loss: 753337.8125 - val_mae: 272.2177\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 576268.0625 - mae: 261.0614 - val_loss: 756674.1875 - val_mae: 273.1930\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 557255.5625 - mae: 258.9653 - val_loss: 759560.1875 - val_mae: 272.9069\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 542839.3750 - mae: 258.3449 - val_loss: 762761.5625 - val_mae: 275.9345\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 534265.1875 - mae: 257.7647 - val_loss: 766675.9375 - val_mae: 273.4413\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 534846.3750 - mae: 256.0154 - val_loss: 768059.3750 - val_mae: 278.5553\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 529130.1250 - mae: 256.7731 - val_loss: 771313.9375 - val_mae: 275.9336\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 515450.2500 - mae: 254.5018 - val_loss: 775317.5000 - val_mae: 277.1710\n",
      "Processing ./db/train_df...\n",
      "Loaded 881531 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 767787.5000 - mae: 279.9037 - val_loss: 805822.6875 - val_mae: 284.5222\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 681329.6875 - mae: 271.6435 - val_loss: 805497.3750 - val_mae: 282.2433\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 618180.0000 - mae: 267.3578 - val_loss: 802922.7500 - val_mae: 285.8703\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 598148.2500 - mae: 266.6082 - val_loss: 803676.8125 - val_mae: 283.8835\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 599765.4375 - mae: 265.8738 - val_loss: 804435.0000 - val_mae: 285.3229\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 608984.0625 - mae: 267.0787 - val_loss: 805761.6875 - val_mae: 283.3336\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 571758.6250 - mae: 261.6846 - val_loss: 806541.5000 - val_mae: 285.5707\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 572562.0625 - mae: 262.2643 - val_loss: 810222.1250 - val_mae: 284.3258\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 537451.6250 - mae: 259.6526 - val_loss: 814198.5000 - val_mae: 284.5668\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 552289.8750 - mae: 260.9372 - val_loss: 813597.0625 - val_mae: 285.8369\n",
      "Processing ./db/train_dg...\n",
      "Loaded 879460 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 775633.3750 - mae: 280.9297 - val_loss: 888344.3750 - val_mae: 298.7184\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 649236.9375 - mae: 269.7738 - val_loss: 891030.3125 - val_mae: 299.6757\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 630545.6250 - mae: 268.5881 - val_loss: 893026.8125 - val_mae: 300.7364\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 606099.0000 - mae: 265.8676 - val_loss: 896320.1875 - val_mae: 300.8821\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 588238.1875 - mae: 264.3445 - val_loss: 899436.9375 - val_mae: 301.3860\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 570971.5625 - mae: 262.8454 - val_loss: 900623.5000 - val_mae: 301.5308\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 582667.7500 - mae: 263.9628 - val_loss: 903737.7500 - val_mae: 301.7756\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 559034.3750 - mae: 262.2145 - val_loss: 906691.5625 - val_mae: 305.3503\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 529242.5625 - mae: 259.2917 - val_loss: 908119.5000 - val_mae: 306.1727\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 535709.1875 - mae: 260.0735 - val_loss: 910432.1875 - val_mae: 303.6326\n",
      "Processing ./db/train_dh...\n",
      "Loaded 873254 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 711375.2500 - mae: 282.4461 - val_loss: 614524.7500 - val_mae: 271.7257\n",
      "Epoch 2/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 659424.3125 - mae: 275.5773 - val_loss: 611650.0000 - val_mae: 269.8965\n",
      "Epoch 3/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 644842.2500 - mae: 272.2135 - val_loss: 611582.3125 - val_mae: 270.8080\n",
      "Epoch 4/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 608331.9375 - mae: 270.3224 - val_loss: 613437.2500 - val_mae: 273.3289\n",
      "Epoch 5/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 593814.0625 - mae: 267.9982 - val_loss: 614834.2500 - val_mae: 274.2781\n",
      "Epoch 6/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 591508.4375 - mae: 268.9281 - val_loss: 617149.6875 - val_mae: 272.9427\n",
      "Epoch 7/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 588315.8125 - mae: 268.0812 - val_loss: 619666.7500 - val_mae: 274.3924\n",
      "Epoch 8/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 582282.6250 - mae: 267.4234 - val_loss: 622375.1250 - val_mae: 274.6873\n",
      "Epoch 9/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 558302.6250 - mae: 265.6483 - val_loss: 625747.8750 - val_mae: 275.4089\n",
      "Epoch 10/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 589688.3750 - mae: 268.4668 - val_loss: 628852.3750 - val_mae: 274.6372\n",
      "Processing ./db/train_di...\n",
      "Loaded 879200 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 756737.4375 - mae: 282.8974 - val_loss: 855602.6875 - val_mae: 281.0765\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 734592.8750 - mae: 278.0426 - val_loss: 849297.3125 - val_mae: 281.9340\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 691385.3750 - mae: 275.5249 - val_loss: 852401.0000 - val_mae: 282.4089\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 685684.6875 - mae: 274.4630 - val_loss: 862769.7500 - val_mae: 283.5926\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 665027.9375 - mae: 272.8133 - val_loss: 878229.0625 - val_mae: 284.2352\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 654544.2500 - mae: 271.2773 - val_loss: 889529.1250 - val_mae: 287.0196\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 662589.0000 - mae: 271.9856 - val_loss: 902433.6875 - val_mae: 285.7074\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 641272.0000 - mae: 270.6216 - val_loss: 917918.0625 - val_mae: 289.6474\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 638479.8125 - mae: 270.6548 - val_loss: 940022.6875 - val_mae: 286.5310\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 631239.6250 - mae: 269.5746 - val_loss: 957103.2500 - val_mae: 288.2303\n",
      "Processing ./db/train_dj...\n",
      "Loaded 872573 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 812962.4375 - mae: 291.8380 - val_loss: 791941.8125 - val_mae: 282.9705\n",
      "Epoch 2/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 746958.8750 - mae: 283.5912 - val_loss: 789680.7500 - val_mae: 282.8519\n",
      "Epoch 3/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 754703.1875 - mae: 283.5554 - val_loss: 789661.5625 - val_mae: 284.0843\n",
      "Epoch 4/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 718182.8750 - mae: 280.8428 - val_loss: 790676.7500 - val_mae: 285.6653\n",
      "Epoch 5/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 712869.6875 - mae: 280.4061 - val_loss: 793191.3750 - val_mae: 286.0694\n",
      "Epoch 6/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 704070.8125 - mae: 280.7354 - val_loss: 795363.8750 - val_mae: 286.0677\n",
      "Epoch 7/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 671540.0625 - mae: 277.7832 - val_loss: 798733.6875 - val_mae: 287.3589\n",
      "Epoch 8/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 677720.6875 - mae: 278.5776 - val_loss: 802166.4375 - val_mae: 288.3787\n",
      "Epoch 9/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 654433.5000 - mae: 276.7584 - val_loss: 805990.2500 - val_mae: 288.1512\n",
      "Epoch 10/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 666411.5625 - mae: 278.1835 - val_loss: 808224.5000 - val_mae: 289.8078\n",
      "Processing ./db/train_dk...\n",
      "Loaded 873584 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 728768.5625 - mae: 285.8098 - val_loss: 930774.8750 - val_mae: 312.7632\n",
      "Epoch 2/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 672407.8750 - mae: 276.9575 - val_loss: 925509.5000 - val_mae: 311.7492\n",
      "Epoch 3/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 636776.6875 - mae: 272.4931 - val_loss: 928166.0000 - val_mae: 311.2281\n",
      "Epoch 4/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 619482.5625 - mae: 271.3280 - val_loss: 931057.4375 - val_mae: 311.5976\n",
      "Epoch 5/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 610166.6250 - mae: 269.6973 - val_loss: 932249.3750 - val_mae: 313.6094\n",
      "Epoch 6/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 632516.3125 - mae: 271.7922 - val_loss: 936279.6250 - val_mae: 314.6075\n",
      "Epoch 7/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 618296.6875 - mae: 270.1465 - val_loss: 939975.8125 - val_mae: 313.8524\n",
      "Epoch 8/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 592432.6250 - mae: 268.0889 - val_loss: 945938.8750 - val_mae: 316.0021\n",
      "Epoch 9/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 576807.1875 - mae: 267.1594 - val_loss: 951848.3750 - val_mae: 316.0168\n",
      "Epoch 10/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 575321.8125 - mae: 267.3801 - val_loss: 956703.6250 - val_mae: 316.2727\n",
      "Processing ./db/train_dl...\n",
      "Loaded 882839 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 776169.1875 - mae: 292.7683 - val_loss: 707755.1875 - val_mae: 272.0618\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 704814.8125 - mae: 282.7336 - val_loss: 706955.7500 - val_mae: 273.8983\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 693167.6250 - mae: 281.1812 - val_loss: 707077.3125 - val_mae: 273.7677\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 681998.5625 - mae: 279.4490 - val_loss: 709081.2500 - val_mae: 274.1631\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 667657.4375 - mae: 279.4803 - val_loss: 711032.8750 - val_mae: 273.1020\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 673801.2500 - mae: 279.1821 - val_loss: 713521.3750 - val_mae: 273.9038\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 627335.6250 - mae: 274.9388 - val_loss: 713536.0625 - val_mae: 275.7853\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 642979.5625 - mae: 277.5008 - val_loss: 718290.6250 - val_mae: 275.4488\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 617766.2500 - mae: 274.2560 - val_loss: 721138.1250 - val_mae: 276.9915\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 622073.1875 - mae: 275.0416 - val_loss: 724625.0625 - val_mae: 276.3782\n",
      "Processing ./db/train_dm...\n",
      "Loaded 873210 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 941233.2500 - mae: 312.7425 - val_loss: 703843.1250 - val_mae: 276.3347\n",
      "Epoch 2/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 859932.0625 - mae: 303.2159 - val_loss: 702367.6875 - val_mae: 276.1156\n",
      "Epoch 3/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 836906.7500 - mae: 299.9701 - val_loss: 703839.5625 - val_mae: 277.5208\n",
      "Epoch 4/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 800774.2500 - mae: 298.3042 - val_loss: 707189.4375 - val_mae: 278.3044\n",
      "Epoch 5/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 795550.8125 - mae: 296.4643 - val_loss: 709059.0000 - val_mae: 279.5093\n",
      "Epoch 6/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 779309.9375 - mae: 295.8467 - val_loss: 713347.8125 - val_mae: 279.8914\n",
      "Epoch 7/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 777582.4375 - mae: 295.3996 - val_loss: 715243.6875 - val_mae: 281.4125\n",
      "Epoch 8/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 747011.6250 - mae: 293.6067 - val_loss: 719215.8125 - val_mae: 282.3919\n",
      "Epoch 9/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 747275.1250 - mae: 293.3801 - val_loss: 724136.0625 - val_mae: 288.8875\n",
      "Epoch 10/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 721571.7500 - mae: 292.2537 - val_loss: 725050.1250 - val_mae: 282.5521\n",
      "Processing ./db/train_dn...\n",
      "Loaded 869970 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 919072.1250 - mae: 319.2317 - val_loss: 700037.6875 - val_mae: 287.2640\n",
      "Epoch 2/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 835479.3750 - mae: 305.9163 - val_loss: 699007.0000 - val_mae: 287.0273\n",
      "Epoch 3/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 823765.8125 - mae: 303.9868 - val_loss: 699818.6875 - val_mae: 285.1061\n",
      "Epoch 4/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 797414.1875 - mae: 301.7601 - val_loss: 703092.3750 - val_mae: 285.4178\n",
      "Epoch 5/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 798901.9375 - mae: 301.2262 - val_loss: 708386.0625 - val_mae: 285.2477\n",
      "Epoch 6/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 777446.6875 - mae: 297.6725 - val_loss: 710215.8750 - val_mae: 286.7233\n",
      "Epoch 7/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 774387.1250 - mae: 297.7912 - val_loss: 713667.5625 - val_mae: 287.6237\n",
      "Epoch 8/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 761330.3125 - mae: 297.3638 - val_loss: 716391.9375 - val_mae: 287.4566\n",
      "Epoch 9/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 734925.8750 - mae: 294.3362 - val_loss: 720682.8125 - val_mae: 288.6112\n",
      "Epoch 10/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 756243.0000 - mae: 296.7327 - val_loss: 723457.3125 - val_mae: 288.9897\n",
      "Processing ./db/train_do...\n",
      "Loaded 874765 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 772670.3750 - mae: 297.5078 - val_loss: 623779.9375 - val_mae: 270.7659\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 722216.8125 - mae: 289.5366 - val_loss: 620693.8750 - val_mae: 269.1199\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 689662.9375 - mae: 285.5346 - val_loss: 620314.3125 - val_mae: 269.9590\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 684510.5000 - mae: 285.5471 - val_loss: 620956.1875 - val_mae: 270.8080\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 673422.4375 - mae: 285.4330 - val_loss: 622395.8750 - val_mae: 271.2414\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 629940.5000 - mae: 280.9683 - val_loss: 625010.0625 - val_mae: 272.1091\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 654246.6875 - mae: 284.1982 - val_loss: 625791.9375 - val_mae: 270.7196\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 637593.1875 - mae: 280.8459 - val_loss: 628812.4375 - val_mae: 272.0686\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 628189.0625 - mae: 280.8531 - val_loss: 631166.3125 - val_mae: 273.1792\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 609914.0000 - mae: 279.7169 - val_loss: 634981.6875 - val_mae: 273.7728\n",
      "Processing ./db/train_dp...\n",
      "Loaded 877069 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 775174.9375 - mae: 292.9455 - val_loss: 730933.3125 - val_mae: 294.0998\n",
      "Epoch 2/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 717217.6250 - mae: 288.3183 - val_loss: 724280.1875 - val_mae: 280.4960\n",
      "Epoch 3/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 687178.0000 - mae: 282.5795 - val_loss: 726865.1250 - val_mae: 281.2164\n",
      "Epoch 4/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 685120.5000 - mae: 281.5155 - val_loss: 727365.4375 - val_mae: 280.4767\n",
      "Epoch 5/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 683894.0000 - mae: 281.2684 - val_loss: 730048.9375 - val_mae: 280.6131\n",
      "Epoch 6/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 640508.6875 - mae: 277.5463 - val_loss: 733394.3125 - val_mae: 281.3170\n",
      "Epoch 7/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 652406.6875 - mae: 277.8141 - val_loss: 734250.6875 - val_mae: 281.8880\n",
      "Epoch 8/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 659439.3125 - mae: 278.3179 - val_loss: 738761.8750 - val_mae: 283.2059\n",
      "Epoch 9/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 623741.5625 - mae: 274.9426 - val_loss: 741387.3750 - val_mae: 284.4742\n",
      "Epoch 10/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 645275.6875 - mae: 276.2184 - val_loss: 743548.3125 - val_mae: 282.0190\n",
      "Processing ./db/train_dq...\n",
      "Loaded 876129 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 937870.7500 - mae: 292.2750 - val_loss: 684187.0625 - val_mae: 278.5849\n",
      "Epoch 2/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 691236.1875 - mae: 279.6836 - val_loss: 680090.3750 - val_mae: 279.3919\n",
      "Epoch 3/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 658803.4375 - mae: 275.8047 - val_loss: 681606.7500 - val_mae: 278.8925\n",
      "Epoch 4/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 627508.9375 - mae: 273.7467 - val_loss: 682300.3750 - val_mae: 279.6667\n",
      "Epoch 5/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 629962.8125 - mae: 273.0408 - val_loss: 682805.1875 - val_mae: 278.8046\n",
      "Epoch 6/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 652574.1250 - mae: 274.8353 - val_loss: 684361.2500 - val_mae: 279.0961\n",
      "Epoch 7/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 628462.5000 - mae: 271.5153 - val_loss: 687643.3125 - val_mae: 279.6499\n",
      "Epoch 8/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 617568.8125 - mae: 270.4769 - val_loss: 691023.8125 - val_mae: 280.1345\n",
      "Epoch 9/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 596714.9375 - mae: 269.0684 - val_loss: 695646.6875 - val_mae: 279.9906\n",
      "Epoch 10/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 604326.9375 - mae: 269.6783 - val_loss: 698415.0000 - val_mae: 280.6775\n",
      "Processing ./db/train_dr...\n",
      "Loaded 866696 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 777200.3125 - mae: 286.4363 - val_loss: 686547.5000 - val_mae: 280.4807\n",
      "Epoch 2/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 710422.0000 - mae: 277.9193 - val_loss: 683865.7500 - val_mae: 282.7899\n",
      "Epoch 3/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 701558.8750 - mae: 277.3004 - val_loss: 683792.9375 - val_mae: 281.1490\n",
      "Epoch 4/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 689154.4375 - mae: 275.0082 - val_loss: 685128.8750 - val_mae: 282.4818\n",
      "Epoch 5/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 646188.9375 - mae: 272.5442 - val_loss: 688790.6875 - val_mae: 282.7934\n",
      "Epoch 6/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 622419.5000 - mae: 271.3528 - val_loss: 692743.5000 - val_mae: 285.1437\n",
      "Epoch 7/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 634503.8125 - mae: 272.5859 - val_loss: 695036.0625 - val_mae: 284.4503\n",
      "Epoch 8/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 608670.2500 - mae: 269.1023 - val_loss: 700259.9375 - val_mae: 287.2617\n",
      "Epoch 9/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 605309.8125 - mae: 269.0008 - val_loss: 702022.0000 - val_mae: 286.3922\n",
      "Epoch 10/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 583894.3125 - mae: 267.6250 - val_loss: 707891.3750 - val_mae: 289.9495\n",
      "Processing ./db/train_ds...\n",
      "Loaded 879587 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 688934.1250 - mae: 275.4508 - val_loss: 701390.6250 - val_mae: 282.8236\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 645089.8750 - mae: 269.9088 - val_loss: 695336.8750 - val_mae: 280.4425\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 618190.0625 - mae: 266.7294 - val_loss: 694978.0625 - val_mae: 285.1273\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 601551.2500 - mae: 265.6087 - val_loss: 694826.0000 - val_mae: 282.3259\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 583264.8750 - mae: 263.4910 - val_loss: 697025.7500 - val_mae: 283.3068\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 559710.1250 - mae: 261.4348 - val_loss: 698509.7500 - val_mae: 284.5659\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 553209.1250 - mae: 260.3163 - val_loss: 701233.8125 - val_mae: 285.1460\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 550552.1875 - mae: 260.4061 - val_loss: 704037.5000 - val_mae: 285.1295\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 545518.0625 - mae: 259.3344 - val_loss: 706028.2500 - val_mae: 285.9275\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 564797.3125 - mae: 261.2124 - val_loss: 708664.7500 - val_mae: 285.7403\n",
      "Processing ./db/train_dt...\n",
      "Loaded 871768 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 748509.3125 - mae: 284.2876 - val_loss: 729790.3125 - val_mae: 286.6673\n",
      "Epoch 2/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 668697.5000 - mae: 274.1368 - val_loss: 729019.5000 - val_mae: 287.9636\n",
      "Epoch 3/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 659122.6875 - mae: 273.7605 - val_loss: 728958.6250 - val_mae: 285.6995\n",
      "Epoch 4/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 626804.1250 - mae: 271.2673 - val_loss: 730597.9375 - val_mae: 286.4283\n",
      "Epoch 5/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 616215.8125 - mae: 269.7595 - val_loss: 734221.0000 - val_mae: 288.0563\n",
      "Epoch 6/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 590569.6875 - mae: 267.7917 - val_loss: 736884.1250 - val_mae: 288.9469\n",
      "Epoch 7/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 590560.5000 - mae: 267.9274 - val_loss: 739116.4375 - val_mae: 289.4842\n",
      "Epoch 8/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 602486.3125 - mae: 268.9894 - val_loss: 743056.0625 - val_mae: 289.5565\n",
      "Epoch 9/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 567649.0625 - mae: 266.4774 - val_loss: 748527.0625 - val_mae: 291.1868\n",
      "Epoch 10/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 570220.6250 - mae: 265.7607 - val_loss: 750868.0000 - val_mae: 291.7961\n",
      "Processing ./db/train_du...\n",
      "Loaded 869836 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 857362.0000 - mae: 293.0163 - val_loss: 771737.1250 - val_mae: 284.9400\n",
      "Epoch 2/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 702832.1250 - mae: 278.2848 - val_loss: 768069.4375 - val_mae: 283.9921\n",
      "Epoch 3/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 672386.2500 - mae: 275.9731 - val_loss: 766706.8750 - val_mae: 284.8571\n",
      "Epoch 4/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 670896.4375 - mae: 275.5858 - val_loss: 767368.5625 - val_mae: 283.4430\n",
      "Epoch 5/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 624654.3125 - mae: 271.9896 - val_loss: 768617.0000 - val_mae: 283.8214\n",
      "Epoch 6/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 631870.6875 - mae: 272.0913 - val_loss: 769899.2500 - val_mae: 283.9539\n",
      "Epoch 7/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 603640.0000 - mae: 270.3139 - val_loss: 771723.3750 - val_mae: 284.4810\n",
      "Epoch 8/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 591820.8125 - mae: 269.4600 - val_loss: 773876.5625 - val_mae: 285.6812\n",
      "Epoch 9/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595710.9375 - mae: 269.3426 - val_loss: 776515.7500 - val_mae: 285.6668\n",
      "Epoch 10/10\n",
      "\u001b[1m680/680\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 594875.7500 - mae: 268.8905 - val_loss: 779678.6875 - val_mae: 285.9841\n",
      "Processing ./db/train_dv...\n",
      "Loaded 874259 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 723257.3125 - mae: 280.2364 - val_loss: 642042.9375 - val_mae: 277.6231\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 665432.6250 - mae: 274.0490 - val_loss: 637498.6250 - val_mae: 275.2017\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 630776.3125 - mae: 270.0617 - val_loss: 635129.3125 - val_mae: 279.3165\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 618651.1875 - mae: 269.7923 - val_loss: 635676.7500 - val_mae: 274.0367\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 618850.1250 - mae: 269.3697 - val_loss: 638580.4375 - val_mae: 277.1423\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 600998.5625 - mae: 268.2880 - val_loss: 645870.8125 - val_mae: 277.3457\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 598995.5625 - mae: 267.7433 - val_loss: 647745.7500 - val_mae: 275.9910\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 578287.5625 - mae: 265.8087 - val_loss: 654718.0000 - val_mae: 278.8695\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 593284.9375 - mae: 266.4534 - val_loss: 659392.5625 - val_mae: 277.9692\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 559894.6875 - mae: 264.6306 - val_loss: 666186.5625 - val_mae: 277.6782\n",
      "Processing ./db/train_dw...\n",
      "Loaded 880396 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 703948.5000 - mae: 278.5211 - val_loss: 861132.4375 - val_mae: 287.4279\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 643157.2500 - mae: 269.2017 - val_loss: 863768.6250 - val_mae: 287.4066\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 624800.6250 - mae: 267.1313 - val_loss: 861316.2500 - val_mae: 286.9424\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 616601.4375 - mae: 266.3917 - val_loss: 863358.4375 - val_mae: 289.5310\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 607023.2500 - mae: 266.1812 - val_loss: 855143.5000 - val_mae: 288.9429\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 587130.1250 - mae: 264.1600 - val_loss: 847159.8125 - val_mae: 289.9568\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 565945.8125 - mae: 262.9855 - val_loss: 837887.6250 - val_mae: 290.3824\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 580038.5625 - mae: 263.7794 - val_loss: 833067.7500 - val_mae: 290.9874\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 533038.2500 - mae: 260.2310 - val_loss: 830965.1875 - val_mae: 294.5289\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 539557.2500 - mae: 260.4612 - val_loss: 825703.7500 - val_mae: 293.3582\n",
      "Processing ./db/train_dx...\n",
      "Loaded 880820 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 739175.7500 - mae: 280.3349 - val_loss: 735778.5625 - val_mae: 283.1142\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 684271.9375 - mae: 272.0026 - val_loss: 732945.4375 - val_mae: 284.4481\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 665508.7500 - mae: 271.4024 - val_loss: 734050.1250 - val_mae: 285.7245\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 643653.7500 - mae: 269.2276 - val_loss: 735732.6250 - val_mae: 285.1227\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 622970.8750 - mae: 266.9182 - val_loss: 737823.9375 - val_mae: 287.0076\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 618527.6250 - mae: 266.9312 - val_loss: 740491.1250 - val_mae: 288.4332\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 598903.8750 - mae: 265.3135 - val_loss: 742703.3750 - val_mae: 288.2028\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 591710.2500 - mae: 264.2743 - val_loss: 746651.2500 - val_mae: 290.2195\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 612085.2500 - mae: 264.7230 - val_loss: 748635.3125 - val_mae: 288.8339\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 587075.1250 - mae: 264.2114 - val_loss: 753349.8125 - val_mae: 290.1397\n",
      "Processing ./db/train_dy...\n",
      "Loaded 875210 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 776352.6250 - mae: 283.7444 - val_loss: 685637.3750 - val_mae: 280.2365\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 746468.8125 - mae: 279.3021 - val_loss: 684961.7500 - val_mae: 278.9897\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 698431.8125 - mae: 273.8687 - val_loss: 688780.3750 - val_mae: 281.7411\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 673704.9375 - mae: 273.5266 - val_loss: 690433.8750 - val_mae: 281.2165\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 634366.6250 - mae: 270.4629 - val_loss: 691814.7500 - val_mae: 281.8589\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 657277.5000 - mae: 271.3376 - val_loss: 693669.2500 - val_mae: 282.3024\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 635999.6250 - mae: 270.0113 - val_loss: 696098.3125 - val_mae: 282.1459\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 615034.0000 - mae: 268.7157 - val_loss: 696970.1875 - val_mae: 282.9676\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 602052.8125 - mae: 267.5584 - val_loss: 698667.0625 - val_mae: 282.5932\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 615883.2500 - mae: 268.5341 - val_loss: 702227.0625 - val_mae: 283.3315\n",
      "Processing ./db/train_dz...\n",
      "Loaded 879262 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 672230.2500 - mae: 273.3326 - val_loss: 660084.3750 - val_mae: 274.2795\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 614450.6875 - mae: 264.3361 - val_loss: 658131.7500 - val_mae: 273.8970\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 597517.8750 - mae: 263.6347 - val_loss: 657751.8750 - val_mae: 273.4214\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 589383.6250 - mae: 262.2092 - val_loss: 660512.5000 - val_mae: 274.2058\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 577978.1250 - mae: 260.7599 - val_loss: 663957.6875 - val_mae: 274.4223\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 565716.2500 - mae: 260.1792 - val_loss: 667241.6875 - val_mae: 275.2041\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 559190.5625 - mae: 259.8320 - val_loss: 668692.5000 - val_mae: 275.4785\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 538130.2500 - mae: 257.3392 - val_loss: 671408.5000 - val_mae: 275.8547\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 531989.5000 - mae: 256.2606 - val_loss: 673325.1250 - val_mae: 277.2915\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 521386.8750 - mae: 257.3089 - val_loss: 676425.3125 - val_mae: 277.3712\n",
      "Processing ./db/train_ea...\n",
      "Loaded 882633 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 767041.4375 - mae: 279.6710 - val_loss: 749926.6875 - val_mae: 277.2159\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 681389.4375 - mae: 270.3705 - val_loss: 750155.1875 - val_mae: 278.7152\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 672578.5000 - mae: 271.3079 - val_loss: 751448.1875 - val_mae: 280.4385\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 661107.6875 - mae: 270.6047 - val_loss: 754247.8750 - val_mae: 280.8629\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 644543.8125 - mae: 267.9171 - val_loss: 753986.0625 - val_mae: 281.8839\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 637806.1875 - mae: 268.5879 - val_loss: 757342.9375 - val_mae: 283.7598\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 637224.8750 - mae: 268.2573 - val_loss: 763879.4375 - val_mae: 283.0713\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 617257.6250 - mae: 266.2104 - val_loss: 773561.3125 - val_mae: 284.6615\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 605102.3750 - mae: 265.4473 - val_loss: 776831.9375 - val_mae: 285.5083\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 614475.2500 - mae: 266.8505 - val_loss: 778390.1875 - val_mae: 287.7470\n",
      "Processing ./db/train_eb...\n",
      "Loaded 875727 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 795069.0000 - mae: 292.1721 - val_loss: 667399.0000 - val_mae: 274.2993\n",
      "Epoch 2/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 718315.5625 - mae: 280.4477 - val_loss: 665201.6875 - val_mae: 272.1852\n",
      "Epoch 3/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 691115.8125 - mae: 276.9977 - val_loss: 664575.5000 - val_mae: 273.9683\n",
      "Epoch 4/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 681343.8125 - mae: 276.2784 - val_loss: 667158.3750 - val_mae: 272.4996\n",
      "Epoch 5/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 655549.2500 - mae: 272.5985 - val_loss: 670103.5000 - val_mae: 275.3453\n",
      "Epoch 6/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 643889.3750 - mae: 271.8120 - val_loss: 671319.5625 - val_mae: 273.5215\n",
      "Epoch 7/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 643086.0000 - mae: 271.0326 - val_loss: 675097.8750 - val_mae: 275.3214\n",
      "Epoch 8/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 643977.0625 - mae: 272.3758 - val_loss: 683236.7500 - val_mae: 274.9261\n",
      "Epoch 9/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 604095.5000 - mae: 268.7203 - val_loss: 691472.2500 - val_mae: 277.1693\n",
      "Epoch 10/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 613003.1250 - mae: 269.1988 - val_loss: 695240.2500 - val_mae: 276.8861\n",
      "Processing ./db/train_ec...\n",
      "Loaded 871889 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 734752.7500 - mae: 282.3989 - val_loss: 665080.6250 - val_mae: 281.1659\n",
      "Epoch 2/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 691424.4375 - mae: 274.6701 - val_loss: 661055.5625 - val_mae: 280.5620\n",
      "Epoch 3/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 674899.0000 - mae: 271.0651 - val_loss: 659059.5625 - val_mae: 278.7075\n",
      "Epoch 4/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 655187.1250 - mae: 270.3123 - val_loss: 660594.5000 - val_mae: 279.9803\n",
      "Epoch 5/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 636664.6875 - mae: 268.8373 - val_loss: 661799.5000 - val_mae: 279.4618\n",
      "Epoch 6/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 613662.4375 - mae: 266.4348 - val_loss: 664465.5625 - val_mae: 281.5745\n",
      "Epoch 7/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 594571.9375 - mae: 265.1575 - val_loss: 667626.9375 - val_mae: 283.6682\n",
      "Epoch 8/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 627244.3125 - mae: 267.6562 - val_loss: 668201.1250 - val_mae: 281.8160\n",
      "Epoch 9/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 587961.6875 - mae: 264.0262 - val_loss: 671565.8750 - val_mae: 283.5696\n",
      "Epoch 10/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 588535.0000 - mae: 265.2028 - val_loss: 677104.4375 - val_mae: 287.9470\n",
      "Processing ./db/train_ed...\n",
      "Loaded 875833 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 623838.4375 - mae: 270.6354 - val_loss: 703158.3125 - val_mae: 273.8110\n",
      "Epoch 2/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 590245.7500 - mae: 263.6407 - val_loss: 701164.4375 - val_mae: 272.2645\n",
      "Epoch 3/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 562528.0625 - mae: 260.3755 - val_loss: 699415.3750 - val_mae: 272.6884\n",
      "Epoch 4/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 572633.9375 - mae: 261.9420 - val_loss: 700808.8750 - val_mae: 274.0993\n",
      "Epoch 5/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 551863.6250 - mae: 258.4777 - val_loss: 700360.8750 - val_mae: 273.2468\n",
      "Epoch 6/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 579117.2500 - mae: 261.0694 - val_loss: 700499.2500 - val_mae: 272.5075\n",
      "Epoch 7/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 574454.4375 - mae: 260.2213 - val_loss: 702609.3750 - val_mae: 272.7027\n",
      "Epoch 8/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 546011.5000 - mae: 257.4195 - val_loss: 703598.2500 - val_mae: 278.1230\n",
      "Epoch 9/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 515507.5625 - mae: 256.1647 - val_loss: 705732.7500 - val_mae: 275.4864\n",
      "Epoch 10/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 523742.9688 - mae: 256.5977 - val_loss: 706493.8750 - val_mae: 276.1691\n",
      "Processing ./db/train_ee...\n",
      "Loaded 868143 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 694255.6875 - mae: 278.3398 - val_loss: 894977.0000 - val_mae: 313.9123\n",
      "Epoch 2/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 673523.0625 - mae: 271.5791 - val_loss: 898587.2500 - val_mae: 313.9533\n",
      "Epoch 3/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 650276.2500 - mae: 270.3353 - val_loss: 902333.3750 - val_mae: 315.0038\n",
      "Epoch 4/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 652591.4375 - mae: 269.6964 - val_loss: 905038.7500 - val_mae: 314.8359\n",
      "Epoch 5/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 617930.9375 - mae: 266.9021 - val_loss: 906948.8125 - val_mae: 318.0030\n",
      "Epoch 6/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 624623.8750 - mae: 268.3989 - val_loss: 909306.7500 - val_mae: 317.4254\n",
      "Epoch 7/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 596659.8125 - mae: 265.0459 - val_loss: 913611.3750 - val_mae: 318.5781\n",
      "Epoch 8/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 584589.3750 - mae: 264.8509 - val_loss: 915886.7500 - val_mae: 321.1723\n",
      "Epoch 9/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 583439.5000 - mae: 263.4781 - val_loss: 925615.4375 - val_mae: 319.2646\n",
      "Epoch 10/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 578512.4375 - mae: 262.5112 - val_loss: 936951.7500 - val_mae: 322.2450\n",
      "Processing ./db/train_ef...\n",
      "Loaded 867022 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 695254.0000 - mae: 282.0613 - val_loss: 783253.7500 - val_mae: 302.3220\n",
      "Epoch 2/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 660220.6250 - mae: 273.9615 - val_loss: 782428.2500 - val_mae: 303.8785\n",
      "Epoch 3/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 644919.2500 - mae: 271.2688 - val_loss: 782857.3125 - val_mae: 304.0655\n",
      "Epoch 4/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 596926.0625 - mae: 267.5858 - val_loss: 784120.4375 - val_mae: 302.5609\n",
      "Epoch 5/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 604400.6875 - mae: 267.6912 - val_loss: 787853.1875 - val_mae: 305.7251\n",
      "Epoch 6/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 581904.2500 - mae: 267.6608 - val_loss: 790935.1250 - val_mae: 305.6035\n",
      "Epoch 7/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 600099.6250 - mae: 267.7881 - val_loss: 794010.4375 - val_mae: 307.2175\n",
      "Epoch 8/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 564272.8125 - mae: 265.4697 - val_loss: 798021.6875 - val_mae: 306.9925\n",
      "Epoch 9/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 573103.8750 - mae: 266.0184 - val_loss: 803194.6875 - val_mae: 307.7689\n",
      "Epoch 10/10\n",
      "\u001b[1m678/678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 537177.5000 - mae: 263.8484 - val_loss: 808124.6875 - val_mae: 310.1348\n",
      "Processing ./db/train_eg...\n",
      "Loaded 875033 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 706571.3750 - mae: 276.9297 - val_loss: 692958.2500 - val_mae: 268.3698\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 649985.3125 - mae: 269.4728 - val_loss: 691195.2500 - val_mae: 267.9210\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 633974.3750 - mae: 267.4184 - val_loss: 698053.4375 - val_mae: 268.2499\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 632158.7500 - mae: 266.9923 - val_loss: 697893.9375 - val_mae: 268.5667\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 596384.6875 - mae: 264.3666 - val_loss: 706988.8125 - val_mae: 268.7458\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 608944.2500 - mae: 264.6693 - val_loss: 710964.8125 - val_mae: 269.9690\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 578564.9375 - mae: 262.8060 - val_loss: 713879.5625 - val_mae: 270.4288\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 563961.9375 - mae: 261.1872 - val_loss: 722496.1875 - val_mae: 272.6944\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 565135.3750 - mae: 261.5227 - val_loss: 730380.7500 - val_mae: 272.1574\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 547105.8125 - mae: 260.1907 - val_loss: 738772.1250 - val_mae: 273.3424\n",
      "Processing ./db/train_eh...\n",
      "Loaded 881509 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 654697.6250 - mae: 266.2479 - val_loss: 687691.5625 - val_mae: 273.9094\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 609179.8125 - mae: 260.9712 - val_loss: 684850.6875 - val_mae: 272.8785\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 603404.9375 - mae: 259.2607 - val_loss: 684559.3125 - val_mae: 272.3847\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 581113.4375 - mae: 257.9058 - val_loss: 686303.0625 - val_mae: 272.8490\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 552314.1875 - mae: 256.6384 - val_loss: 687717.3750 - val_mae: 273.4439\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 571928.9375 - mae: 256.3621 - val_loss: 690509.6250 - val_mae: 274.3228\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 554707.7500 - mae: 255.1476 - val_loss: 692811.7500 - val_mae: 274.8245\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 541034.3125 - mae: 253.9158 - val_loss: 696189.8125 - val_mae: 276.9202\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 545720.1250 - mae: 255.5165 - val_loss: 698529.7500 - val_mae: 275.7228\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 542056.5000 - mae: 254.6978 - val_loss: 701397.3125 - val_mae: 277.2920\n",
      "Processing ./db/train_ei...\n",
      "Loaded 882069 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 671075.0000 - mae: 269.0582 - val_loss: 696631.1875 - val_mae: 269.8958\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 621743.8750 - mae: 261.7581 - val_loss: 696041.1875 - val_mae: 268.2692\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 622702.0000 - mae: 261.5081 - val_loss: 697327.9375 - val_mae: 267.2259\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 578681.6875 - mae: 257.1161 - val_loss: 699283.8125 - val_mae: 267.8727\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 587417.3125 - mae: 258.3777 - val_loss: 700664.8750 - val_mae: 268.6532\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 564431.6250 - mae: 255.8851 - val_loss: 702386.7500 - val_mae: 270.1568\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 559791.2500 - mae: 256.9001 - val_loss: 704666.7500 - val_mae: 271.5858\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 576849.8750 - mae: 258.2034 - val_loss: 708257.1875 - val_mae: 270.9510\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 545666.5000 - mae: 256.0211 - val_loss: 711439.0000 - val_mae: 276.0869\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 528480.7500 - mae: 255.2442 - val_loss: 713800.6250 - val_mae: 272.9534\n",
      "Processing ./db/train_ej...\n",
      "Loaded 880532 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 780293.5000 - mae: 282.7922 - val_loss: 628988.5625 - val_mae: 267.6258\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 735606.0000 - mae: 274.5101 - val_loss: 625055.5625 - val_mae: 269.7433\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 706132.2500 - mae: 272.2095 - val_loss: 625516.0000 - val_mae: 268.2201\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 706885.4375 - mae: 271.6039 - val_loss: 625848.0000 - val_mae: 267.8058\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 682675.9375 - mae: 268.9891 - val_loss: 629760.1875 - val_mae: 268.8173\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 674926.5625 - mae: 268.2684 - val_loss: 632883.1250 - val_mae: 268.6152\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 651408.3125 - mae: 266.3932 - val_loss: 635542.8750 - val_mae: 269.2752\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 650366.3750 - mae: 266.9892 - val_loss: 637749.2500 - val_mae: 269.3692\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 634446.6875 - mae: 265.5073 - val_loss: 640896.0000 - val_mae: 269.2217\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 648204.3125 - mae: 266.4959 - val_loss: 643622.8750 - val_mae: 270.8853\n",
      "Processing ./db/train_ek...\n",
      "Loaded 878712 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 668988.3125 - mae: 268.0273 - val_loss: 541584.6250 - val_mae: 254.1205\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 610567.2500 - mae: 261.4869 - val_loss: 540401.9375 - val_mae: 255.6277\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 615165.9375 - mae: 261.6275 - val_loss: 539184.8125 - val_mae: 253.5028\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 583200.9375 - mae: 258.5785 - val_loss: 539394.6250 - val_mae: 254.8286\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 586172.6250 - mae: 258.9440 - val_loss: 540019.3750 - val_mae: 254.8137\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 573340.0625 - mae: 258.0860 - val_loss: 541518.9375 - val_mae: 256.2637\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 554400.6250 - mae: 256.0823 - val_loss: 542718.6875 - val_mae: 256.5549\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 554080.6250 - mae: 256.0456 - val_loss: 544144.8125 - val_mae: 255.9590\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 548254.5000 - mae: 255.5809 - val_loss: 546786.6875 - val_mae: 257.0999\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 562483.1250 - mae: 256.7463 - val_loss: 549356.1875 - val_mae: 256.5660\n",
      "Processing ./db/train_el...\n",
      "Loaded 884422 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 719780.3750 - mae: 272.6385 - val_loss: 660192.8125 - val_mae: 268.8381\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 654507.1250 - mae: 265.5305 - val_loss: 657914.4375 - val_mae: 268.6561\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 627173.1875 - mae: 262.7849 - val_loss: 657954.0000 - val_mae: 269.2721\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 614992.4375 - mae: 263.4034 - val_loss: 658370.8750 - val_mae: 270.0789\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 609748.5000 - mae: 263.4139 - val_loss: 660146.5625 - val_mae: 271.2961\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 617939.0625 - mae: 263.2698 - val_loss: 662641.2500 - val_mae: 270.7044\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 604974.9375 - mae: 261.8652 - val_loss: 665686.6875 - val_mae: 272.5378\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 592555.8750 - mae: 261.7436 - val_loss: 666465.1875 - val_mae: 273.3059\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 588678.0625 - mae: 260.1719 - val_loss: 669079.1875 - val_mae: 274.9612\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 571001.3750 - mae: 259.7492 - val_loss: 671018.5625 - val_mae: 274.2661\n",
      "Processing ./db/train_em...\n",
      "Loaded 872061 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 731956.4375 - mae: 280.7011 - val_loss: 702358.3125 - val_mae: 272.5468\n",
      "Epoch 2/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 678271.4375 - mae: 271.5838 - val_loss: 697141.1875 - val_mae: 272.1858\n",
      "Epoch 3/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 662099.2500 - mae: 270.1674 - val_loss: 697903.6250 - val_mae: 274.9391\n",
      "Epoch 4/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 677627.6875 - mae: 270.7704 - val_loss: 696553.7500 - val_mae: 272.6960\n",
      "Epoch 5/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 629267.0000 - mae: 267.5838 - val_loss: 696826.4375 - val_mae: 273.6643\n",
      "Epoch 6/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 634322.8750 - mae: 266.2389 - val_loss: 698422.1875 - val_mae: 274.6915\n",
      "Epoch 7/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 616174.0000 - mae: 266.0696 - val_loss: 701594.8750 - val_mae: 275.0788\n",
      "Epoch 8/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 605534.1875 - mae: 265.2558 - val_loss: 702935.1875 - val_mae: 274.6191\n",
      "Epoch 9/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 609718.2500 - mae: 264.8068 - val_loss: 705514.5625 - val_mae: 275.9247\n",
      "Epoch 10/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 616715.3750 - mae: 265.9308 - val_loss: 707839.9375 - val_mae: 275.5500\n",
      "Processing ./db/train_en...\n",
      "Loaded 873072 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 745552.4375 - mae: 281.5439 - val_loss: 667956.6250 - val_mae: 268.1249\n",
      "Epoch 2/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 680834.6250 - mae: 271.4747 - val_loss: 666482.3750 - val_mae: 269.2741\n",
      "Epoch 3/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 654305.0000 - mae: 269.9857 - val_loss: 669094.5625 - val_mae: 270.0257\n",
      "Epoch 4/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 652819.8750 - mae: 269.4769 - val_loss: 670437.5000 - val_mae: 270.3491\n",
      "Epoch 5/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 658628.3125 - mae: 269.5589 - val_loss: 672138.3125 - val_mae: 269.9453\n",
      "Epoch 6/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 616114.8125 - mae: 265.3570 - val_loss: 676799.5625 - val_mae: 272.9452\n",
      "Epoch 7/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 616471.8750 - mae: 266.8085 - val_loss: 678388.5625 - val_mae: 272.8841\n",
      "Epoch 8/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 612816.6250 - mae: 266.5571 - val_loss: 680799.9375 - val_mae: 272.1621\n",
      "Epoch 9/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 605180.0000 - mae: 265.7890 - val_loss: 683868.3125 - val_mae: 273.4112\n",
      "Epoch 10/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 588732.3125 - mae: 264.9882 - val_loss: 685915.0625 - val_mae: 273.2071\n",
      "Processing ./db/train_eo...\n",
      "Loaded 873191 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 694781.9375 - mae: 275.3987 - val_loss: 604986.7500 - val_mae: 266.3134\n",
      "Epoch 2/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 633165.5625 - mae: 266.1528 - val_loss: 604799.1875 - val_mae: 267.4134\n",
      "Epoch 3/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 611580.3750 - mae: 265.0982 - val_loss: 606238.1250 - val_mae: 267.7281\n",
      "Epoch 4/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 589674.2500 - mae: 262.7234 - val_loss: 607888.9375 - val_mae: 268.8178\n",
      "Epoch 5/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 591557.8750 - mae: 262.9581 - val_loss: 610778.5625 - val_mae: 270.0955\n",
      "Epoch 6/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 590260.6875 - mae: 263.2770 - val_loss: 610750.5625 - val_mae: 270.6029\n",
      "Epoch 7/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 571235.4375 - mae: 260.6632 - val_loss: 613501.0625 - val_mae: 272.6078\n",
      "Epoch 8/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 573741.3125 - mae: 260.8208 - val_loss: 616619.9375 - val_mae: 272.0826\n",
      "Epoch 9/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 556882.1875 - mae: 259.7462 - val_loss: 619448.6250 - val_mae: 274.0803\n",
      "Epoch 10/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 542063.0000 - mae: 259.3493 - val_loss: 622248.0000 - val_mae: 273.1116\n",
      "Processing ./db/train_ep...\n",
      "Loaded 878668 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 704246.7500 - mae: 274.2736 - val_loss: 856294.1250 - val_mae: 291.1488\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 659052.6875 - mae: 268.0720 - val_loss: 854926.5000 - val_mae: 292.1662\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595218.3125 - mae: 262.2143 - val_loss: 855115.6875 - val_mae: 292.6582\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 583169.1250 - mae: 262.0877 - val_loss: 857614.3125 - val_mae: 294.2532\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 566427.7500 - mae: 260.6861 - val_loss: 859534.6875 - val_mae: 294.3998\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 565907.0000 - mae: 259.0684 - val_loss: 862139.3125 - val_mae: 294.0654\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 574975.4375 - mae: 259.9319 - val_loss: 866808.3750 - val_mae: 297.1784\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 591983.8125 - mae: 261.3706 - val_loss: 871167.8750 - val_mae: 295.9027\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 560605.6875 - mae: 259.1459 - val_loss: 875099.1875 - val_mae: 296.1768\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 537393.1875 - mae: 257.1238 - val_loss: 877801.6250 - val_mae: 296.5106\n",
      "Processing ./db/train_eq...\n",
      "Loaded 872394 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 831545.5625 - mae: 290.2642 - val_loss: 686344.5625 - val_mae: 280.6497\n",
      "Epoch 2/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 799022.3125 - mae: 285.1528 - val_loss: 685623.7500 - val_mae: 281.4711\n",
      "Epoch 3/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 757207.1250 - mae: 281.7771 - val_loss: 689210.2500 - val_mae: 281.0969\n",
      "Epoch 4/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 730645.3125 - mae: 278.8116 - val_loss: 690194.8125 - val_mae: 282.8530\n",
      "Epoch 5/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 732023.4375 - mae: 280.2621 - val_loss: 694639.0625 - val_mae: 281.9694\n",
      "Epoch 6/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 721312.6875 - mae: 280.2202 - val_loss: 694798.3125 - val_mae: 283.4153\n",
      "Epoch 7/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 713710.6250 - mae: 280.3600 - val_loss: 697171.0625 - val_mae: 283.0420\n",
      "Epoch 8/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 680520.8750 - mae: 276.8817 - val_loss: 699945.0625 - val_mae: 285.7523\n",
      "Epoch 9/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 689238.1875 - mae: 277.7260 - val_loss: 704001.5000 - val_mae: 285.6349\n",
      "Epoch 10/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 680584.6250 - mae: 276.9641 - val_loss: 706499.1875 - val_mae: 287.0835\n",
      "Processing ./db/train_er...\n",
      "Loaded 863831 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 799766.5000 - mae: 296.6299 - val_loss: 707757.1250 - val_mae: 274.8555\n",
      "Epoch 2/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 733759.3750 - mae: 285.8494 - val_loss: 706987.7500 - val_mae: 274.7485\n",
      "Epoch 3/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 723982.0625 - mae: 284.9696 - val_loss: 706434.1875 - val_mae: 275.3779\n",
      "Epoch 4/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 700985.1250 - mae: 281.7477 - val_loss: 708488.1250 - val_mae: 278.4765\n",
      "Epoch 5/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 710319.3750 - mae: 283.8016 - val_loss: 709906.9375 - val_mae: 278.5212\n",
      "Epoch 6/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 671552.5625 - mae: 280.0661 - val_loss: 710395.7500 - val_mae: 278.0488\n",
      "Epoch 7/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 676259.2500 - mae: 281.3561 - val_loss: 712900.1250 - val_mae: 278.9692\n",
      "Epoch 8/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 652756.6250 - mae: 278.2938 - val_loss: 714377.2500 - val_mae: 279.4753\n",
      "Epoch 9/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 666571.0000 - mae: 280.3474 - val_loss: 714220.8125 - val_mae: 279.9718\n",
      "Epoch 10/10\n",
      "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 616671.4375 - mae: 276.0184 - val_loss: 718407.5625 - val_mae: 282.5438\n",
      "Processing ./db/train_es...\n",
      "Loaded 865812 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 716057.5625 - mae: 289.1125 - val_loss: 616089.7500 - val_mae: 270.8206\n",
      "Epoch 2/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 675471.5000 - mae: 281.4758 - val_loss: 617519.0000 - val_mae: 271.3911\n",
      "Epoch 3/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 645317.9375 - mae: 277.8815 - val_loss: 621745.2500 - val_mae: 272.0864\n",
      "Epoch 4/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 623125.1250 - mae: 275.2827 - val_loss: 623369.2500 - val_mae: 271.8918\n",
      "Epoch 5/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 624093.2500 - mae: 275.6225 - val_loss: 623678.1875 - val_mae: 270.5736\n",
      "Epoch 6/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 617269.6875 - mae: 273.5432 - val_loss: 625546.9375 - val_mae: 272.2829\n",
      "Epoch 7/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 600505.8750 - mae: 273.3355 - val_loss: 626516.8750 - val_mae: 272.2667\n",
      "Epoch 8/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 601253.0000 - mae: 272.9630 - val_loss: 627503.0625 - val_mae: 272.7458\n",
      "Epoch 9/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 592230.9375 - mae: 270.9900 - val_loss: 630132.7500 - val_mae: 273.9663\n",
      "Epoch 10/10\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 572378.4375 - mae: 270.5366 - val_loss: 632391.3750 - val_mae: 274.1986\n",
      "Processing ./db/train_et...\n",
      "Loaded 882618 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 639711.0625 - mae: 271.7784 - val_loss: 743216.1250 - val_mae: 279.6165\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 597232.3125 - mae: 263.5011 - val_loss: 740625.7500 - val_mae: 280.0804\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 572015.4375 - mae: 262.5483 - val_loss: 739051.9375 - val_mae: 282.7663\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 565874.5000 - mae: 260.3124 - val_loss: 740006.6250 - val_mae: 280.7383\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 565928.5625 - mae: 260.5685 - val_loss: 743289.1250 - val_mae: 281.2500\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 538395.5000 - mae: 258.3911 - val_loss: 746016.5625 - val_mae: 283.3935\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 528415.4375 - mae: 258.5955 - val_loss: 746952.3750 - val_mae: 284.7636\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 561041.3750 - mae: 261.5912 - val_loss: 751195.7500 - val_mae: 285.2314\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 520998.7812 - mae: 257.3569 - val_loss: 753893.0000 - val_mae: 284.8784\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 504685.9062 - mae: 256.9580 - val_loss: 754800.0625 - val_mae: 287.1541\n",
      "Processing ./db/train_eu...\n",
      "Loaded 877790 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 685481.5625 - mae: 277.7628 - val_loss: 692666.6250 - val_mae: 271.8880\n",
      "Epoch 2/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 661700.8125 - mae: 272.1339 - val_loss: 692218.5625 - val_mae: 271.6917\n",
      "Epoch 3/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 639827.6250 - mae: 269.4792 - val_loss: 693115.6875 - val_mae: 272.1522\n",
      "Epoch 4/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 612019.7500 - mae: 267.6360 - val_loss: 695250.3750 - val_mae: 273.6910\n",
      "Epoch 5/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 614629.5625 - mae: 267.8355 - val_loss: 698125.4375 - val_mae: 272.4608\n",
      "Epoch 6/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 603908.3750 - mae: 266.2865 - val_loss: 698403.7500 - val_mae: 273.6140\n",
      "Epoch 7/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 591294.8750 - mae: 265.0409 - val_loss: 700184.5625 - val_mae: 276.6309\n",
      "Epoch 8/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 576089.7500 - mae: 265.1880 - val_loss: 703107.0625 - val_mae: 276.6955\n",
      "Epoch 9/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 583066.4375 - mae: 263.9538 - val_loss: 704516.3125 - val_mae: 275.5666\n",
      "Epoch 10/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 570760.5000 - mae: 263.9040 - val_loss: 708251.9375 - val_mae: 277.9412\n",
      "Processing ./db/train_ev...\n",
      "Loaded 875446 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 692427.2500 - mae: 278.0904 - val_loss: 663602.6875 - val_mae: 274.1487\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 648647.2500 - mae: 271.2042 - val_loss: 662802.8750 - val_mae: 274.7721\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 637175.6875 - mae: 269.5571 - val_loss: 665788.4375 - val_mae: 274.6637\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 607786.8750 - mae: 266.1551 - val_loss: 665190.1875 - val_mae: 274.5337\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 617133.5000 - mae: 266.5947 - val_loss: 668634.5000 - val_mae: 278.2710\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 606206.6875 - mae: 265.2063 - val_loss: 669199.5000 - val_mae: 275.8603\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 581831.0625 - mae: 264.9961 - val_loss: 670140.8125 - val_mae: 277.3311\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 558402.3750 - mae: 262.9930 - val_loss: 673823.3750 - val_mae: 278.6240\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 569651.6250 - mae: 264.5741 - val_loss: 672788.3125 - val_mae: 277.9907\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 579891.5000 - mae: 264.7136 - val_loss: 675118.5625 - val_mae: 277.6990\n",
      "Processing ./db/train_ew...\n",
      "Loaded 872133 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 641313.0000 - mae: 275.1010 - val_loss: 730840.2500 - val_mae: 278.4779\n",
      "Epoch 2/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 573373.4375 - mae: 264.3527 - val_loss: 722424.9375 - val_mae: 276.5275\n",
      "Epoch 3/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 593855.1250 - mae: 265.1787 - val_loss: 722098.1875 - val_mae: 276.9471\n",
      "Epoch 4/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 544233.8125 - mae: 261.0607 - val_loss: 719432.5000 - val_mae: 277.3821\n",
      "Epoch 5/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 545867.6875 - mae: 260.2302 - val_loss: 722381.4375 - val_mae: 277.3791\n",
      "Epoch 6/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 560489.2500 - mae: 262.3728 - val_loss: 723994.8750 - val_mae: 278.2906\n",
      "Epoch 7/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 557505.2500 - mae: 261.2324 - val_loss: 725216.9375 - val_mae: 277.8243\n",
      "Epoch 8/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 554765.4375 - mae: 261.8651 - val_loss: 727109.5000 - val_mae: 280.6585\n",
      "Epoch 9/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 519208.7812 - mae: 258.0381 - val_loss: 729246.4375 - val_mae: 279.4737\n",
      "Epoch 10/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 514005.2812 - mae: 258.8252 - val_loss: 729118.3125 - val_mae: 280.5099\n",
      "Processing ./db/train_ex...\n",
      "Loaded 872578 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 656469.0625 - mae: 272.6720 - val_loss: 850973.6875 - val_mae: 290.4916\n",
      "Epoch 2/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 608188.5000 - mae: 265.9254 - val_loss: 851556.1250 - val_mae: 290.9789\n",
      "Epoch 3/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 597079.0000 - mae: 264.0352 - val_loss: 855171.3750 - val_mae: 290.3058\n",
      "Epoch 4/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 585089.0625 - mae: 263.2398 - val_loss: 859538.1875 - val_mae: 293.1401\n",
      "Epoch 5/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 570325.2500 - mae: 262.0641 - val_loss: 862148.2500 - val_mae: 292.7846\n",
      "Epoch 6/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 545324.8125 - mae: 260.8023 - val_loss: 872476.2500 - val_mae: 295.3805\n",
      "Epoch 7/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 553942.8750 - mae: 261.8519 - val_loss: 878030.5625 - val_mae: 296.8323\n",
      "Epoch 8/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 556679.7500 - mae: 261.7677 - val_loss: 888208.1250 - val_mae: 298.1138\n",
      "Epoch 9/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 550470.3750 - mae: 260.6354 - val_loss: 893731.6250 - val_mae: 297.8969\n",
      "Epoch 10/10\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 540943.7500 - mae: 261.2514 - val_loss: 901326.4375 - val_mae: 297.3190\n",
      "Processing ./db/train_ey...\n",
      "Loaded 871634 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 722067.2500 - mae: 284.1075 - val_loss: 548016.6250 - val_mae: 254.8134\n",
      "Epoch 2/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 637879.5000 - mae: 274.5870 - val_loss: 546480.5625 - val_mae: 256.1208\n",
      "Epoch 3/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 669261.4375 - mae: 276.1134 - val_loss: 548026.6875 - val_mae: 256.0001\n",
      "Epoch 4/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 632522.8750 - mae: 275.1057 - val_loss: 550092.4375 - val_mae: 258.2221\n",
      "Epoch 5/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 609428.3750 - mae: 273.1484 - val_loss: 551388.6875 - val_mae: 257.7792\n",
      "Epoch 6/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 615927.4375 - mae: 271.5869 - val_loss: 556701.1875 - val_mae: 260.0490\n",
      "Epoch 7/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 594838.8750 - mae: 270.9369 - val_loss: 560310.1250 - val_mae: 262.2552\n",
      "Epoch 8/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 588756.0000 - mae: 270.0891 - val_loss: 562600.3125 - val_mae: 262.2643\n",
      "Epoch 9/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 564070.7500 - mae: 268.9319 - val_loss: 566874.1875 - val_mae: 263.1302\n",
      "Epoch 10/10\n",
      "\u001b[1m681/681\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 576050.3125 - mae: 269.9706 - val_loss: 570888.0625 - val_mae: 263.6248\n",
      "Processing ./db/train_ez...\n",
      "Loaded 868959 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 798950.3750 - mae: 287.5669 - val_loss: 789200.5625 - val_mae: 279.3045\n",
      "Epoch 2/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 713593.8125 - mae: 276.4207 - val_loss: 789946.5625 - val_mae: 277.9037\n",
      "Epoch 3/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 700157.3750 - mae: 274.3359 - val_loss: 791610.7500 - val_mae: 278.8097\n",
      "Epoch 4/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 695747.9375 - mae: 274.3893 - val_loss: 792983.2500 - val_mae: 277.9185\n",
      "Epoch 5/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 654249.9375 - mae: 270.5944 - val_loss: 796185.8125 - val_mae: 278.9241\n",
      "Epoch 6/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 652478.3750 - mae: 271.8276 - val_loss: 797793.3125 - val_mae: 279.4607\n",
      "Epoch 7/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 614119.0000 - mae: 267.6652 - val_loss: 798345.1875 - val_mae: 281.9396\n",
      "Epoch 8/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 621786.0000 - mae: 268.8553 - val_loss: 804589.5625 - val_mae: 281.3641\n",
      "Epoch 9/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 607100.0000 - mae: 267.8123 - val_loss: 804026.7500 - val_mae: 282.4760\n",
      "Epoch 10/10\n",
      "\u001b[1m679/679\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 620788.3125 - mae: 268.8387 - val_loss: 806495.6875 - val_mae: 284.2483\n",
      "Processing ./db/train_fa...\n",
      "Loaded 873803 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 719977.4375 - mae: 275.9667 - val_loss: 699308.5000 - val_mae: 271.0406\n",
      "Epoch 2/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 683859.7500 - mae: 267.6077 - val_loss: 694243.4375 - val_mae: 269.3920\n",
      "Epoch 3/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 663755.9375 - mae: 265.1473 - val_loss: 694743.5625 - val_mae: 269.4078\n",
      "Epoch 4/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 646634.8750 - mae: 263.8508 - val_loss: 694561.6875 - val_mae: 271.8885\n",
      "Epoch 5/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 659520.8125 - mae: 266.0133 - val_loss: 694475.8750 - val_mae: 271.0621\n",
      "Epoch 6/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 649114.6250 - mae: 262.4975 - val_loss: 696276.3750 - val_mae: 271.0626\n",
      "Epoch 7/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 638997.8125 - mae: 263.7094 - val_loss: 698212.6250 - val_mae: 271.3169\n",
      "Epoch 8/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 614114.2500 - mae: 263.0412 - val_loss: 699147.3750 - val_mae: 271.0347\n",
      "Epoch 9/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 587645.8125 - mae: 259.5403 - val_loss: 700924.5000 - val_mae: 273.6330\n",
      "Epoch 10/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 605205.2500 - mae: 261.1094 - val_loss: 702624.1250 - val_mae: 272.8256\n",
      "Processing ./db/train_fb...\n",
      "Loaded 883879 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 614621.2500 - mae: 265.6361 - val_loss: 630184.0000 - val_mae: 260.6666\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 565424.3125 - mae: 256.2153 - val_loss: 627367.2500 - val_mae: 259.5358\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 545761.5000 - mae: 254.9415 - val_loss: 630049.0000 - val_mae: 260.8099\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 554939.5000 - mae: 255.6792 - val_loss: 629927.7500 - val_mae: 262.0034\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 544897.4375 - mae: 254.3774 - val_loss: 631265.4375 - val_mae: 261.3135\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 526035.1875 - mae: 252.4094 - val_loss: 632289.6875 - val_mae: 260.3954\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 519183.4062 - mae: 252.4013 - val_loss: 633265.8750 - val_mae: 261.1001\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 509162.7188 - mae: 251.1139 - val_loss: 631062.9375 - val_mae: 261.7750\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 513605.3750 - mae: 251.3076 - val_loss: 631389.6250 - val_mae: 262.3492\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 483994.7500 - mae: 249.2970 - val_loss: 632686.4375 - val_mae: 262.7616\n",
      "Processing ./db/train_fc...\n",
      "Loaded 883819 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 676431.6875 - mae: 270.6980 - val_loss: 591833.1875 - val_mae: 269.3690\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 612544.0000 - mae: 261.5940 - val_loss: 591925.7500 - val_mae: 271.5135\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 585417.4375 - mae: 259.6882 - val_loss: 591296.2500 - val_mae: 271.0742\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 569467.0625 - mae: 257.9450 - val_loss: 592827.6250 - val_mae: 274.4952\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 586373.7500 - mae: 259.6506 - val_loss: 594048.1250 - val_mae: 272.2638\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 557002.1250 - mae: 257.0972 - val_loss: 597034.4375 - val_mae: 276.1315\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 570443.1250 - mae: 258.8922 - val_loss: 597616.8750 - val_mae: 277.0595\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 575285.7500 - mae: 257.8087 - val_loss: 602028.8750 - val_mae: 278.4712\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 556171.6875 - mae: 256.7567 - val_loss: 604181.7500 - val_mae: 279.1006\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 544977.6250 - mae: 257.2229 - val_loss: 608095.4375 - val_mae: 278.8753\n",
      "Processing ./db/train_fd...\n",
      "Loaded 877643 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 706158.3750 - mae: 283.1583 - val_loss: 768307.3125 - val_mae: 278.4967\n",
      "Epoch 2/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 644213.3750 - mae: 273.2119 - val_loss: 768668.0625 - val_mae: 278.2661\n",
      "Epoch 3/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 619796.0625 - mae: 269.7607 - val_loss: 768936.3125 - val_mae: 278.9449\n",
      "Epoch 4/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 624056.5625 - mae: 270.9699 - val_loss: 772564.8750 - val_mae: 279.8484\n",
      "Epoch 5/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 602109.8750 - mae: 268.6836 - val_loss: 774922.8750 - val_mae: 282.6269\n",
      "Epoch 6/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 603319.3750 - mae: 269.1176 - val_loss: 777951.0000 - val_mae: 281.9677\n",
      "Epoch 7/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 597840.0625 - mae: 268.4143 - val_loss: 782118.0000 - val_mae: 282.9065\n",
      "Epoch 8/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 586408.3750 - mae: 267.7050 - val_loss: 785865.6250 - val_mae: 283.4090\n",
      "Epoch 9/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 581922.0625 - mae: 266.9254 - val_loss: 792636.9375 - val_mae: 283.9501\n",
      "Epoch 10/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 575827.1250 - mae: 266.5001 - val_loss: 788132.1250 - val_mae: 285.3243\n",
      "Processing ./db/train_fe...\n",
      "Loaded 873039 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 665599.3125 - mae: 274.6936 - val_loss: 691795.6250 - val_mae: 274.4450\n",
      "Epoch 2/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 609983.7500 - mae: 264.3136 - val_loss: 687804.1250 - val_mae: 277.8768\n",
      "Epoch 3/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 613981.0625 - mae: 265.6177 - val_loss: 688638.1875 - val_mae: 275.5389\n",
      "Epoch 4/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 617564.8125 - mae: 264.7693 - val_loss: 687656.7500 - val_mae: 276.5140\n",
      "Epoch 5/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 608048.0000 - mae: 264.2368 - val_loss: 689278.5625 - val_mae: 276.1695\n",
      "Epoch 6/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 584040.4375 - mae: 262.0602 - val_loss: 690985.9375 - val_mae: 277.2551\n",
      "Epoch 7/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 583740.5625 - mae: 261.0013 - val_loss: 698116.6250 - val_mae: 284.3693\n",
      "Epoch 8/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 554212.0625 - mae: 260.5203 - val_loss: 698475.3125 - val_mae: 279.1201\n",
      "Epoch 9/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 549847.1250 - mae: 259.1828 - val_loss: 701325.3750 - val_mae: 282.2879\n",
      "Epoch 10/10\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 554954.3750 - mae: 258.6617 - val_loss: 704860.0000 - val_mae: 282.5337\n",
      "Processing ./db/train_ff...\n",
      "Loaded 875956 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 634036.1875 - mae: 263.7716 - val_loss: 584364.6875 - val_mae: 268.5247\n",
      "Epoch 2/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 584831.5000 - mae: 257.6263 - val_loss: 586853.5000 - val_mae: 269.0313\n",
      "Epoch 3/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 567426.1250 - mae: 254.9910 - val_loss: 588426.1250 - val_mae: 270.6841\n",
      "Epoch 4/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 542592.6875 - mae: 252.9060 - val_loss: 592772.6875 - val_mae: 272.1953\n",
      "Epoch 5/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 568546.5625 - mae: 255.2787 - val_loss: 597066.7500 - val_mae: 271.9010\n",
      "Epoch 6/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 521089.7812 - mae: 252.4054 - val_loss: 597508.4375 - val_mae: 272.0596\n",
      "Epoch 7/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 522548.0625 - mae: 252.4185 - val_loss: 599414.2500 - val_mae: 272.1609\n",
      "Epoch 8/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 510922.1250 - mae: 250.7437 - val_loss: 603629.6250 - val_mae: 273.3293\n",
      "Epoch 9/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 511023.0312 - mae: 250.7372 - val_loss: 607369.7500 - val_mae: 274.1079\n",
      "Epoch 10/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 517611.1250 - mae: 251.5775 - val_loss: 611844.6250 - val_mae: 275.6284\n",
      "Processing ./db/train_fg...\n",
      "Loaded 875037 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 675131.4375 - mae: 269.9813 - val_loss: 700790.6250 - val_mae: 270.4507\n",
      "Epoch 2/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 620235.9375 - mae: 261.6664 - val_loss: 701906.0000 - val_mae: 268.0789\n",
      "Epoch 3/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 595822.8750 - mae: 260.3902 - val_loss: 705270.1875 - val_mae: 269.7220\n",
      "Epoch 4/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 587942.6875 - mae: 259.4049 - val_loss: 706535.4375 - val_mae: 272.0715\n",
      "Epoch 5/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 568476.3125 - mae: 258.2552 - val_loss: 711515.8125 - val_mae: 273.7555\n",
      "Epoch 6/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 572790.6250 - mae: 257.9575 - val_loss: 711656.2500 - val_mae: 272.4435\n",
      "Epoch 7/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 551542.5625 - mae: 256.8665 - val_loss: 715040.5000 - val_mae: 273.6488\n",
      "Epoch 8/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 551130.3125 - mae: 257.0219 - val_loss: 718223.0000 - val_mae: 274.9150\n",
      "Epoch 9/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 546995.1250 - mae: 256.4062 - val_loss: 719124.5000 - val_mae: 274.6448\n",
      "Epoch 10/10\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 553785.9375 - mae: 258.1472 - val_loss: 723242.0625 - val_mae: 274.3599\n",
      "Processing ./db/train_fh...\n",
      "Loaded 887759 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 661165.1875 - mae: 272.9253 - val_loss: 929005.6250 - val_mae: 292.9192\n",
      "Epoch 2/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 616437.0000 - mae: 261.0186 - val_loss: 924902.4375 - val_mae: 293.6243\n",
      "Epoch 3/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 580334.0000 - mae: 257.9771 - val_loss: 924994.1250 - val_mae: 291.0168\n",
      "Epoch 4/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 579657.5000 - mae: 257.1972 - val_loss: 924525.2500 - val_mae: 291.8660\n",
      "Epoch 5/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 569645.0000 - mae: 256.1843 - val_loss: 927433.5000 - val_mae: 292.9427\n",
      "Epoch 6/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 551236.0625 - mae: 254.6180 - val_loss: 931468.3750 - val_mae: 294.1228\n",
      "Epoch 7/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 548654.0000 - mae: 254.1191 - val_loss: 934656.3750 - val_mae: 295.7632\n",
      "Epoch 8/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 535319.7500 - mae: 253.4028 - val_loss: 939457.8750 - val_mae: 295.3939\n",
      "Epoch 9/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 533518.7500 - mae: 253.0598 - val_loss: 941841.8125 - val_mae: 297.9086\n",
      "Epoch 10/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 521761.8750 - mae: 252.2907 - val_loss: 947481.0000 - val_mae: 299.5623\n",
      "Processing ./db/train_fi...\n",
      "Loaded 897890 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 864347.7500 - mae: 291.8775 - val_loss: 649139.0625 - val_mae: 271.4292\n",
      "Epoch 2/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 797291.0000 - mae: 281.5052 - val_loss: 647570.7500 - val_mae: 268.1226\n",
      "Epoch 3/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 758784.9375 - mae: 278.8887 - val_loss: 649756.5625 - val_mae: 269.1396\n",
      "Epoch 4/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 725790.7500 - mae: 275.3658 - val_loss: 652874.9375 - val_mae: 273.7470\n",
      "Epoch 5/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 722443.6875 - mae: 276.2597 - val_loss: 654075.3750 - val_mae: 270.8649\n",
      "Epoch 6/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 704892.1250 - mae: 274.6332 - val_loss: 657119.2500 - val_mae: 271.8501\n",
      "Epoch 7/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 707390.5625 - mae: 275.3239 - val_loss: 662172.9375 - val_mae: 277.8406\n",
      "Epoch 8/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 683778.7500 - mae: 273.4903 - val_loss: 663982.8750 - val_mae: 274.8421\n",
      "Epoch 9/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 667186.7500 - mae: 272.1191 - val_loss: 666045.8750 - val_mae: 274.3987\n",
      "Epoch 10/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 666467.5625 - mae: 271.2586 - val_loss: 669080.1250 - val_mae: 274.5883\n",
      "Processing ./db/train_fj...\n",
      "Loaded 892410 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 765683.8125 - mae: 304.0582 - val_loss: 956185.8125 - val_mae: 338.0601\n",
      "Epoch 2/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 722895.0000 - mae: 298.0746 - val_loss: 955421.7500 - val_mae: 338.5885\n",
      "Epoch 3/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 713041.6250 - mae: 296.3521 - val_loss: 954900.6250 - val_mae: 338.6084\n",
      "Epoch 4/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 674736.1250 - mae: 292.8911 - val_loss: 957311.7500 - val_mae: 339.3124\n",
      "Epoch 5/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 654088.6875 - mae: 292.1154 - val_loss: 957496.3750 - val_mae: 339.9592\n",
      "Epoch 6/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 662730.2500 - mae: 292.1269 - val_loss: 959928.1250 - val_mae: 340.7369\n",
      "Epoch 7/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 651251.5625 - mae: 290.6657 - val_loss: 964173.0625 - val_mae: 340.8544\n",
      "Epoch 8/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 646383.1250 - mae: 291.1709 - val_loss: 968562.8750 - val_mae: 342.7929\n",
      "Epoch 9/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 628226.8750 - mae: 289.9696 - val_loss: 967983.4375 - val_mae: 344.0422\n",
      "Epoch 10/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 643231.2500 - mae: 289.8536 - val_loss: 973894.4375 - val_mae: 344.4291\n",
      "Processing ./db/train_fk...\n",
      "Loaded 886863 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 873959.2500 - mae: 336.8448 - val_loss: 919397.2500 - val_mae: 333.0935\n",
      "Epoch 2/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 791385.6875 - mae: 327.4893 - val_loss: 916824.0000 - val_mae: 333.0583\n",
      "Epoch 3/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 775902.1250 - mae: 325.9094 - val_loss: 914691.5000 - val_mae: 333.2968\n",
      "Epoch 4/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 767867.7500 - mae: 324.7434 - val_loss: 916204.2500 - val_mae: 333.8625\n",
      "Epoch 5/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 762261.2500 - mae: 324.3250 - val_loss: 915256.3750 - val_mae: 334.0473\n",
      "Epoch 6/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 755908.6250 - mae: 323.2479 - val_loss: 917482.5625 - val_mae: 334.9688\n",
      "Epoch 7/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 720786.8125 - mae: 320.8693 - val_loss: 921865.6250 - val_mae: 339.7837\n",
      "Epoch 8/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 733344.0000 - mae: 322.5697 - val_loss: 922333.1250 - val_mae: 337.1371\n",
      "Epoch 9/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 732242.1250 - mae: 321.9175 - val_loss: 925478.6250 - val_mae: 336.6745\n",
      "Epoch 10/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 741852.5625 - mae: 321.2639 - val_loss: 928792.0000 - val_mae: 337.4055\n",
      "Processing ./db/train_fl...\n",
      "Loaded 886706 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 926126.8125 - mae: 341.9929 - val_loss: 883168.9375 - val_mae: 342.6929\n",
      "Epoch 2/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 861812.3750 - mae: 333.9217 - val_loss: 884869.5625 - val_mae: 346.6233\n",
      "Epoch 3/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 854384.8750 - mae: 333.3495 - val_loss: 885263.1875 - val_mae: 343.6085\n",
      "Epoch 4/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 795324.2500 - mae: 328.0685 - val_loss: 887124.1250 - val_mae: 345.3060\n",
      "Epoch 5/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 806218.4375 - mae: 330.0258 - val_loss: 890233.3750 - val_mae: 345.1060\n",
      "Epoch 6/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 805039.0625 - mae: 328.9510 - val_loss: 892197.1250 - val_mae: 346.0506\n",
      "Epoch 7/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 811777.3125 - mae: 329.7456 - val_loss: 897464.2500 - val_mae: 346.2334\n",
      "Epoch 8/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 774788.1875 - mae: 326.3351 - val_loss: 898869.2500 - val_mae: 346.7852\n",
      "Epoch 9/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 780147.3125 - mae: 326.5910 - val_loss: 905135.3125 - val_mae: 347.0627\n",
      "Epoch 10/10\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 761688.1250 - mae: 325.3907 - val_loss: 906159.3750 - val_mae: 349.0006\n",
      "Processing ./db/train_fm...\n",
      "Loaded 879921 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 908271.0000 - mae: 345.2764 - val_loss: 989406.6875 - val_mae: 350.4130\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 862619.5000 - mae: 339.1824 - val_loss: 991501.3750 - val_mae: 351.1364\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 842682.8125 - mae: 337.7629 - val_loss: 995870.6875 - val_mae: 351.7029\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 830873.2500 - mae: 334.6411 - val_loss: 999462.9375 - val_mae: 353.6495\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 817662.5000 - mae: 334.7152 - val_loss: 1003850.5000 - val_mae: 355.4989\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 810942.5000 - mae: 334.2053 - val_loss: 1008117.3125 - val_mae: 354.8781\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 803211.8750 - mae: 332.9684 - val_loss: 1011295.8750 - val_mae: 357.2535\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 790161.1875 - mae: 333.0949 - val_loss: 1015968.6250 - val_mae: 357.4712\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 768324.5000 - mae: 330.5977 - val_loss: 1020048.7500 - val_mae: 357.4048\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 782768.8750 - mae: 331.5421 - val_loss: 1023496.5000 - val_mae: 359.3856\n",
      "Processing ./db/train_fn...\n",
      "Loaded 881158 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 941173.1250 - mae: 349.2113 - val_loss: 861446.6875 - val_mae: 340.6655\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 898778.1875 - mae: 340.5359 - val_loss: 865836.5625 - val_mae: 341.8683\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 853490.7500 - mae: 337.2935 - val_loss: 866068.8125 - val_mae: 342.2512\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 840742.7500 - mae: 335.1074 - val_loss: 870723.6875 - val_mae: 344.2882\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 822474.3125 - mae: 334.4710 - val_loss: 873934.0000 - val_mae: 344.8149\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 803970.6875 - mae: 333.5402 - val_loss: 879503.6250 - val_mae: 345.8210\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 807090.6250 - mae: 333.7436 - val_loss: 883052.5000 - val_mae: 348.4284\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 792753.6875 - mae: 332.4252 - val_loss: 886219.6875 - val_mae: 351.2788\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 796767.3125 - mae: 332.3607 - val_loss: 888643.4375 - val_mae: 349.3757\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 776436.2500 - mae: 331.4074 - val_loss: 891756.2500 - val_mae: 348.8918\n",
      "Processing ./db/train_fo...\n",
      "Loaded 880626 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 933330.5000 - mae: 350.5903 - val_loss: 871322.9375 - val_mae: 341.5835\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 876761.0000 - mae: 339.9276 - val_loss: 869239.8125 - val_mae: 341.7660\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 877587.7500 - mae: 338.9635 - val_loss: 870309.4375 - val_mae: 343.0735\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 817566.9375 - mae: 333.5273 - val_loss: 870769.8750 - val_mae: 342.6355\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 813947.5000 - mae: 333.5680 - val_loss: 873948.3125 - val_mae: 342.8664\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 809562.1250 - mae: 333.8147 - val_loss: 875540.9375 - val_mae: 343.1625\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 779824.5625 - mae: 331.4209 - val_loss: 878906.1875 - val_mae: 344.4402\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 790015.8125 - mae: 331.5115 - val_loss: 883011.6875 - val_mae: 343.5164\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 760784.1250 - mae: 328.5655 - val_loss: 885312.5625 - val_mae: 345.9205\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 770216.1875 - mae: 329.3741 - val_loss: 887223.8125 - val_mae: 345.9934\n",
      "Processing ./db/train_fp...\n",
      "Loaded 883562 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 878432.1250 - mae: 341.2081 - val_loss: 1061614.5000 - val_mae: 345.2614\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 802555.6875 - mae: 331.8211 - val_loss: 1046809.0625 - val_mae: 347.3314\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 795290.8125 - mae: 330.6895 - val_loss: 1055335.0000 - val_mae: 347.4604\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 758073.7500 - mae: 327.2734 - val_loss: 1057824.8750 - val_mae: 348.3958\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 775418.3750 - mae: 329.6433 - val_loss: 1066380.2500 - val_mae: 349.4037\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 757538.5000 - mae: 327.0556 - val_loss: 1092240.6250 - val_mae: 350.4200\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 749060.1875 - mae: 327.0762 - val_loss: 1130253.1250 - val_mae: 351.4153\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 748831.5625 - mae: 325.3887 - val_loss: 1168485.8750 - val_mae: 352.3041\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 716008.6250 - mae: 323.2381 - val_loss: 1221611.8750 - val_mae: 354.7555\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 718735.6250 - mae: 324.1764 - val_loss: 1294340.8750 - val_mae: 355.7632\n",
      "Processing ./db/train_fq...\n",
      "Loaded 877740 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 904578.6875 - mae: 344.1461 - val_loss: 839744.5625 - val_mae: 337.1958\n",
      "Epoch 2/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 842828.4375 - mae: 336.9657 - val_loss: 838826.7500 - val_mae: 338.4921\n",
      "Epoch 3/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 811721.5625 - mae: 333.2768 - val_loss: 841201.9375 - val_mae: 341.4298\n",
      "Epoch 4/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 827119.6250 - mae: 335.6679 - val_loss: 841482.0000 - val_mae: 338.7249\n",
      "Epoch 5/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 790780.1875 - mae: 331.7599 - val_loss: 844961.0000 - val_mae: 341.1777\n",
      "Epoch 6/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 799406.1250 - mae: 331.8066 - val_loss: 846705.2500 - val_mae: 341.4825\n",
      "Epoch 7/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 789580.1250 - mae: 331.8606 - val_loss: 849155.1250 - val_mae: 343.1709\n",
      "Epoch 8/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 780522.1875 - mae: 330.6169 - val_loss: 854426.8750 - val_mae: 344.6959\n",
      "Epoch 9/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 764111.0000 - mae: 329.6536 - val_loss: 853368.8750 - val_mae: 343.4789\n",
      "Epoch 10/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 767360.5000 - mae: 329.6176 - val_loss: 857161.1250 - val_mae: 345.1626\n",
      "Processing ./db/train_fr...\n",
      "Loaded 879591 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1195358.7500 - mae: 358.9816 - val_loss: 944625.7500 - val_mae: 356.3540\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 866295.3750 - mae: 341.2545 - val_loss: 942595.5625 - val_mae: 355.5312\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 854091.0625 - mae: 341.3432 - val_loss: 940779.6875 - val_mae: 356.0277\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 845970.6875 - mae: 339.5289 - val_loss: 945046.2500 - val_mae: 356.8404\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 812926.3125 - mae: 336.1921 - val_loss: 946371.3750 - val_mae: 358.2043\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 826193.6875 - mae: 337.7478 - val_loss: 948982.5625 - val_mae: 358.5105\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 792694.6250 - mae: 334.2122 - val_loss: 954106.4375 - val_mae: 359.2924\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 795563.7500 - mae: 334.9674 - val_loss: 956831.6875 - val_mae: 361.9609\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 796703.5000 - mae: 335.6654 - val_loss: 960178.2500 - val_mae: 362.1691\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 782513.8750 - mae: 333.8015 - val_loss: 961950.2500 - val_mae: 362.7892\n",
      "Processing ./db/train_fs...\n",
      "Loaded 878281 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 962502.5625 - mae: 351.3525 - val_loss: 800095.6250 - val_mae: 341.0224\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 901720.7500 - mae: 342.6921 - val_loss: 798670.3125 - val_mae: 340.7562\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 879776.9375 - mae: 341.4200 - val_loss: 800800.3125 - val_mae: 342.5544\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 865813.3125 - mae: 339.9304 - val_loss: 802912.0625 - val_mae: 341.9134\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 861235.5000 - mae: 338.5254 - val_loss: 808414.2500 - val_mae: 343.3624\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 849282.1250 - mae: 338.5301 - val_loss: 813783.1250 - val_mae: 347.6856\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 839952.0625 - mae: 337.3174 - val_loss: 815442.8750 - val_mae: 345.2531\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 813417.4375 - mae: 335.0578 - val_loss: 819492.1250 - val_mae: 345.4962\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 827285.2500 - mae: 335.8344 - val_loss: 823821.3125 - val_mae: 346.5466\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 799721.2500 - mae: 334.4266 - val_loss: 828883.7500 - val_mae: 347.5144\n",
      "Processing ./db/train_ft...\n",
      "Loaded 883573 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 940820.0000 - mae: 347.6923 - val_loss: 912444.8750 - val_mae: 339.1291\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 920167.2500 - mae: 342.5644 - val_loss: 912910.8125 - val_mae: 338.4085\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 870964.0000 - mae: 338.6696 - val_loss: 916384.9375 - val_mae: 339.7769\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 843990.7500 - mae: 337.1721 - val_loss: 922204.2500 - val_mae: 340.2835\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 815732.2500 - mae: 333.8884 - val_loss: 923532.4375 - val_mae: 342.6170\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 852831.2500 - mae: 337.2898 - val_loss: 928161.3125 - val_mae: 342.1828\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 848527.5000 - mae: 336.7698 - val_loss: 930695.6875 - val_mae: 341.6598\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 801789.7500 - mae: 333.1725 - val_loss: 933996.9375 - val_mae: 343.0115\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 797693.2500 - mae: 332.9660 - val_loss: 938858.4375 - val_mae: 344.2840\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 784156.7500 - mae: 332.3725 - val_loss: 942811.1250 - val_mae: 345.5495\n",
      "Processing ./db/train_fu...\n",
      "Loaded 879040 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 897605.0625 - mae: 347.0987 - val_loss: 1184212.1250 - val_mae: 345.2995\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 840254.7500 - mae: 338.2318 - val_loss: 1205669.5000 - val_mae: 347.2047\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 797676.9375 - mae: 334.9734 - val_loss: 1211514.1250 - val_mae: 347.1361\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 805716.3750 - mae: 337.4404 - val_loss: 1218018.0000 - val_mae: 348.0397\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 783519.0000 - mae: 334.0521 - val_loss: 1217251.2500 - val_mae: 354.2283\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 786632.4375 - mae: 334.6159 - val_loss: 1207227.7500 - val_mae: 349.0016\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 761476.5000 - mae: 332.1322 - val_loss: 1190586.5000 - val_mae: 349.4887\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 752240.5000 - mae: 330.8543 - val_loss: 1183905.8750 - val_mae: 349.4908\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 762126.8125 - mae: 331.8425 - val_loss: 1178772.6250 - val_mae: 350.6418\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 745508.3750 - mae: 330.0476 - val_loss: 1164524.0000 - val_mae: 350.8144\n",
      "Processing ./db/train_fv...\n",
      "Loaded 878658 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 870441.0000 - mae: 343.8357 - val_loss: 973772.8125 - val_mae: 351.5616\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 823986.8750 - mae: 337.0832 - val_loss: 972839.5625 - val_mae: 352.2078\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 812224.8125 - mae: 335.0156 - val_loss: 973094.6875 - val_mae: 351.6089\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 797849.8125 - mae: 334.8094 - val_loss: 974400.6875 - val_mae: 354.0662\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 794827.1875 - mae: 334.1576 - val_loss: 977616.7500 - val_mae: 352.3510\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 768249.7500 - mae: 331.5937 - val_loss: 980817.5000 - val_mae: 353.9680\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 764829.4375 - mae: 331.6107 - val_loss: 983937.4375 - val_mae: 356.0909\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 773831.8125 - mae: 332.8110 - val_loss: 986375.5625 - val_mae: 353.6225\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 767362.0625 - mae: 331.9020 - val_loss: 988147.1875 - val_mae: 355.2308\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 744358.4375 - mae: 329.5948 - val_loss: 993378.9375 - val_mae: 355.8492\n",
      "Processing ./db/train_fw...\n",
      "Loaded 879233 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 918650.3750 - mae: 344.7174 - val_loss: 1116609.6250 - val_mae: 360.8344\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 842331.4375 - mae: 337.0048 - val_loss: 1112912.0000 - val_mae: 359.9014\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 852275.2500 - mae: 336.6791 - val_loss: 1113244.5000 - val_mae: 361.1706\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 798070.9375 - mae: 333.8502 - val_loss: 1111375.2500 - val_mae: 361.2346\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 787965.0625 - mae: 331.3095 - val_loss: 1110575.0000 - val_mae: 360.9867\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 792950.4375 - mae: 331.5650 - val_loss: 1111146.7500 - val_mae: 362.0288\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 788138.8125 - mae: 331.4641 - val_loss: 1111175.3750 - val_mae: 361.8160\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 758593.6875 - mae: 329.6408 - val_loss: 1114708.2500 - val_mae: 363.5793\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 785418.0625 - mae: 330.7441 - val_loss: 1116155.6250 - val_mae: 363.5249\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 761265.3750 - mae: 328.3783 - val_loss: 1117120.0000 - val_mae: 367.5936\n",
      "Processing ./db/train_fx...\n",
      "Loaded 878647 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 964231.6875 - mae: 348.5290 - val_loss: 1082256.7500 - val_mae: 359.0128\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 870093.6875 - mae: 339.3050 - val_loss: 1083925.1250 - val_mae: 359.7752\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 853361.4375 - mae: 338.8323 - val_loss: 1080856.8750 - val_mae: 362.0033\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 858659.3125 - mae: 339.0076 - val_loss: 1086944.8750 - val_mae: 361.4922\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 860005.1250 - mae: 337.5388 - val_loss: 1091714.0000 - val_mae: 362.4028\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 824704.1875 - mae: 335.2169 - val_loss: 1097317.5000 - val_mae: 364.8003\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 821733.1250 - mae: 336.4827 - val_loss: 1104005.8750 - val_mae: 364.2758\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 803937.3750 - mae: 334.3590 - val_loss: 1107864.7500 - val_mae: 364.5767\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 760526.4375 - mae: 331.3983 - val_loss: 1101542.7500 - val_mae: 364.9523\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 800843.8750 - mae: 334.8717 - val_loss: 1105477.7500 - val_mae: 366.4771\n",
      "Processing ./db/train_fy...\n",
      "Loaded 881209 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 837463.4375 - mae: 338.6823 - val_loss: 980242.7500 - val_mae: 349.5312\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 780815.6250 - mae: 329.0457 - val_loss: 980291.8125 - val_mae: 350.5626\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 774477.4375 - mae: 328.1714 - val_loss: 979262.0625 - val_mae: 350.7388\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 745346.9375 - mae: 326.7772 - val_loss: 983585.8750 - val_mae: 351.4102\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 742646.0625 - mae: 326.0614 - val_loss: 986105.7500 - val_mae: 352.1070\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 713689.3750 - mae: 322.1488 - val_loss: 990804.5625 - val_mae: 352.4189\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 739505.8750 - mae: 325.3708 - val_loss: 993837.3750 - val_mae: 352.7241\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 730187.6250 - mae: 325.0007 - val_loss: 995745.9375 - val_mae: 353.6404\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 719311.3750 - mae: 323.0292 - val_loss: 1001015.0625 - val_mae: 354.8721\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 708417.8750 - mae: 322.1221 - val_loss: 1004095.3750 - val_mae: 354.9874\n",
      "Processing ./db/train_fz...\n",
      "Loaded 880269 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 940626.3750 - mae: 347.7408 - val_loss: 1098168.3750 - val_mae: 352.6553\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 867657.5625 - mae: 339.7740 - val_loss: 1096591.3750 - val_mae: 352.0204\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 842119.7500 - mae: 336.3784 - val_loss: 1094678.0000 - val_mae: 353.7934\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 828580.8750 - mae: 336.9910 - val_loss: 1096061.7500 - val_mae: 355.1101\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 816772.7500 - mae: 335.2007 - val_loss: 1095334.1250 - val_mae: 354.4573\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 833609.4375 - mae: 336.2648 - val_loss: 1097089.2500 - val_mae: 356.4431\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 799687.0625 - mae: 333.6646 - val_loss: 1097720.0000 - val_mae: 356.8917\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 809879.0625 - mae: 334.4967 - val_loss: 1096519.6250 - val_mae: 356.3209\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 791025.8125 - mae: 332.5017 - val_loss: 1101698.7500 - val_mae: 356.3087\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 805650.1875 - mae: 332.9422 - val_loss: 1104579.6250 - val_mae: 357.4860\n",
      "Processing ./db/train_ga...\n",
      "Loaded 882976 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 926651.8125 - mae: 344.8541 - val_loss: 876971.2500 - val_mae: 337.0724\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 896534.3750 - mae: 340.2717 - val_loss: 874061.9375 - val_mae: 338.2621\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 842336.2500 - mae: 334.6973 - val_loss: 875194.3125 - val_mae: 338.7396\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 839915.9375 - mae: 334.5572 - val_loss: 877869.3125 - val_mae: 339.6218\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 810336.2500 - mae: 331.2042 - val_loss: 881846.6250 - val_mae: 340.5081\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 801562.3125 - mae: 331.5833 - val_loss: 881945.9375 - val_mae: 340.4312\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 813172.9375 - mae: 332.6278 - val_loss: 886299.7500 - val_mae: 340.7918\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 798350.8125 - mae: 330.3286 - val_loss: 889752.2500 - val_mae: 342.5540\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 795065.6250 - mae: 329.0570 - val_loss: 892064.8750 - val_mae: 342.5505\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 781693.4375 - mae: 329.2885 - val_loss: 892333.1250 - val_mae: 342.7114\n",
      "Processing ./db/train_gb...\n",
      "Loaded 878987 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 868196.3125 - mae: 345.8476 - val_loss: 836847.0000 - val_mae: 334.8258\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 815354.7500 - mae: 335.8418 - val_loss: 833537.1875 - val_mae: 334.9413\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 800330.6875 - mae: 335.0391 - val_loss: 833789.6875 - val_mae: 335.5231\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 813004.0000 - mae: 334.2303 - val_loss: 836432.5625 - val_mae: 335.9238\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 762095.5625 - mae: 331.3036 - val_loss: 841111.1250 - val_mae: 337.6070\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 796117.1250 - mae: 334.4571 - val_loss: 843833.3125 - val_mae: 338.9090\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 758117.5625 - mae: 331.0208 - val_loss: 848044.5625 - val_mae: 338.2330\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 770846.1875 - mae: 331.4095 - val_loss: 849413.7500 - val_mae: 340.4603\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 742434.5000 - mae: 329.3647 - val_loss: 852869.4375 - val_mae: 341.3545\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 736991.2500 - mae: 328.3722 - val_loss: 856378.5625 - val_mae: 341.0957\n",
      "Processing ./db/train_gc...\n",
      "Loaded 878067 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 921946.6250 - mae: 347.9068 - val_loss: 887668.4375 - val_mae: 338.5201\n",
      "Epoch 2/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 857271.5000 - mae: 339.4998 - val_loss: 888117.0000 - val_mae: 340.5592\n",
      "Epoch 3/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 844152.5000 - mae: 338.7885 - val_loss: 890041.8125 - val_mae: 341.3822\n",
      "Epoch 4/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 836491.5625 - mae: 337.5176 - val_loss: 894421.6875 - val_mae: 341.2643\n",
      "Epoch 5/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 833430.3750 - mae: 337.1391 - val_loss: 898339.6875 - val_mae: 341.7176\n",
      "Epoch 6/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 781881.6875 - mae: 333.1906 - val_loss: 902147.1875 - val_mae: 344.1978\n",
      "Epoch 7/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 802721.5625 - mae: 334.9922 - val_loss: 903600.0625 - val_mae: 345.4978\n",
      "Epoch 8/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 790783.9375 - mae: 333.0242 - val_loss: 907325.9375 - val_mae: 345.8088\n",
      "Epoch 9/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 780145.3750 - mae: 333.4092 - val_loss: 910611.6250 - val_mae: 344.9843\n",
      "Epoch 10/10\n",
      "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 772738.1250 - mae: 332.4110 - val_loss: 916419.0625 - val_mae: 347.0709\n",
      "Processing ./db/train_gd...\n",
      "Loaded 882055 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 896600.6250 - mae: 347.1020 - val_loss: 881749.4375 - val_mae: 341.8138\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 850481.5000 - mae: 339.2752 - val_loss: 883147.3125 - val_mae: 342.5877\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 826461.0000 - mae: 336.8775 - val_loss: 885286.7500 - val_mae: 342.3138\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 794694.4375 - mae: 334.0492 - val_loss: 887389.6875 - val_mae: 344.1912\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 775173.5625 - mae: 332.8798 - val_loss: 890851.1250 - val_mae: 346.5284\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 788515.8750 - mae: 334.1887 - val_loss: 893028.7500 - val_mae: 344.5243\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 745117.3750 - mae: 328.1570 - val_loss: 897217.0625 - val_mae: 346.9525\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 776706.7500 - mae: 332.2005 - val_loss: 897978.7500 - val_mae: 346.5212\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 757960.6250 - mae: 330.4611 - val_loss: 903107.0625 - val_mae: 347.8607\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 741784.7500 - mae: 329.3710 - val_loss: 906677.8750 - val_mae: 348.2593\n",
      "Processing ./db/train_ge...\n",
      "Loaded 883705 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 868131.4375 - mae: 336.2862 - val_loss: 1012527.4375 - val_mae: 357.7213\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 802540.6875 - mae: 329.0140 - val_loss: 1012511.0000 - val_mae: 353.9018\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 790977.8125 - mae: 327.5691 - val_loss: 1014709.2500 - val_mae: 354.6707\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 790788.3125 - mae: 327.7940 - val_loss: 1021706.5625 - val_mae: 355.3105\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 786105.3125 - mae: 326.3120 - val_loss: 1024913.5000 - val_mae: 355.9733\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 785491.6250 - mae: 325.9785 - val_loss: 1030626.1875 - val_mae: 361.1945\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 772821.6875 - mae: 325.8927 - val_loss: 1033485.8125 - val_mae: 358.1460\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 751002.6875 - mae: 322.8145 - val_loss: 1036605.1875 - val_mae: 358.6421\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 750243.2500 - mae: 323.2908 - val_loss: 1039484.5625 - val_mae: 359.8222\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 734740.8750 - mae: 321.9329 - val_loss: 1043486.9375 - val_mae: 360.7608\n",
      "Processing ./db/train_gf...\n",
      "Loaded 876017 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 904440.5625 - mae: 342.4370 - val_loss: 1029039.5625 - val_mae: 352.6424\n",
      "Epoch 2/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 872210.7500 - mae: 335.8476 - val_loss: 1083755.5000 - val_mae: 354.6264\n",
      "Epoch 3/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 845442.3125 - mae: 333.6875 - val_loss: 1043617.8125 - val_mae: 354.2825\n",
      "Epoch 4/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 823696.0000 - mae: 332.2705 - val_loss: 1025446.9375 - val_mae: 355.1844\n",
      "Epoch 5/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 807981.5000 - mae: 329.8658 - val_loss: 1031990.0000 - val_mae: 353.7458\n",
      "Epoch 6/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 786784.6875 - mae: 328.3481 - val_loss: 1068557.1250 - val_mae: 356.2364\n",
      "Epoch 7/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 787541.1250 - mae: 328.7685 - val_loss: 1040297.5000 - val_mae: 354.5435\n",
      "Epoch 8/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 778978.6875 - mae: 327.8896 - val_loss: 1045920.7500 - val_mae: 355.9907\n",
      "Epoch 9/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 785382.7500 - mae: 327.9995 - val_loss: 1049699.2500 - val_mae: 356.6686\n",
      "Epoch 10/10\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 785088.6250 - mae: 328.0834 - val_loss: 1054173.0000 - val_mae: 357.2215\n",
      "Processing ./db/train_gg...\n",
      "Loaded 881872 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 922572.3750 - mae: 340.9577 - val_loss: 964964.6250 - val_mae: 339.6696\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 845790.5000 - mae: 330.4132 - val_loss: 965497.4375 - val_mae: 340.5326\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 825075.9375 - mae: 329.4022 - val_loss: 971325.1875 - val_mae: 340.9272\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 796078.3125 - mae: 327.0188 - val_loss: 974396.5000 - val_mae: 342.2191\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 813968.7500 - mae: 330.2466 - val_loss: 979575.7500 - val_mae: 343.2282\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 776271.5625 - mae: 325.1656 - val_loss: 983821.8750 - val_mae: 343.5073\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 780688.1250 - mae: 325.9235 - val_loss: 989258.5625 - val_mae: 343.4557\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 781615.0625 - mae: 325.4516 - val_loss: 1001545.9375 - val_mae: 343.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 743939.6875 - mae: 323.4451 - val_loss: 1013596.1250 - val_mae: 344.8075\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 751710.5000 - mae: 323.2448 - val_loss: 1018799.4375 - val_mae: 345.4353\n",
      "Processing ./db/train_gh...\n",
      "Loaded 884291 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 911814.8125 - mae: 344.4363 - val_loss: 943709.8125 - val_mae: 340.3888\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 856683.5625 - mae: 335.2065 - val_loss: 942887.7500 - val_mae: 339.6905\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 830151.5625 - mae: 332.5012 - val_loss: 944715.3125 - val_mae: 341.5416\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 818356.7500 - mae: 331.9431 - val_loss: 948174.6875 - val_mae: 341.3264\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 803610.6250 - mae: 330.3189 - val_loss: 951811.1250 - val_mae: 342.9882\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 790771.5000 - mae: 329.0888 - val_loss: 953579.1875 - val_mae: 342.8123\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 777718.7500 - mae: 329.3810 - val_loss: 956444.8125 - val_mae: 343.7334\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 782634.5000 - mae: 328.2714 - val_loss: 960143.3125 - val_mae: 344.4243\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 775501.6875 - mae: 328.6036 - val_loss: 961142.3125 - val_mae: 343.7221\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 762292.2500 - mae: 326.8694 - val_loss: 963577.2500 - val_mae: 345.9557\n",
      "Processing ./db/train_gi...\n",
      "Loaded 884440 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 860979.6250 - mae: 333.1334 - val_loss: 926680.8750 - val_mae: 346.9590\n",
      "Epoch 2/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 806634.5000 - mae: 326.8306 - val_loss: 926412.0625 - val_mae: 346.0489\n",
      "Epoch 3/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 788787.6250 - mae: 325.5758 - val_loss: 928434.2500 - val_mae: 346.8682\n",
      "Epoch 4/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 780910.3125 - mae: 324.2040 - val_loss: 931815.5625 - val_mae: 347.7594\n",
      "Epoch 5/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 749235.6875 - mae: 322.3235 - val_loss: 938123.7500 - val_mae: 348.9085\n",
      "Epoch 6/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 769548.5625 - mae: 324.2056 - val_loss: 937857.3125 - val_mae: 350.6330\n",
      "Epoch 7/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 756765.1875 - mae: 323.0387 - val_loss: 938523.4375 - val_mae: 349.9249\n",
      "Epoch 8/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 720971.3750 - mae: 319.2030 - val_loss: 943089.6875 - val_mae: 351.4327\n",
      "Epoch 9/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 751192.3125 - mae: 322.4140 - val_loss: 947359.8125 - val_mae: 351.9878\n",
      "Epoch 10/10\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 716749.6875 - mae: 318.7126 - val_loss: 953342.5000 - val_mae: 350.9019\n",
      "Processing ./db/train_gj...\n",
      "Loaded 880847 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 887396.2500 - mae: 338.1829 - val_loss: 890520.1875 - val_mae: 340.6750\n",
      "Epoch 2/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 835744.8125 - mae: 329.8163 - val_loss: 891170.9375 - val_mae: 342.2575\n",
      "Epoch 3/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 802706.8125 - mae: 326.6705 - val_loss: 892412.0000 - val_mae: 342.3044\n",
      "Epoch 4/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 807786.6250 - mae: 325.7084 - val_loss: 893614.5625 - val_mae: 341.7960\n",
      "Epoch 5/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 779903.1250 - mae: 324.2804 - val_loss: 894739.1250 - val_mae: 341.9383\n",
      "Epoch 6/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 797987.9375 - mae: 325.6754 - val_loss: 895188.6875 - val_mae: 341.5451\n",
      "Epoch 7/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 746960.8750 - mae: 320.8827 - val_loss: 899231.6875 - val_mae: 344.1810\n",
      "Epoch 8/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 749811.9375 - mae: 321.5004 - val_loss: 899525.0625 - val_mae: 344.1354\n",
      "Epoch 9/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 751130.5000 - mae: 322.1015 - val_loss: 901689.5625 - val_mae: 343.3940\n",
      "Epoch 10/10\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 760602.8750 - mae: 321.7135 - val_loss: 903639.7500 - val_mae: 345.3864\n",
      "Processing ./db/train_gk...\n",
      "Loaded 884949 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 885097.2500 - mae: 337.5977 - val_loss: 754944.3125 - val_mae: 327.1490\n",
      "Epoch 2/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 835215.1875 - mae: 329.9676 - val_loss: 756881.2500 - val_mae: 331.1460\n",
      "Epoch 3/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 831197.1250 - mae: 330.3401 - val_loss: 759993.8750 - val_mae: 328.8258\n",
      "Epoch 4/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 829143.3125 - mae: 329.4442 - val_loss: 762679.4375 - val_mae: 329.0840\n",
      "Epoch 5/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 814004.0625 - mae: 329.0128 - val_loss: 764234.5625 - val_mae: 329.7995\n",
      "Epoch 6/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 798529.3750 - mae: 326.7918 - val_loss: 768760.8750 - val_mae: 333.5510\n",
      "Epoch 7/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 804070.1875 - mae: 326.8685 - val_loss: 771103.5625 - val_mae: 333.7921\n",
      "Epoch 8/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 803373.4375 - mae: 327.6895 - val_loss: 770582.1250 - val_mae: 331.1520\n",
      "Epoch 9/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 794349.2500 - mae: 325.9493 - val_loss: 773774.8125 - val_mae: 333.5319\n",
      "Epoch 10/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 771663.4375 - mae: 323.7393 - val_loss: 775222.8125 - val_mae: 332.6833\n",
      "Processing ./db/train_gl...\n",
      "Loaded 884489 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 908322.7500 - mae: 340.7193 - val_loss: 823982.1875 - val_mae: 338.5863\n",
      "Epoch 2/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 827349.1250 - mae: 332.2298 - val_loss: 822679.1250 - val_mae: 340.5757\n",
      "Epoch 3/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 844117.1250 - mae: 333.2017 - val_loss: 822418.3125 - val_mae: 339.5921\n",
      "Epoch 4/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 807013.2500 - mae: 331.0637 - val_loss: 824315.3125 - val_mae: 339.4370\n",
      "Epoch 5/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 794677.4375 - mae: 329.7480 - val_loss: 830129.6875 - val_mae: 349.3018\n",
      "Epoch 6/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 776791.6875 - mae: 328.8517 - val_loss: 832122.1875 - val_mae: 349.3956\n",
      "Epoch 7/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 800474.3750 - mae: 332.8882 - val_loss: 830636.6250 - val_mae: 341.7217\n",
      "Epoch 8/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 762166.3125 - mae: 326.1446 - val_loss: 831908.5625 - val_mae: 342.3837\n",
      "Epoch 9/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 772098.8125 - mae: 328.0573 - val_loss: 839486.5625 - val_mae: 348.3567\n",
      "Epoch 10/10\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 771478.7500 - mae: 327.7614 - val_loss: 837030.1250 - val_mae: 343.6312\n",
      "Processing ./db/train_gm...\n",
      "Loaded 879824 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 946114.1250 - mae: 346.1396 - val_loss: 977200.5625 - val_mae: 323.4072\n",
      "Epoch 2/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 887531.3125 - mae: 337.8452 - val_loss: 975156.4375 - val_mae: 325.0293\n",
      "Epoch 3/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 864627.2500 - mae: 335.7446 - val_loss: 974180.2500 - val_mae: 322.2392\n",
      "Epoch 4/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 832628.6250 - mae: 333.9776 - val_loss: 977169.5625 - val_mae: 323.2370\n",
      "Epoch 5/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 829313.5000 - mae: 332.9615 - val_loss: 978775.0000 - val_mae: 323.6886\n",
      "Epoch 6/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 810074.0625 - mae: 330.7852 - val_loss: 981952.7500 - val_mae: 326.5836\n",
      "Epoch 7/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 802335.8750 - mae: 331.0680 - val_loss: 983312.3750 - val_mae: 326.1132\n",
      "Epoch 8/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 810916.8750 - mae: 331.2114 - val_loss: 985064.6875 - val_mae: 325.8849\n",
      "Epoch 9/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 806998.7500 - mae: 330.1046 - val_loss: 988176.9375 - val_mae: 325.5405\n",
      "Epoch 10/10\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 806709.5625 - mae: 329.8390 - val_loss: 992261.0000 - val_mae: 326.0702\n",
      "Processing ./db/train_gn...\n",
      "Loaded 888141 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1062831.6250 - mae: 328.7732 - val_loss: 934460.5000 - val_mae: 312.9152\n",
      "Epoch 2/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 986768.6250 - mae: 316.9790 - val_loss: 938098.0000 - val_mae: 314.4253\n",
      "Epoch 3/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 972688.7500 - mae: 315.6205 - val_loss: 943689.8750 - val_mae: 315.8056\n",
      "Epoch 4/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 960245.6875 - mae: 315.4890 - val_loss: 948115.6875 - val_mae: 316.8228\n",
      "Epoch 5/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 961332.3125 - mae: 315.7289 - val_loss: 952586.4375 - val_mae: 316.5150\n",
      "Epoch 6/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 927220.6250 - mae: 313.6773 - val_loss: 957315.3125 - val_mae: 318.1936\n",
      "Epoch 7/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 915883.4375 - mae: 313.7831 - val_loss: 960140.1875 - val_mae: 318.3934\n",
      "Epoch 8/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 909413.8125 - mae: 311.8602 - val_loss: 965416.5000 - val_mae: 321.0199\n",
      "Epoch 9/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 890374.5000 - mae: 311.0455 - val_loss: 968461.5625 - val_mae: 322.4378\n",
      "Epoch 10/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 870003.4375 - mae: 310.4212 - val_loss: 971170.5625 - val_mae: 324.2478\n",
      "Processing ./db/train_go...\n",
      "Loaded 896405 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1051658.8750 - mae: 329.0840 - val_loss: 1177767.8750 - val_mae: 339.0167\n",
      "Epoch 2/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1018319.5000 - mae: 322.1708 - val_loss: 1178659.6250 - val_mae: 337.9539\n",
      "Epoch 3/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 979535.0625 - mae: 319.3678 - val_loss: 1177336.1250 - val_mae: 337.7510\n",
      "Epoch 4/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 974698.6250 - mae: 318.1844 - val_loss: 1182834.7500 - val_mae: 338.5183\n",
      "Epoch 5/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 928118.5625 - mae: 314.4101 - val_loss: 1191062.1250 - val_mae: 338.8128\n",
      "Epoch 6/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 939757.0000 - mae: 315.5585 - val_loss: 1191444.6250 - val_mae: 339.9911\n",
      "Epoch 7/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 899916.3750 - mae: 313.0749 - val_loss: 1196502.3750 - val_mae: 340.3301\n",
      "Epoch 8/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 884670.2500 - mae: 311.2034 - val_loss: 1198701.3750 - val_mae: 341.8228\n",
      "Epoch 9/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 904589.8125 - mae: 312.2666 - val_loss: 1207219.0000 - val_mae: 342.2981\n",
      "Epoch 10/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 847907.7500 - mae: 308.8578 - val_loss: 1210299.7500 - val_mae: 346.4428\n",
      "Processing ./db/train_gp...\n",
      "Loaded 898770 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1006315.6250 - mae: 321.1136 - val_loss: 969028.0000 - val_mae: 308.7118\n",
      "Epoch 2/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 940500.6250 - mae: 312.2026 - val_loss: 966761.2500 - val_mae: 309.0199\n",
      "Epoch 3/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 943583.3125 - mae: 310.6746 - val_loss: 968197.6875 - val_mae: 310.9360\n",
      "Epoch 4/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 889224.7500 - mae: 307.9049 - val_loss: 966206.4375 - val_mae: 312.7029\n",
      "Epoch 5/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 857872.0625 - mae: 306.7442 - val_loss: 968794.7500 - val_mae: 312.7900\n",
      "Epoch 6/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 859194.2500 - mae: 306.8253 - val_loss: 972396.2500 - val_mae: 312.3459\n",
      "Epoch 7/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 846116.3125 - mae: 305.8821 - val_loss: 972838.5000 - val_mae: 312.8203\n",
      "Epoch 8/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 851586.0000 - mae: 305.9355 - val_loss: 976131.0625 - val_mae: 318.5338\n",
      "Epoch 9/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 840143.1875 - mae: 304.5384 - val_loss: 982275.2500 - val_mae: 320.3459\n",
      "Epoch 10/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 824710.8125 - mae: 303.8845 - val_loss: 981785.7500 - val_mae: 315.6890\n",
      "Processing ./db/train_gq...\n",
      "Loaded 904261 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 788234.9375 - mae: 298.6380 - val_loss: 1117418.7500 - val_mae: 325.8716\n",
      "Epoch 2/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 740117.5000 - mae: 288.7671 - val_loss: 1113056.6250 - val_mae: 325.1411\n",
      "Epoch 3/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 744788.0000 - mae: 288.6073 - val_loss: 1114723.8750 - val_mae: 324.4725\n",
      "Epoch 4/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 727477.2500 - mae: 286.6908 - val_loss: 1115186.3750 - val_mae: 325.6684\n",
      "Epoch 5/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 703755.4375 - mae: 284.8846 - val_loss: 1123283.5000 - val_mae: 326.7549\n",
      "Epoch 6/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 707376.9375 - mae: 285.7819 - val_loss: 1128903.2500 - val_mae: 331.0376\n",
      "Epoch 7/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 686730.7500 - mae: 285.0066 - val_loss: 1129773.6250 - val_mae: 330.1580\n",
      "Epoch 8/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 676912.6250 - mae: 283.6559 - val_loss: 1136137.6250 - val_mae: 331.7650\n",
      "Epoch 9/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 683519.3750 - mae: 285.2725 - val_loss: 1140168.2500 - val_mae: 332.7318\n",
      "Epoch 10/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 674922.1250 - mae: 282.6430 - val_loss: 1144807.0000 - val_mae: 332.8940\n",
      "Processing ./db/train_gr...\n",
      "Loaded 891186 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 955221.2500 - mae: 317.7320 - val_loss: 867336.7500 - val_mae: 311.6880\n",
      "Epoch 2/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 871230.6875 - mae: 308.7187 - val_loss: 869923.5625 - val_mae: 313.8052\n",
      "Epoch 3/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 831164.0000 - mae: 305.3621 - val_loss: 871423.3125 - val_mae: 310.2091\n",
      "Epoch 4/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 826567.5625 - mae: 305.7534 - val_loss: 875952.3125 - val_mae: 313.1346\n",
      "Epoch 5/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 832287.0625 - mae: 306.0175 - val_loss: 879464.3750 - val_mae: 312.0558\n",
      "Epoch 6/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 810789.3125 - mae: 304.2805 - val_loss: 882793.8750 - val_mae: 312.0640\n",
      "Epoch 7/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 812819.5000 - mae: 303.7041 - val_loss: 885472.6875 - val_mae: 312.5519\n",
      "Epoch 8/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 799818.3125 - mae: 303.6488 - val_loss: 887003.8125 - val_mae: 314.5676\n",
      "Epoch 9/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 789867.5625 - mae: 303.7252 - val_loss: 890487.7500 - val_mae: 314.5653\n",
      "Epoch 10/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 776424.1875 - mae: 301.7827 - val_loss: 894280.8125 - val_mae: 314.7274\n",
      "Processing ./db/train_gs...\n",
      "Loaded 900881 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 924652.0000 - mae: 311.3005 - val_loss: 891499.1875 - val_mae: 303.3649\n",
      "Epoch 2/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 843412.7500 - mae: 301.7749 - val_loss: 890584.4375 - val_mae: 302.3512\n",
      "Epoch 3/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 819101.4375 - mae: 298.9027 - val_loss: 891100.9375 - val_mae: 305.0027\n",
      "Epoch 4/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 798059.0000 - mae: 297.8837 - val_loss: 894157.4375 - val_mae: 302.9502\n",
      "Epoch 5/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 805273.1250 - mae: 297.2452 - val_loss: 895505.1875 - val_mae: 304.2005\n",
      "Epoch 6/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 808109.1250 - mae: 298.2861 - val_loss: 899420.7500 - val_mae: 307.2770\n",
      "Epoch 7/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 783285.0000 - mae: 297.4314 - val_loss: 900261.6875 - val_mae: 305.0256\n",
      "Epoch 8/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 788563.1875 - mae: 296.6344 - val_loss: 904618.5625 - val_mae: 305.4629\n",
      "Epoch 9/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 784914.1875 - mae: 295.6292 - val_loss: 907548.2500 - val_mae: 306.3578\n",
      "Epoch 10/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 758950.5000 - mae: 295.5154 - val_loss: 909304.2500 - val_mae: 306.6487\n",
      "Processing ./db/train_gt...\n",
      "Loaded 905911 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 944824.6250 - mae: 308.9136 - val_loss: 823858.9375 - val_mae: 300.6156\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 950847.6250 - mae: 306.5387 - val_loss: 825278.8125 - val_mae: 299.4031\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 900008.5625 - mae: 302.8098 - val_loss: 826375.0625 - val_mae: 297.6852\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 898339.6875 - mae: 303.0930 - val_loss: 830333.7500 - val_mae: 299.2134\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 866922.8125 - mae: 301.6503 - val_loss: 832738.9375 - val_mae: 301.4729\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 843299.1875 - mae: 299.2348 - val_loss: 838576.3750 - val_mae: 301.5595\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 817292.1250 - mae: 299.1330 - val_loss: 843611.4375 - val_mae: 301.2322\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 820784.9375 - mae: 297.8981 - val_loss: 843632.6875 - val_mae: 303.7095\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 812949.1250 - mae: 299.4298 - val_loss: 851392.6875 - val_mae: 305.5777\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 809790.6250 - mae: 297.6766 - val_loss: 851757.1875 - val_mae: 304.5924\n",
      "Processing ./db/train_gu...\n",
      "Loaded 900345 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 946256.8125 - mae: 315.4985 - val_loss: 910840.4375 - val_mae: 302.1919\n",
      "Epoch 2/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 892403.6250 - mae: 307.4843 - val_loss: 906852.3750 - val_mae: 302.9148\n",
      "Epoch 3/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 848175.6875 - mae: 303.4421 - val_loss: 907921.1875 - val_mae: 303.9358\n",
      "Epoch 4/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 817784.1250 - mae: 301.3834 - val_loss: 910035.9375 - val_mae: 304.0901\n",
      "Epoch 5/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 840544.0625 - mae: 302.3071 - val_loss: 911769.5000 - val_mae: 302.9308\n",
      "Epoch 6/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 809809.6250 - mae: 299.7976 - val_loss: 913647.6875 - val_mae: 304.9405\n",
      "Epoch 7/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 797334.5625 - mae: 299.1782 - val_loss: 915694.8125 - val_mae: 305.6134\n",
      "Epoch 8/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 784087.1875 - mae: 298.4118 - val_loss: 919140.7500 - val_mae: 308.2062\n",
      "Epoch 9/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 779492.8125 - mae: 299.4423 - val_loss: 920528.6250 - val_mae: 305.3546\n",
      "Epoch 10/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 762547.1250 - mae: 296.5780 - val_loss: 925195.2500 - val_mae: 305.4614\n",
      "Processing ./db/train_gv...\n",
      "Loaded 895459 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 978702.0625 - mae: 317.4966 - val_loss: 1201028.6250 - val_mae: 314.1216\n",
      "Epoch 2/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 923081.1875 - mae: 309.7154 - val_loss: 1201327.1250 - val_mae: 316.5184\n",
      "Epoch 3/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 888895.0625 - mae: 307.7287 - val_loss: 1186274.0000 - val_mae: 314.4242\n",
      "Epoch 4/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 862564.3750 - mae: 306.6773 - val_loss: 1192120.6250 - val_mae: 313.8269\n",
      "Epoch 5/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 876447.1875 - mae: 306.5573 - val_loss: 1189302.8750 - val_mae: 315.2173\n",
      "Epoch 6/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 859889.7500 - mae: 306.2297 - val_loss: 1198912.3750 - val_mae: 315.4428\n",
      "Epoch 7/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 838044.2500 - mae: 304.7204 - val_loss: 1205457.0000 - val_mae: 315.9539\n",
      "Epoch 8/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 835662.1875 - mae: 304.2162 - val_loss: 1216867.7500 - val_mae: 315.9521\n",
      "Epoch 9/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 785207.9375 - mae: 299.9922 - val_loss: 1217461.1250 - val_mae: 319.8103\n",
      "Epoch 10/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 804427.8750 - mae: 303.0891 - val_loss: 1240206.1250 - val_mae: 320.8638\n",
      "Processing ./db/train_gw...\n",
      "Loaded 894626 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 1007864.1250 - mae: 319.6291 - val_loss: 969939.0000 - val_mae: 318.0444\n",
      "Epoch 2/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 889416.2500 - mae: 308.5519 - val_loss: 963475.0625 - val_mae: 319.7785\n",
      "Epoch 3/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 899944.6250 - mae: 308.3295 - val_loss: 968741.1250 - val_mae: 318.2757\n",
      "Epoch 4/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 876334.5000 - mae: 306.0501 - val_loss: 967300.7500 - val_mae: 318.8677\n",
      "Epoch 5/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 868094.7500 - mae: 306.0091 - val_loss: 968566.6875 - val_mae: 319.3659\n",
      "Epoch 6/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 808795.0000 - mae: 302.2588 - val_loss: 970240.0625 - val_mae: 322.6699\n",
      "Epoch 7/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 865412.9375 - mae: 307.3638 - val_loss: 971441.1875 - val_mae: 320.0831\n",
      "Epoch 8/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 813133.3750 - mae: 302.5189 - val_loss: 969244.6250 - val_mae: 320.6672\n",
      "Epoch 9/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 801197.0000 - mae: 302.0399 - val_loss: 967701.6875 - val_mae: 321.8788\n",
      "Epoch 10/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 794767.4375 - mae: 301.7267 - val_loss: 972548.1875 - val_mae: 321.5300\n",
      "Processing ./db/train_gx...\n",
      "Loaded 899195 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 880973.6875 - mae: 306.5681 - val_loss: 942848.8750 - val_mae: 310.5034\n",
      "Epoch 2/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 815147.3750 - mae: 298.6042 - val_loss: 939940.1250 - val_mae: 310.9964\n",
      "Epoch 3/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 821632.6250 - mae: 298.5106 - val_loss: 941216.1250 - val_mae: 311.7400\n",
      "Epoch 4/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 780176.8750 - mae: 295.5723 - val_loss: 940887.3125 - val_mae: 312.1464\n",
      "Epoch 5/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 763296.7500 - mae: 295.1964 - val_loss: 945854.7500 - val_mae: 312.4820\n",
      "Epoch 6/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 794756.5000 - mae: 297.7631 - val_loss: 946450.1875 - val_mae: 314.0971\n",
      "Epoch 7/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 769255.5625 - mae: 295.3901 - val_loss: 948903.6875 - val_mae: 314.8589\n",
      "Epoch 8/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 742510.0625 - mae: 293.1030 - val_loss: 950891.6250 - val_mae: 315.0160\n",
      "Epoch 9/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 744798.9375 - mae: 293.6747 - val_loss: 952752.1250 - val_mae: 314.8454\n",
      "Epoch 10/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 749976.2500 - mae: 293.5523 - val_loss: 957547.7500 - val_mae: 315.0835\n",
      "Processing ./db/train_gy...\n",
      "Loaded 896694 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 912158.8125 - mae: 311.1256 - val_loss: 942423.2500 - val_mae: 319.1178\n",
      "Epoch 2/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 874926.0625 - mae: 303.7777 - val_loss: 942485.6875 - val_mae: 320.9091\n",
      "Epoch 3/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 849600.9375 - mae: 302.1888 - val_loss: 944193.4375 - val_mae: 322.0211\n",
      "Epoch 4/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 851911.4375 - mae: 301.1603 - val_loss: 947558.3125 - val_mae: 325.6294\n",
      "Epoch 5/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 826082.3125 - mae: 299.7773 - val_loss: 949842.0625 - val_mae: 321.8221\n",
      "Epoch 6/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 837761.0625 - mae: 301.7501 - val_loss: 950359.8125 - val_mae: 324.8629\n",
      "Epoch 7/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 800627.6875 - mae: 298.8184 - val_loss: 951917.1875 - val_mae: 322.0122\n",
      "Epoch 8/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 770933.6250 - mae: 296.4318 - val_loss: 955835.3125 - val_mae: 326.8915\n",
      "Epoch 9/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 781193.3125 - mae: 296.7210 - val_loss: 955081.6875 - val_mae: 327.8941\n",
      "Epoch 10/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 768985.4375 - mae: 297.5363 - val_loss: 958832.6875 - val_mae: 325.6080\n",
      "Processing ./db/train_gz...\n",
      "Loaded 896583 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 985458.0000 - mae: 315.8031 - val_loss: 975850.7500 - val_mae: 317.0294\n",
      "Epoch 2/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 916997.5625 - mae: 309.7490 - val_loss: 971221.8750 - val_mae: 319.5795\n",
      "Epoch 3/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 894168.0000 - mae: 308.9197 - val_loss: 967987.5000 - val_mae: 316.9412\n",
      "Epoch 4/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 862910.6250 - mae: 305.8888 - val_loss: 973027.8125 - val_mae: 318.9944\n",
      "Epoch 5/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 852297.2500 - mae: 306.3401 - val_loss: 974607.3750 - val_mae: 320.8511\n",
      "Epoch 6/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 841262.6875 - mae: 305.2883 - val_loss: 975668.8750 - val_mae: 321.4716\n",
      "Epoch 7/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 830285.3125 - mae: 304.4646 - val_loss: 979381.3750 - val_mae: 320.7915\n",
      "Epoch 8/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 831251.9375 - mae: 303.9781 - val_loss: 985527.1250 - val_mae: 322.4344\n",
      "Epoch 9/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 813838.6250 - mae: 304.1271 - val_loss: 995404.3125 - val_mae: 323.3858\n",
      "Epoch 10/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 825822.6250 - mae: 304.8808 - val_loss: 1015901.3750 - val_mae: 324.0385\n",
      "Processing ./db/train_ha...\n",
      "Loaded 900209 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 936190.8750 - mae: 315.0079 - val_loss: 856436.8125 - val_mae: 297.4924\n",
      "Epoch 2/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 864893.6875 - mae: 304.8246 - val_loss: 854763.5625 - val_mae: 298.9152\n",
      "Epoch 3/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 849090.0625 - mae: 302.8309 - val_loss: 854005.0625 - val_mae: 297.9882\n",
      "Epoch 4/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 842324.5000 - mae: 303.2202 - val_loss: 856447.0000 - val_mae: 299.0401\n",
      "Epoch 5/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 785606.5000 - mae: 298.5102 - val_loss: 862771.8125 - val_mae: 303.6313\n",
      "Epoch 6/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 790848.8750 - mae: 300.3652 - val_loss: 863063.5625 - val_mae: 301.4742\n",
      "Epoch 7/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 802385.0625 - mae: 300.9404 - val_loss: 864912.8125 - val_mae: 300.9179\n",
      "Epoch 8/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 776378.9375 - mae: 299.2534 - val_loss: 865348.3125 - val_mae: 302.2306\n",
      "Epoch 9/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 771141.3125 - mae: 299.3202 - val_loss: 870217.6875 - val_mae: 302.2796\n",
      "Epoch 10/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 753301.9375 - mae: 298.8168 - val_loss: 873532.9375 - val_mae: 305.2284\n",
      "Processing ./db/train_hb...\n",
      "Loaded 906375 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 876846.3125 - mae: 306.7396 - val_loss: 773945.8125 - val_mae: 304.5252\n",
      "Epoch 2/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 815167.6875 - mae: 296.5454 - val_loss: 771003.0000 - val_mae: 303.6523\n",
      "Epoch 3/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 810718.3750 - mae: 295.2271 - val_loss: 771731.6250 - val_mae: 305.2884\n",
      "Epoch 4/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 786496.3125 - mae: 294.6561 - val_loss: 774027.6875 - val_mae: 310.2904\n",
      "Epoch 5/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 769478.1875 - mae: 292.6820 - val_loss: 776476.5000 - val_mae: 307.4566\n",
      "Epoch 6/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 756849.4375 - mae: 294.0337 - val_loss: 778860.0000 - val_mae: 307.5621\n",
      "Epoch 7/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 734355.4375 - mae: 291.2093 - val_loss: 781817.0000 - val_mae: 309.1199\n",
      "Epoch 8/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 725050.6250 - mae: 291.3096 - val_loss: 785211.0000 - val_mae: 308.5281\n",
      "Epoch 9/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 729240.7500 - mae: 290.7287 - val_loss: 788182.6250 - val_mae: 310.0792\n",
      "Epoch 10/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 740297.8125 - mae: 291.5798 - val_loss: 789238.8750 - val_mae: 309.3968\n",
      "Processing ./db/train_hc...\n",
      "Loaded 896505 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 978321.8125 - mae: 323.4054 - val_loss: 840177.1875 - val_mae: 298.0192\n",
      "Epoch 2/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 909167.4375 - mae: 313.3950 - val_loss: 838928.7500 - val_mae: 296.2906\n",
      "Epoch 3/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 855832.3125 - mae: 310.4495 - val_loss: 838966.3125 - val_mae: 297.1734\n",
      "Epoch 4/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 831361.5625 - mae: 306.7845 - val_loss: 842390.6875 - val_mae: 302.9875\n",
      "Epoch 5/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 842650.5625 - mae: 309.3324 - val_loss: 841848.8125 - val_mae: 299.6561\n",
      "Epoch 6/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 824597.2500 - mae: 308.2848 - val_loss: 845704.4375 - val_mae: 299.2925\n",
      "Epoch 7/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 801594.5625 - mae: 305.6361 - val_loss: 854033.9375 - val_mae: 307.6686\n",
      "Epoch 8/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 807091.3750 - mae: 305.7691 - val_loss: 851868.0625 - val_mae: 300.4729\n",
      "Epoch 9/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 795022.6250 - mae: 305.2002 - val_loss: 854100.4375 - val_mae: 303.1832\n",
      "Epoch 10/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 785337.6875 - mae: 305.2079 - val_loss: 856808.3125 - val_mae: 300.1158\n",
      "Processing ./db/train_hd...\n",
      "Loaded 891839 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1098898.5000 - mae: 338.1600 - val_loss: 855434.6875 - val_mae: 298.2181\n",
      "Epoch 2/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1019705.8750 - mae: 329.5568 - val_loss: 856166.6875 - val_mae: 298.0644\n",
      "Epoch 3/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 957550.1875 - mae: 324.4145 - val_loss: 858510.5625 - val_mae: 299.8406\n",
      "Epoch 4/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 959362.6875 - mae: 324.7192 - val_loss: 862621.6250 - val_mae: 303.4136\n",
      "Epoch 5/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 943135.0625 - mae: 323.0956 - val_loss: 860085.2500 - val_mae: 299.4373\n",
      "Epoch 6/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 930231.3750 - mae: 322.0683 - val_loss: 863635.4375 - val_mae: 301.6166\n",
      "Epoch 7/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 937976.9375 - mae: 323.7864 - val_loss: 864411.3125 - val_mae: 301.0947\n",
      "Epoch 8/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 917375.1250 - mae: 320.6963 - val_loss: 868794.3125 - val_mae: 302.5020\n",
      "Epoch 9/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 926576.8750 - mae: 321.4431 - val_loss: 869065.2500 - val_mae: 302.7597\n",
      "Epoch 10/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 902724.5000 - mae: 320.2049 - val_loss: 869833.1875 - val_mae: 301.8166\n",
      "Processing ./db/train_he...\n",
      "Loaded 895857 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 913400.6250 - mae: 314.6023 - val_loss: 884514.2500 - val_mae: 326.4155\n",
      "Epoch 2/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 830131.6875 - mae: 300.9991 - val_loss: 878823.1875 - val_mae: 326.5999\n",
      "Epoch 3/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 833177.3750 - mae: 301.0986 - val_loss: 881925.6875 - val_mae: 326.3857\n",
      "Epoch 4/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 782784.9375 - mae: 296.4279 - val_loss: 879173.1875 - val_mae: 326.7021\n",
      "Epoch 5/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 792118.8125 - mae: 298.6794 - val_loss: 883895.2500 - val_mae: 325.7603\n",
      "Epoch 6/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 802219.3125 - mae: 299.0858 - val_loss: 883721.0625 - val_mae: 327.1584\n",
      "Epoch 7/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 773226.7500 - mae: 297.1812 - val_loss: 886985.3750 - val_mae: 329.1817\n",
      "Epoch 8/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 769126.3750 - mae: 296.3001 - val_loss: 888448.1875 - val_mae: 329.0460\n",
      "Epoch 9/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 759381.8125 - mae: 294.7132 - val_loss: 889175.1875 - val_mae: 328.9576\n",
      "Epoch 10/10\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 753277.7500 - mae: 294.6614 - val_loss: 892578.4375 - val_mae: 330.6064\n",
      "Processing ./db/train_hf...\n",
      "Loaded 902111 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 877592.4375 - mae: 305.7027 - val_loss: 1008469.0000 - val_mae: 321.8255\n",
      "Epoch 2/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 817920.3750 - mae: 299.3207 - val_loss: 1006829.3750 - val_mae: 322.5959\n",
      "Epoch 3/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 787819.1250 - mae: 295.9057 - val_loss: 1010234.1250 - val_mae: 322.9652\n",
      "Epoch 4/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 763662.1250 - mae: 295.2444 - val_loss: 1013216.9375 - val_mae: 323.0999\n",
      "Epoch 5/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 752403.7500 - mae: 294.1208 - val_loss: 1016561.0000 - val_mae: 325.6937\n",
      "Epoch 6/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 743209.8750 - mae: 292.2444 - val_loss: 1019385.6875 - val_mae: 325.9507\n",
      "Epoch 7/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 740294.1875 - mae: 292.7534 - val_loss: 1019856.6875 - val_mae: 325.6783\n",
      "Epoch 8/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 749575.0000 - mae: 292.8795 - val_loss: 1026526.8125 - val_mae: 324.8382\n",
      "Epoch 9/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 728562.6250 - mae: 291.6425 - val_loss: 1029795.3750 - val_mae: 328.8205\n",
      "Epoch 10/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 710200.8125 - mae: 291.0418 - val_loss: 1031678.7500 - val_mae: 327.6108\n",
      "Processing ./db/train_hg...\n",
      "Loaded 896369 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 907230.1250 - mae: 311.3331 - val_loss: 962909.2500 - val_mae: 313.7660\n",
      "Epoch 2/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 859523.5000 - mae: 302.5206 - val_loss: 960938.7500 - val_mae: 312.6581\n",
      "Epoch 3/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 848582.8750 - mae: 301.5241 - val_loss: 960951.9375 - val_mae: 314.2693\n",
      "Epoch 4/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 823840.1875 - mae: 300.7947 - val_loss: 962732.5625 - val_mae: 313.9864\n",
      "Epoch 5/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 815963.3750 - mae: 298.9304 - val_loss: 964543.7500 - val_mae: 314.6269\n",
      "Epoch 6/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 791381.3125 - mae: 296.4997 - val_loss: 969460.4375 - val_mae: 315.8302\n",
      "Epoch 7/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 785947.0625 - mae: 297.7620 - val_loss: 973136.4375 - val_mae: 317.7811\n",
      "Epoch 8/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 769947.3125 - mae: 296.1655 - val_loss: 975260.2500 - val_mae: 318.4628\n",
      "Epoch 9/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 784286.7500 - mae: 296.7361 - val_loss: 978819.3125 - val_mae: 319.5474\n",
      "Epoch 10/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 748806.9375 - mae: 295.2290 - val_loss: 982145.1250 - val_mae: 319.5643\n",
      "Processing ./db/train_hh...\n",
      "Loaded 892896 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1033560.4375 - mae: 327.8557 - val_loss: 973957.3125 - val_mae: 312.2065\n",
      "Epoch 2/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 925990.3125 - mae: 316.6554 - val_loss: 974401.3125 - val_mae: 312.8317\n",
      "Epoch 3/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 942330.8125 - mae: 317.3071 - val_loss: 977268.6875 - val_mae: 315.8430\n",
      "Epoch 4/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 924085.4375 - mae: 316.1079 - val_loss: 978601.1250 - val_mae: 315.0454\n",
      "Epoch 5/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 906435.6250 - mae: 315.9323 - val_loss: 982287.0625 - val_mae: 314.5028\n",
      "Epoch 6/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 884490.6250 - mae: 314.4075 - val_loss: 988488.4375 - val_mae: 316.5125\n",
      "Epoch 7/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 861917.5000 - mae: 313.5318 - val_loss: 992163.9375 - val_mae: 317.6643\n",
      "Epoch 8/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 852401.9375 - mae: 313.3993 - val_loss: 997205.6875 - val_mae: 318.3659\n",
      "Epoch 9/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 836913.0625 - mae: 312.3209 - val_loss: 1002391.8750 - val_mae: 318.7587\n",
      "Epoch 10/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 844687.3750 - mae: 312.6854 - val_loss: 1002072.3125 - val_mae: 319.4552\n",
      "Processing ./db/train_hi...\n",
      "Loaded 891793 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 919666.8750 - mae: 317.2414 - val_loss: 1135966.7500 - val_mae: 344.5713\n",
      "Epoch 2/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 863674.1250 - mae: 307.9153 - val_loss: 1127704.2500 - val_mae: 344.7271\n",
      "Epoch 3/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 852177.0625 - mae: 306.3663 - val_loss: 1128263.1250 - val_mae: 345.9060\n",
      "Epoch 4/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 823528.8125 - mae: 303.3308 - val_loss: 1131268.0000 - val_mae: 345.8150\n",
      "Epoch 5/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 814649.8125 - mae: 302.5570 - val_loss: 1137706.2500 - val_mae: 348.9305\n",
      "Epoch 6/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 797875.3125 - mae: 303.0446 - val_loss: 1143828.6250 - val_mae: 351.0849\n",
      "Epoch 7/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 798588.5625 - mae: 303.5056 - val_loss: 1149222.2500 - val_mae: 350.0767\n",
      "Epoch 8/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 795033.1250 - mae: 301.5891 - val_loss: 1154457.0000 - val_mae: 352.4510\n",
      "Epoch 9/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 762511.7500 - mae: 299.2685 - val_loss: 1157565.1250 - val_mae: 352.5341\n",
      "Epoch 10/10\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 750907.5625 - mae: 298.0246 - val_loss: 1164634.5000 - val_mae: 355.4813\n",
      "Processing ./db/train_hj...\n",
      "Loaded 902460 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 909439.9375 - mae: 315.4695 - val_loss: 818770.1250 - val_mae: 297.5816\n",
      "Epoch 2/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 855713.1875 - mae: 307.1184 - val_loss: 815533.8125 - val_mae: 290.7055\n",
      "Epoch 3/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 827240.5000 - mae: 305.7039 - val_loss: 815137.7500 - val_mae: 290.4221\n",
      "Epoch 4/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 792358.9375 - mae: 300.9774 - val_loss: 818282.2500 - val_mae: 293.9654\n",
      "Epoch 5/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 798802.1250 - mae: 301.8243 - val_loss: 820941.4375 - val_mae: 292.0335\n",
      "Epoch 6/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 799744.0625 - mae: 301.1145 - val_loss: 821290.5000 - val_mae: 290.6486\n",
      "Epoch 7/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 773254.3750 - mae: 299.0950 - val_loss: 822452.4375 - val_mae: 291.4595\n",
      "Epoch 8/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 788836.9375 - mae: 300.9068 - val_loss: 825958.1250 - val_mae: 292.6562\n",
      "Epoch 9/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 748963.3125 - mae: 297.6169 - val_loss: 828306.3750 - val_mae: 292.6819\n",
      "Epoch 10/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 759942.9375 - mae: 297.4119 - val_loss: 828230.5625 - val_mae: 291.9986\n",
      "Processing ./db/train_hk...\n",
      "Loaded 903801 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 781429.6875 - mae: 286.7191 - val_loss: 861038.6250 - val_mae: 287.9695\n",
      "Epoch 2/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 733851.5000 - mae: 277.4274 - val_loss: 862058.5625 - val_mae: 293.9006\n",
      "Epoch 3/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 735838.7500 - mae: 277.1544 - val_loss: 861377.6250 - val_mae: 289.4877\n",
      "Epoch 4/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 717847.0625 - mae: 274.8052 - val_loss: 863921.6250 - val_mae: 288.8984\n",
      "Epoch 5/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 666944.0000 - mae: 270.7859 - val_loss: 865323.7500 - val_mae: 289.6819\n",
      "Epoch 6/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 697846.9375 - mae: 273.4067 - val_loss: 870649.0000 - val_mae: 289.6042\n",
      "Epoch 7/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 667390.5000 - mae: 271.7158 - val_loss: 871686.0625 - val_mae: 290.9542\n",
      "Epoch 8/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 670226.5625 - mae: 271.2318 - val_loss: 876028.3750 - val_mae: 290.9256\n",
      "Epoch 9/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 643037.3750 - mae: 268.4220 - val_loss: 878051.1250 - val_mae: 291.2691\n",
      "Epoch 10/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 639495.5000 - mae: 269.2438 - val_loss: 880593.3125 - val_mae: 292.6438\n",
      "Processing ./db/train_hl...\n",
      "Loaded 897215 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 788958.8750 - mae: 285.9342 - val_loss: 700382.3125 - val_mae: 275.1734\n",
      "Epoch 2/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 759134.5625 - mae: 280.2276 - val_loss: 704109.0625 - val_mae: 276.8394\n",
      "Epoch 3/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 716073.3125 - mae: 277.4068 - val_loss: 709893.1250 - val_mae: 278.4771\n",
      "Epoch 4/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 686849.8125 - mae: 276.2558 - val_loss: 708210.4375 - val_mae: 278.0533\n",
      "Epoch 5/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 669232.5000 - mae: 274.4817 - val_loss: 713056.4375 - val_mae: 276.4012\n",
      "Epoch 6/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 669812.2500 - mae: 273.4554 - val_loss: 713764.6875 - val_mae: 277.9304\n",
      "Epoch 7/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 654414.0000 - mae: 271.9120 - val_loss: 716464.8125 - val_mae: 277.6984\n",
      "Epoch 8/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 660720.0000 - mae: 272.3535 - val_loss: 721055.0625 - val_mae: 276.2989\n",
      "Epoch 9/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 662645.1875 - mae: 273.1321 - val_loss: 719867.9375 - val_mae: 278.1914\n",
      "Epoch 10/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 638881.1875 - mae: 270.6581 - val_loss: 720561.4375 - val_mae: 279.8914\n",
      "Processing ./db/train_hm...\n",
      "Loaded 902531 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 800987.1250 - mae: 290.1958 - val_loss: 736171.2500 - val_mae: 276.8769\n",
      "Epoch 2/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 748159.1250 - mae: 283.1444 - val_loss: 734131.0625 - val_mae: 279.9420\n",
      "Epoch 3/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 752488.1875 - mae: 283.0814 - val_loss: 732872.0625 - val_mae: 278.7184\n",
      "Epoch 4/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 747671.8750 - mae: 283.9826 - val_loss: 734575.5625 - val_mae: 280.6795\n",
      "Epoch 5/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 717006.2500 - mae: 280.3252 - val_loss: 735713.9375 - val_mae: 279.8960\n",
      "Epoch 6/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 675559.6250 - mae: 278.0692 - val_loss: 735119.6250 - val_mae: 280.6400\n",
      "Epoch 7/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 690261.0000 - mae: 279.4772 - val_loss: 736007.1250 - val_mae: 281.5856\n",
      "Epoch 8/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 669235.6875 - mae: 276.4919 - val_loss: 737897.3125 - val_mae: 280.9137\n",
      "Epoch 9/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 687807.6875 - mae: 278.3366 - val_loss: 740894.2500 - val_mae: 283.8497\n",
      "Epoch 10/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 665581.3125 - mae: 276.7561 - val_loss: 741526.6875 - val_mae: 281.9912\n",
      "Processing ./db/train_hn...\n",
      "Loaded 898643 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 834798.6250 - mae: 292.7102 - val_loss: 746633.8125 - val_mae: 280.2039\n",
      "Epoch 2/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 793904.4375 - mae: 286.7676 - val_loss: 747982.5625 - val_mae: 279.5893\n",
      "Epoch 3/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 783708.3125 - mae: 285.2981 - val_loss: 749416.2500 - val_mae: 283.4438\n",
      "Epoch 4/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 766149.7500 - mae: 284.1229 - val_loss: 750501.4375 - val_mae: 284.2581\n",
      "Epoch 5/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 771354.5000 - mae: 284.9439 - val_loss: 753602.8125 - val_mae: 282.6339\n",
      "Epoch 6/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 725369.2500 - mae: 281.9534 - val_loss: 757598.5000 - val_mae: 284.1006\n",
      "Epoch 7/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 731297.8125 - mae: 282.4038 - val_loss: 760568.4375 - val_mae: 284.3796\n",
      "Epoch 8/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 724671.3125 - mae: 281.7734 - val_loss: 763717.6875 - val_mae: 285.2176\n",
      "Epoch 9/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 721223.2500 - mae: 281.7814 - val_loss: 767074.3125 - val_mae: 285.8507\n",
      "Epoch 10/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 715188.0000 - mae: 281.0850 - val_loss: 775450.1250 - val_mae: 289.3713\n",
      "Processing ./db/train_ho...\n",
      "Loaded 894700 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 835081.7500 - mae: 301.0800 - val_loss: 931389.0000 - val_mae: 301.8952\n",
      "Epoch 2/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 819829.7500 - mae: 291.7616 - val_loss: 931255.0625 - val_mae: 301.5711\n",
      "Epoch 3/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 767686.5000 - mae: 287.0437 - val_loss: 934989.5625 - val_mae: 304.6764\n",
      "Epoch 4/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 782716.5000 - mae: 287.7012 - val_loss: 934959.0625 - val_mae: 304.1469\n",
      "Epoch 5/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 777772.0625 - mae: 287.5955 - val_loss: 938034.2500 - val_mae: 304.4269\n",
      "Epoch 6/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 745066.8750 - mae: 285.6926 - val_loss: 942972.5625 - val_mae: 305.8123\n",
      "Epoch 7/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 772686.8125 - mae: 286.5031 - val_loss: 944058.9375 - val_mae: 307.2129\n",
      "Epoch 8/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 749484.5625 - mae: 285.9780 - val_loss: 945160.1875 - val_mae: 307.4194\n",
      "Epoch 9/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 752481.6875 - mae: 285.8213 - val_loss: 947268.2500 - val_mae: 307.8521\n",
      "Epoch 10/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 761823.1250 - mae: 287.0826 - val_loss: 951293.1875 - val_mae: 313.1695\n",
      "Processing ./db/train_hp...\n",
      "Loaded 905222 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 655278.3750 - mae: 264.9046 - val_loss: 770816.5625 - val_mae: 275.1059\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 625338.0000 - mae: 259.6677 - val_loss: 770124.1875 - val_mae: 274.6964\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 626797.4375 - mae: 259.2622 - val_loss: 771325.4375 - val_mae: 274.9051\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 598473.5000 - mae: 256.2747 - val_loss: 773500.8125 - val_mae: 276.6073\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 584845.9375 - mae: 255.6869 - val_loss: 778461.6875 - val_mae: 276.8674\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 589901.2500 - mae: 256.8019 - val_loss: 777593.1875 - val_mae: 278.1556\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 581505.3750 - mae: 256.5903 - val_loss: 781881.5625 - val_mae: 278.5113\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 580455.1250 - mae: 256.3147 - val_loss: 785590.5625 - val_mae: 283.5013\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 576854.2500 - mae: 256.0926 - val_loss: 786901.3125 - val_mae: 281.5079\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 581979.6250 - mae: 255.6015 - val_loss: 786831.7500 - val_mae: 280.1263\n",
      "Processing ./db/train_hq...\n",
      "Loaded 907030 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 724404.5625 - mae: 273.3203 - val_loss: 843375.2500 - val_mae: 284.0246\n",
      "Epoch 2/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 662186.0000 - mae: 265.0237 - val_loss: 845815.0000 - val_mae: 283.4083\n",
      "Epoch 3/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 637954.5625 - mae: 263.1314 - val_loss: 849302.0000 - val_mae: 285.8444\n",
      "Epoch 4/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 620472.1875 - mae: 262.1338 - val_loss: 851448.2500 - val_mae: 286.5724\n",
      "Epoch 5/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 636124.8125 - mae: 262.9516 - val_loss: 853537.3750 - val_mae: 286.7721\n",
      "Epoch 6/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 609193.4375 - mae: 262.2269 - val_loss: 856753.8125 - val_mae: 286.8742\n",
      "Epoch 7/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 604543.0000 - mae: 260.5616 - val_loss: 858716.6250 - val_mae: 288.1917\n",
      "Epoch 8/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 604185.4375 - mae: 260.7137 - val_loss: 864255.4375 - val_mae: 292.3226\n",
      "Epoch 9/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 569816.8125 - mae: 258.6961 - val_loss: 866018.5000 - val_mae: 290.2931\n",
      "Epoch 10/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 592909.7500 - mae: 261.9574 - val_loss: 866089.6250 - val_mae: 290.6147\n",
      "Processing ./db/train_hr...\n",
      "Loaded 898455 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 773600.0000 - mae: 284.5388 - val_loss: 758126.6250 - val_mae: 276.4865\n",
      "Epoch 2/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 749958.0625 - mae: 279.2313 - val_loss: 755076.0625 - val_mae: 274.0400\n",
      "Epoch 3/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 722775.5625 - mae: 276.0469 - val_loss: 755924.5000 - val_mae: 276.4549\n",
      "Epoch 4/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 710940.0000 - mae: 275.3883 - val_loss: 758187.8750 - val_mae: 276.8902\n",
      "Epoch 5/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 703830.5625 - mae: 274.4143 - val_loss: 757653.6875 - val_mae: 276.8383\n",
      "Epoch 6/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 715603.8750 - mae: 275.4055 - val_loss: 758118.1875 - val_mae: 277.2498\n",
      "Epoch 7/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 686638.0625 - mae: 273.1521 - val_loss: 762118.3125 - val_mae: 279.2003\n",
      "Epoch 8/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 676193.8750 - mae: 274.0275 - val_loss: 763250.6875 - val_mae: 279.2774\n",
      "Epoch 9/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 702724.1875 - mae: 275.6297 - val_loss: 763446.2500 - val_mae: 277.5914\n",
      "Epoch 10/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 673752.7500 - mae: 272.0643 - val_loss: 764065.9375 - val_mae: 276.8982\n",
      "Processing ./db/train_hs...\n",
      "Loaded 904810 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 753119.0625 - mae: 275.9964 - val_loss: 793088.1250 - val_mae: 270.6586\n",
      "Epoch 2/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 739689.5625 - mae: 271.9940 - val_loss: 797072.6875 - val_mae: 273.3753\n",
      "Epoch 3/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 714166.0625 - mae: 269.9260 - val_loss: 796756.1875 - val_mae: 271.5680\n",
      "Epoch 4/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 671395.5000 - mae: 266.4744 - val_loss: 800105.7500 - val_mae: 272.1904\n",
      "Epoch 5/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 688246.3125 - mae: 267.9176 - val_loss: 803564.9375 - val_mae: 273.5944\n",
      "Epoch 6/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 669254.4375 - mae: 267.9068 - val_loss: 806059.5625 - val_mae: 275.6772\n",
      "Epoch 7/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 646588.4375 - mae: 265.9489 - val_loss: 807436.6875 - val_mae: 274.1596\n",
      "Epoch 8/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 673228.3750 - mae: 267.1285 - val_loss: 810123.8125 - val_mae: 274.7375\n",
      "Epoch 9/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 625422.3125 - mae: 264.2468 - val_loss: 813039.3125 - val_mae: 276.2762\n",
      "Epoch 10/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 633970.7500 - mae: 266.3309 - val_loss: 814402.5625 - val_mae: 277.1086\n",
      "Processing ./db/train_ht...\n",
      "Loaded 906519 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 698959.9375 - mae: 273.0556 - val_loss: 737885.1875 - val_mae: 274.1877\n",
      "Epoch 2/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 643397.9375 - mae: 265.2632 - val_loss: 738220.6875 - val_mae: 275.3741\n",
      "Epoch 3/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 624697.8125 - mae: 263.8045 - val_loss: 740114.9375 - val_mae: 275.0860\n",
      "Epoch 4/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 597798.8750 - mae: 261.3195 - val_loss: 741321.1250 - val_mae: 280.1336\n",
      "Epoch 5/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 622886.3125 - mae: 263.0591 - val_loss: 742288.5000 - val_mae: 275.9340\n",
      "Epoch 6/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 589312.8125 - mae: 260.6684 - val_loss: 748684.2500 - val_mae: 278.2554\n",
      "Epoch 7/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 604869.3125 - mae: 262.3846 - val_loss: 747917.7500 - val_mae: 278.5673\n",
      "Epoch 8/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 590925.0000 - mae: 260.8067 - val_loss: 750999.6875 - val_mae: 276.8537\n",
      "Epoch 9/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 589536.1875 - mae: 262.1990 - val_loss: 755380.2500 - val_mae: 281.3204\n",
      "Epoch 10/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 576721.1250 - mae: 261.1418 - val_loss: 755485.0625 - val_mae: 279.2594\n",
      "Processing ./db/train_hu...\n",
      "Loaded 901460 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 921508.9375 - mae: 293.6882 - val_loss: 666185.4375 - val_mae: 274.1939\n",
      "Epoch 2/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 865898.3125 - mae: 287.6483 - val_loss: 668654.7500 - val_mae: 277.7021\n",
      "Epoch 3/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 807669.2500 - mae: 283.4856 - val_loss: 673976.5625 - val_mae: 278.1983\n",
      "Epoch 4/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 818742.1250 - mae: 283.9549 - val_loss: 677654.8750 - val_mae: 278.5265\n",
      "Epoch 5/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 805177.6875 - mae: 283.0384 - val_loss: 680798.1875 - val_mae: 278.3232\n",
      "Epoch 6/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 797527.6250 - mae: 283.0050 - val_loss: 685989.5625 - val_mae: 281.0486\n",
      "Epoch 7/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 806427.5000 - mae: 284.0396 - val_loss: 688478.0000 - val_mae: 280.5749\n",
      "Epoch 8/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 779827.5000 - mae: 281.7640 - val_loss: 693454.8750 - val_mae: 282.2433\n",
      "Epoch 9/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 753255.3125 - mae: 279.6753 - val_loss: 697402.3125 - val_mae: 282.3136\n",
      "Epoch 10/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 732574.3125 - mae: 279.3648 - val_loss: 700153.0625 - val_mae: 284.4772\n",
      "Processing ./db/train_hv...\n",
      "Loaded 902867 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 802834.8125 - mae: 283.9380 - val_loss: 687017.0625 - val_mae: 277.2305\n",
      "Epoch 2/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 727124.0625 - mae: 275.6934 - val_loss: 681845.5000 - val_mae: 273.7521\n",
      "Epoch 3/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 702818.6250 - mae: 272.3093 - val_loss: 681960.1875 - val_mae: 275.6124\n",
      "Epoch 4/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 710925.1250 - mae: 272.7340 - val_loss: 682999.0000 - val_mae: 275.1414\n",
      "Epoch 5/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 705727.7500 - mae: 272.9513 - val_loss: 683444.6250 - val_mae: 274.6302\n",
      "Epoch 6/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 671070.2500 - mae: 270.2201 - val_loss: 686716.1875 - val_mae: 278.1842\n",
      "Epoch 7/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 666333.2500 - mae: 271.0612 - val_loss: 689018.0625 - val_mae: 278.7811\n",
      "Epoch 8/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 673358.8125 - mae: 271.0968 - val_loss: 689243.6250 - val_mae: 276.6050\n",
      "Epoch 9/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 660149.8750 - mae: 270.1893 - val_loss: 691772.5000 - val_mae: 281.4594\n",
      "Epoch 10/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 653495.3125 - mae: 270.3899 - val_loss: 691886.1250 - val_mae: 277.7697\n",
      "Processing ./db/train_hw...\n",
      "Loaded 908927 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 753807.5625 - mae: 281.2061 - val_loss: 795735.1250 - val_mae: 287.5072\n",
      "Epoch 2/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 701039.9375 - mae: 271.3172 - val_loss: 793020.6875 - val_mae: 284.6257\n",
      "Epoch 3/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 673910.1250 - mae: 269.6743 - val_loss: 793764.6250 - val_mae: 285.1357\n",
      "Epoch 4/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 657523.6875 - mae: 269.3622 - val_loss: 798454.8750 - val_mae: 286.5494\n",
      "Epoch 5/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 655206.0000 - mae: 267.7860 - val_loss: 802700.4375 - val_mae: 291.5474\n",
      "Epoch 6/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 636348.8125 - mae: 266.7355 - val_loss: 804871.1875 - val_mae: 289.1525\n",
      "Epoch 7/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 646014.8750 - mae: 267.8058 - val_loss: 807041.7500 - val_mae: 285.4017\n",
      "Epoch 8/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 639437.9375 - mae: 267.1375 - val_loss: 810147.3750 - val_mae: 287.6785\n",
      "Epoch 9/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 618259.2500 - mae: 266.0885 - val_loss: 812079.8125 - val_mae: 288.2311\n",
      "Epoch 10/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 617351.0000 - mae: 265.7286 - val_loss: 813139.5000 - val_mae: 287.9084\n",
      "Processing ./db/train_hx...\n",
      "Loaded 905833 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 834844.3125 - mae: 285.9922 - val_loss: 769286.4375 - val_mae: 295.5589\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 803852.9375 - mae: 281.9998 - val_loss: 770518.7500 - val_mae: 297.8431\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 757906.4375 - mae: 277.1962 - val_loss: 771022.3750 - val_mae: 297.1977\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 762247.6250 - mae: 277.4512 - val_loss: 772908.5625 - val_mae: 296.2739\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 709971.8750 - mae: 274.8684 - val_loss: 776256.8750 - val_mae: 297.1846\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 737688.8125 - mae: 276.9111 - val_loss: 777255.0000 - val_mae: 296.1693\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 704355.0625 - mae: 273.4128 - val_loss: 780734.0000 - val_mae: 297.1978\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 708672.5625 - mae: 274.9490 - val_loss: 785037.6875 - val_mae: 299.5205\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 710550.5625 - mae: 274.6833 - val_loss: 785083.9375 - val_mae: 299.1994\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 661611.0625 - mae: 271.3325 - val_loss: 790672.0625 - val_mae: 302.2820\n",
      "Processing ./db/train_hy...\n",
      "Loaded 900695 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 879225.1875 - mae: 294.4424 - val_loss: 771140.8750 - val_mae: 275.6245\n",
      "Epoch 2/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 845280.8125 - mae: 288.1748 - val_loss: 774051.0000 - val_mae: 278.7927\n",
      "Epoch 3/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 761710.0625 - mae: 281.2906 - val_loss: 776626.3125 - val_mae: 278.2767\n",
      "Epoch 4/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 818726.6250 - mae: 284.6785 - val_loss: 784156.1250 - val_mae: 275.8570\n",
      "Epoch 5/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 784667.1250 - mae: 283.4329 - val_loss: 785312.0000 - val_mae: 278.3951\n",
      "Epoch 6/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 761639.4375 - mae: 280.8977 - val_loss: 789580.6875 - val_mae: 277.6846\n",
      "Epoch 7/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 760448.0625 - mae: 283.0107 - val_loss: 790511.6250 - val_mae: 278.5418\n",
      "Epoch 8/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 756636.6250 - mae: 280.9607 - val_loss: 799214.3750 - val_mae: 283.5485\n",
      "Epoch 9/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 736209.7500 - mae: 280.7665 - val_loss: 799432.0625 - val_mae: 280.4852\n",
      "Epoch 10/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 702340.6875 - mae: 278.7758 - val_loss: 799437.1250 - val_mae: 280.9759\n",
      "Processing ./db/train_hz...\n",
      "Loaded 909812 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 747164.1875 - mae: 276.8245 - val_loss: 798939.8750 - val_mae: 275.4201\n",
      "Epoch 2/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 724336.1875 - mae: 271.1677 - val_loss: 797586.2500 - val_mae: 275.1193\n",
      "Epoch 3/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 687806.6875 - mae: 269.7145 - val_loss: 796286.5625 - val_mae: 276.0162\n",
      "Epoch 4/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 687520.4375 - mae: 268.1090 - val_loss: 797260.8125 - val_mae: 277.6403\n",
      "Epoch 5/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 681951.7500 - mae: 269.0180 - val_loss: 798412.9375 - val_mae: 275.3320\n",
      "Epoch 6/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 662017.6250 - mae: 266.5317 - val_loss: 799792.8750 - val_mae: 277.4469\n",
      "Epoch 7/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 648453.5625 - mae: 267.4248 - val_loss: 801877.0625 - val_mae: 278.3523\n",
      "Epoch 8/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 645653.9375 - mae: 266.6746 - val_loss: 804392.0625 - val_mae: 278.8049\n",
      "Epoch 9/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 638714.0000 - mae: 266.5534 - val_loss: 807493.9375 - val_mae: 280.5246\n",
      "Epoch 10/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 635505.4375 - mae: 264.8114 - val_loss: 808888.5625 - val_mae: 280.2018\n",
      "Processing ./db/train_ia...\n",
      "Loaded 900935 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 763394.0625 - mae: 281.7579 - val_loss: 864014.5625 - val_mae: 285.0679\n",
      "Epoch 2/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 716098.1875 - mae: 274.2392 - val_loss: 861209.2500 - val_mae: 283.8301\n",
      "Epoch 3/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 688762.3125 - mae: 272.1013 - val_loss: 863275.9375 - val_mae: 284.8350\n",
      "Epoch 4/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 664790.7500 - mae: 270.8264 - val_loss: 865373.3125 - val_mae: 284.8939\n",
      "Epoch 5/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 662467.9375 - mae: 270.1968 - val_loss: 870096.7500 - val_mae: 286.1569\n",
      "Epoch 6/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 659648.4375 - mae: 270.2470 - val_loss: 871020.8125 - val_mae: 287.6805\n",
      "Epoch 7/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 676882.1250 - mae: 270.9520 - val_loss: 873129.3750 - val_mae: 286.8957\n",
      "Epoch 8/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 634559.6250 - mae: 268.6232 - val_loss: 876167.4375 - val_mae: 292.2655\n",
      "Epoch 9/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 650683.9375 - mae: 269.1361 - val_loss: 878323.0625 - val_mae: 288.9663\n",
      "Epoch 10/10\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 628106.5625 - mae: 268.6424 - val_loss: 880383.8125 - val_mae: 288.8958\n",
      "Processing ./db/train_ib...\n",
      "Loaded 896214 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 856708.0625 - mae: 291.7009 - val_loss: 755398.6875 - val_mae: 279.3768\n",
      "Epoch 2/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 780557.2500 - mae: 283.7425 - val_loss: 756871.8125 - val_mae: 281.2152\n",
      "Epoch 3/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 796117.0000 - mae: 284.9845 - val_loss: 759346.2500 - val_mae: 280.1446\n",
      "Epoch 4/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 739481.7500 - mae: 281.1059 - val_loss: 761153.3750 - val_mae: 281.8159\n",
      "Epoch 5/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 735602.6875 - mae: 281.0268 - val_loss: 764312.2500 - val_mae: 281.8230\n",
      "Epoch 6/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 721227.3750 - mae: 279.8413 - val_loss: 767048.8750 - val_mae: 284.6112\n",
      "Epoch 7/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 719961.2500 - mae: 281.0772 - val_loss: 770461.4375 - val_mae: 289.6273\n",
      "Epoch 8/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 697468.2500 - mae: 278.2881 - val_loss: 771653.8125 - val_mae: 287.9188\n",
      "Epoch 9/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 725655.6250 - mae: 281.3638 - val_loss: 775223.5625 - val_mae: 291.1691\n",
      "Epoch 10/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 703352.3125 - mae: 279.4267 - val_loss: 773422.3750 - val_mae: 284.7005\n",
      "Processing ./db/train_ic...\n",
      "Loaded 909297 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 828169.5625 - mae: 285.1827 - val_loss: 787127.2500 - val_mae: 287.9560\n",
      "Epoch 2/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 739791.8125 - mae: 275.1853 - val_loss: 786789.8125 - val_mae: 290.0751\n",
      "Epoch 3/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 726620.0000 - mae: 274.4412 - val_loss: 788300.3750 - val_mae: 291.6950\n",
      "Epoch 4/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 702793.5625 - mae: 272.1061 - val_loss: 791306.3750 - val_mae: 290.3799\n",
      "Epoch 5/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 701448.1250 - mae: 272.5090 - val_loss: 796434.1875 - val_mae: 293.7203\n",
      "Epoch 6/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 659110.5000 - mae: 270.7666 - val_loss: 796045.1250 - val_mae: 291.6835\n",
      "Epoch 7/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 679918.8125 - mae: 272.2759 - val_loss: 798387.8125 - val_mae: 292.3263\n",
      "Epoch 8/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 671366.9375 - mae: 269.9811 - val_loss: 803754.1250 - val_mae: 298.6954\n",
      "Epoch 9/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 658584.6250 - mae: 270.7968 - val_loss: 803326.7500 - val_mae: 293.5473\n",
      "Epoch 10/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 643015.0000 - mae: 268.9027 - val_loss: 804868.2500 - val_mae: 292.3543\n",
      "Processing ./db/train_id...\n",
      "Loaded 892205 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 866520.8125 - mae: 294.7477 - val_loss: 802914.0625 - val_mae: 288.3697\n",
      "Epoch 2/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 832703.4375 - mae: 289.7578 - val_loss: 803338.2500 - val_mae: 288.6486\n",
      "Epoch 3/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 806879.6875 - mae: 287.0374 - val_loss: 807102.6875 - val_mae: 299.3535\n",
      "Epoch 4/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 762570.9375 - mae: 284.1982 - val_loss: 808712.3125 - val_mae: 293.3179\n",
      "Epoch 5/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 772209.4375 - mae: 285.1867 - val_loss: 809539.8750 - val_mae: 291.6905\n",
      "Epoch 6/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 751133.4375 - mae: 282.3923 - val_loss: 812197.4375 - val_mae: 290.5941\n",
      "Epoch 7/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 763600.0000 - mae: 284.7600 - val_loss: 813139.1250 - val_mae: 290.8920\n",
      "Epoch 8/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 742088.3125 - mae: 283.8884 - val_loss: 816501.9375 - val_mae: 293.2207\n",
      "Epoch 9/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 732036.8125 - mae: 283.4395 - val_loss: 818712.8125 - val_mae: 291.8672\n",
      "Epoch 10/10\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 720881.7500 - mae: 281.7276 - val_loss: 824403.3125 - val_mae: 307.7102\n",
      "Processing ./db/train_ie...\n",
      "Loaded 894294 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 863812.6875 - mae: 295.1931 - val_loss: 742955.0625 - val_mae: 284.5864\n",
      "Epoch 2/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 832636.0000 - mae: 287.7499 - val_loss: 742637.8750 - val_mae: 284.9709\n",
      "Epoch 3/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 809057.6875 - mae: 286.2851 - val_loss: 742595.0000 - val_mae: 285.3341\n",
      "Epoch 4/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 795540.2500 - mae: 284.7935 - val_loss: 743734.2500 - val_mae: 289.0936\n",
      "Epoch 5/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 769536.0000 - mae: 283.6616 - val_loss: 743834.8125 - val_mae: 285.0977\n",
      "Epoch 6/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 737914.0625 - mae: 281.3751 - val_loss: 745510.9375 - val_mae: 286.3264\n",
      "Epoch 7/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 734471.1250 - mae: 280.8331 - val_loss: 748701.6250 - val_mae: 287.9605\n",
      "Epoch 8/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 742163.0000 - mae: 282.1968 - val_loss: 749811.7500 - val_mae: 287.2180\n",
      "Epoch 9/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 735934.0625 - mae: 282.4319 - val_loss: 753476.6875 - val_mae: 291.4582\n",
      "Epoch 10/10\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 714642.7500 - mae: 280.0036 - val_loss: 754289.5625 - val_mae: 288.9965\n",
      "Processing ./db/train_if...\n",
      "Loaded 902370 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 804137.7500 - mae: 282.2672 - val_loss: 781272.6875 - val_mae: 285.5805\n",
      "Epoch 2/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 743136.3125 - mae: 275.5297 - val_loss: 784170.6875 - val_mae: 287.4552\n",
      "Epoch 3/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 718688.8125 - mae: 274.5869 - val_loss: 786360.6250 - val_mae: 290.3531\n",
      "Epoch 4/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 689577.6250 - mae: 274.7285 - val_loss: 788398.8125 - val_mae: 289.9637\n",
      "Epoch 5/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 672371.0625 - mae: 271.1038 - val_loss: 794073.1250 - val_mae: 290.2486\n",
      "Epoch 6/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 675575.2500 - mae: 272.3819 - val_loss: 801677.3750 - val_mae: 293.0197\n",
      "Epoch 7/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 656941.5000 - mae: 271.9816 - val_loss: 801904.3750 - val_mae: 292.2253\n",
      "Epoch 8/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 658954.1250 - mae: 271.3848 - val_loss: 807065.8125 - val_mae: 292.7050\n",
      "Epoch 9/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 640918.9375 - mae: 269.7058 - val_loss: 807039.9375 - val_mae: 293.4206\n",
      "Epoch 10/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 658670.0000 - mae: 272.1594 - val_loss: 813004.9375 - val_mae: 296.6658\n",
      "Processing ./db/train_ig...\n",
      "Loaded 901679 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 934496.9375 - mae: 295.7029 - val_loss: 852567.0625 - val_mae: 298.7726\n",
      "Epoch 2/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 847943.4375 - mae: 286.9072 - val_loss: 855281.3750 - val_mae: 302.5395\n",
      "Epoch 3/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 848782.9375 - mae: 288.1610 - val_loss: 857582.6250 - val_mae: 302.1555\n",
      "Epoch 4/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 805201.3750 - mae: 285.5110 - val_loss: 863197.1875 - val_mae: 304.4963\n",
      "Epoch 5/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 804911.5000 - mae: 285.2260 - val_loss: 866225.3125 - val_mae: 303.0981\n",
      "Epoch 6/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 785882.8750 - mae: 284.3701 - val_loss: 870948.0000 - val_mae: 304.5232\n",
      "Epoch 7/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 787833.8125 - mae: 283.9045 - val_loss: 873101.5000 - val_mae: 305.4604\n",
      "Epoch 8/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 752343.1875 - mae: 281.7503 - val_loss: 876165.2500 - val_mae: 306.4096\n",
      "Epoch 9/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 780151.2500 - mae: 283.0790 - val_loss: 880677.6875 - val_mae: 307.4943\n",
      "Epoch 10/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 740886.2500 - mae: 281.2077 - val_loss: 884213.5000 - val_mae: 306.2057\n",
      "Processing ./db/train_ih...\n",
      "Loaded 897705 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 820565.5625 - mae: 286.2748 - val_loss: 767824.5000 - val_mae: 274.8736\n",
      "Epoch 2/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 777457.8125 - mae: 279.4416 - val_loss: 768249.5625 - val_mae: 274.4618\n",
      "Epoch 3/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 750395.6250 - mae: 276.8572 - val_loss: 769420.0625 - val_mae: 275.3286\n",
      "Epoch 4/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 736278.2500 - mae: 276.8737 - val_loss: 772265.1250 - val_mae: 275.2536\n",
      "Epoch 5/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 710490.9375 - mae: 273.9821 - val_loss: 775864.5000 - val_mae: 274.9976\n",
      "Epoch 6/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 745937.7500 - mae: 276.4071 - val_loss: 780656.5000 - val_mae: 276.1575\n",
      "Epoch 7/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 726350.8125 - mae: 275.4521 - val_loss: 783864.6250 - val_mae: 276.8479\n",
      "Epoch 8/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 685301.7500 - mae: 272.7844 - val_loss: 785513.3125 - val_mae: 276.7867\n",
      "Epoch 9/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 681825.3125 - mae: 272.4649 - val_loss: 785273.6250 - val_mae: 281.7661\n",
      "Epoch 10/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 687839.1875 - mae: 273.4113 - val_loss: 787223.7500 - val_mae: 277.1953\n",
      "Processing ./db/train_ii...\n",
      "Loaded 904927 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 662875.3125 - mae: 269.9301 - val_loss: 588620.1250 - val_mae: 261.4718\n",
      "Epoch 2/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 626801.2500 - mae: 262.6337 - val_loss: 587166.6875 - val_mae: 261.1736\n",
      "Epoch 3/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 616462.0625 - mae: 262.0125 - val_loss: 588575.6875 - val_mae: 260.8476\n",
      "Epoch 4/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 597314.0000 - mae: 260.5173 - val_loss: 590755.0000 - val_mae: 261.8545\n",
      "Epoch 5/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 574877.8750 - mae: 259.0310 - val_loss: 592115.5625 - val_mae: 261.8339\n",
      "Epoch 6/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 568764.1250 - mae: 258.5114 - val_loss: 594224.8750 - val_mae: 261.9154\n",
      "Epoch 7/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 573468.3125 - mae: 257.7336 - val_loss: 596582.9375 - val_mae: 265.1118\n",
      "Epoch 8/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 535629.5625 - mae: 255.8481 - val_loss: 599184.3125 - val_mae: 263.1353\n",
      "Epoch 9/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 546896.7500 - mae: 256.0254 - val_loss: 599934.5625 - val_mae: 263.9853\n",
      "Epoch 10/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 544409.7500 - mae: 255.8398 - val_loss: 602468.0000 - val_mae: 264.4829\n",
      "Processing ./db/train_ij...\n",
      "Loaded 903753 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 740792.0625 - mae: 274.6978 - val_loss: 793210.2500 - val_mae: 282.0532\n",
      "Epoch 2/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 712491.8750 - mae: 270.8264 - val_loss: 796581.6250 - val_mae: 288.6003\n",
      "Epoch 3/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 672894.5625 - mae: 267.9404 - val_loss: 801512.4375 - val_mae: 282.0558\n",
      "Epoch 4/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 681695.4375 - mae: 268.3405 - val_loss: 800526.4375 - val_mae: 285.3336\n",
      "Epoch 5/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 646259.3125 - mae: 265.2915 - val_loss: 800743.6250 - val_mae: 283.0948\n",
      "Epoch 6/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 668650.4375 - mae: 266.6897 - val_loss: 804542.5625 - val_mae: 293.9027\n",
      "Epoch 7/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 632198.6250 - mae: 264.9291 - val_loss: 803078.1250 - val_mae: 285.2313\n",
      "Epoch 8/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 632954.9375 - mae: 265.7328 - val_loss: 807702.8125 - val_mae: 289.3919\n",
      "Epoch 9/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 627025.5000 - mae: 264.8846 - val_loss: 807845.9375 - val_mae: 286.5275\n",
      "Epoch 10/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 633264.6875 - mae: 264.5092 - val_loss: 808968.1875 - val_mae: 288.3221\n",
      "Processing ./db/train_ik...\n",
      "Loaded 899805 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 862599.1250 - mae: 288.8282 - val_loss: 1088540.0000 - val_mae: 315.6996\n",
      "Epoch 2/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 814583.8750 - mae: 283.6865 - val_loss: 1086769.6250 - val_mae: 312.6718\n",
      "Epoch 3/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 776853.4375 - mae: 281.4948 - val_loss: 1091675.5000 - val_mae: 320.1659\n",
      "Epoch 4/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 741212.4375 - mae: 279.4548 - val_loss: 1094812.2500 - val_mae: 318.8574\n",
      "Epoch 5/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 753319.3125 - mae: 280.3860 - val_loss: 1096615.7500 - val_mae: 317.7307\n",
      "Epoch 6/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 742837.5625 - mae: 280.1329 - val_loss: 1097685.2500 - val_mae: 317.0676\n",
      "Epoch 7/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 736274.9375 - mae: 278.6881 - val_loss: 1103673.5000 - val_mae: 317.7793\n",
      "Epoch 8/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 719147.5000 - mae: 278.3483 - val_loss: 1107325.6250 - val_mae: 318.1440\n",
      "Epoch 9/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 718289.1875 - mae: 277.4646 - val_loss: 1107948.7500 - val_mae: 319.8604\n",
      "Epoch 10/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 710296.9375 - mae: 278.0405 - val_loss: 1109525.8750 - val_mae: 319.9165\n",
      "Processing ./db/train_il...\n",
      "Loaded 903658 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 752905.6875 - mae: 277.3559 - val_loss: 702983.5625 - val_mae: 280.3391\n",
      "Epoch 2/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 692741.5000 - mae: 270.2428 - val_loss: 705397.5625 - val_mae: 280.9857\n",
      "Epoch 3/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 689537.3750 - mae: 269.0653 - val_loss: 707709.2500 - val_mae: 281.9314\n",
      "Epoch 4/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 688209.5625 - mae: 268.7741 - val_loss: 711163.2500 - val_mae: 282.8459\n",
      "Epoch 5/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 663072.9375 - mae: 268.9169 - val_loss: 713572.8125 - val_mae: 282.7392\n",
      "Epoch 6/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 655407.3750 - mae: 266.9894 - val_loss: 715410.6250 - val_mae: 281.9239\n",
      "Epoch 7/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 633080.3750 - mae: 266.0700 - val_loss: 716343.9375 - val_mae: 283.8384\n",
      "Epoch 8/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 630454.6875 - mae: 266.1011 - val_loss: 719737.1250 - val_mae: 284.7689\n",
      "Epoch 9/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 627059.8125 - mae: 264.2410 - val_loss: 721888.2500 - val_mae: 285.7531\n",
      "Epoch 10/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 618838.9375 - mae: 265.0424 - val_loss: 722525.4375 - val_mae: 285.2314\n",
      "Processing ./db/train_im...\n",
      "Loaded 905311 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 817532.8125 - mae: 287.0872 - val_loss: 904204.6250 - val_mae: 310.9907\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 786646.0000 - mae: 281.6050 - val_loss: 905208.6250 - val_mae: 315.7281\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 721204.6250 - mae: 276.3017 - val_loss: 906156.8125 - val_mae: 312.0953\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 707480.9375 - mae: 275.9378 - val_loss: 907691.5625 - val_mae: 310.3042\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 755584.9375 - mae: 279.4075 - val_loss: 908231.1875 - val_mae: 310.7586\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 717969.8125 - mae: 274.9467 - val_loss: 911206.5625 - val_mae: 311.6544\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 718882.6875 - mae: 276.0590 - val_loss: 913331.6250 - val_mae: 311.6250\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 710361.8125 - mae: 275.3402 - val_loss: 917308.1875 - val_mae: 313.9307\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 705933.6875 - mae: 274.1413 - val_loss: 918086.5625 - val_mae: 312.7035\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 679147.9375 - mae: 273.1977 - val_loss: 923804.9375 - val_mae: 314.7632\n",
      "Processing ./db/train_in...\n",
      "Loaded 898362 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 989042.9375 - mae: 305.3690 - val_loss: 911300.7500 - val_mae: 314.2613\n",
      "Epoch 2/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 905912.9375 - mae: 297.8792 - val_loss: 917325.7500 - val_mae: 314.9975\n",
      "Epoch 3/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 894813.7500 - mae: 299.1681 - val_loss: 929205.4375 - val_mae: 319.0015\n",
      "Epoch 4/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 901534.1875 - mae: 299.2005 - val_loss: 934627.6875 - val_mae: 315.8867\n",
      "Epoch 5/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 876223.1875 - mae: 297.3131 - val_loss: 944241.3125 - val_mae: 315.7555\n",
      "Epoch 6/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 878739.0000 - mae: 297.0811 - val_loss: 948894.8125 - val_mae: 318.9384\n",
      "Epoch 7/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 861172.0625 - mae: 297.4702 - val_loss: 962063.6250 - val_mae: 318.9058\n",
      "Epoch 8/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 848865.5625 - mae: 294.2804 - val_loss: 968066.3125 - val_mae: 318.8085\n",
      "Epoch 9/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 818138.3125 - mae: 292.4271 - val_loss: 973628.4375 - val_mae: 321.7202\n",
      "Epoch 10/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 828327.4375 - mae: 294.6869 - val_loss: 982795.6250 - val_mae: 322.8252\n",
      "Processing ./db/train_io...\n",
      "Loaded 901936 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 777380.4375 - mae: 285.7979 - val_loss: 790846.8750 - val_mae: 277.0961\n",
      "Epoch 2/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 769110.6250 - mae: 280.2627 - val_loss: 787893.0625 - val_mae: 277.6761\n",
      "Epoch 3/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 713773.4375 - mae: 274.5780 - val_loss: 786798.6875 - val_mae: 278.1161\n",
      "Epoch 4/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 710772.0625 - mae: 274.6584 - val_loss: 790798.3750 - val_mae: 283.3871\n",
      "Epoch 5/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 684346.1875 - mae: 272.5039 - val_loss: 789129.5625 - val_mae: 280.2035\n",
      "Epoch 6/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 685590.5625 - mae: 272.4403 - val_loss: 791583.0625 - val_mae: 279.9540\n",
      "Epoch 7/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 700684.3125 - mae: 273.1600 - val_loss: 791696.8750 - val_mae: 279.2029\n",
      "Epoch 8/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 682713.8125 - mae: 272.2197 - val_loss: 793973.7500 - val_mae: 280.9701\n",
      "Epoch 9/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 659567.5000 - mae: 269.7129 - val_loss: 795987.0625 - val_mae: 282.7738\n",
      "Epoch 10/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 638663.9375 - mae: 269.3167 - val_loss: 797291.1875 - val_mae: 281.5741\n",
      "Processing ./db/train_ip...\n",
      "Loaded 906915 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 906075.4375 - mae: 295.8174 - val_loss: 840309.6250 - val_mae: 305.3857\n",
      "Epoch 2/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 854949.4375 - mae: 290.4727 - val_loss: 835972.5625 - val_mae: 301.6555\n",
      "Epoch 3/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 812467.5000 - mae: 286.8903 - val_loss: 837960.3750 - val_mae: 305.5078\n",
      "Epoch 4/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 791657.8750 - mae: 285.9495 - val_loss: 837015.1875 - val_mae: 304.0607\n",
      "Epoch 5/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 776263.6250 - mae: 284.8762 - val_loss: 838837.8125 - val_mae: 304.6466\n",
      "Epoch 6/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 780061.9375 - mae: 284.2427 - val_loss: 841132.8750 - val_mae: 304.1401\n",
      "Epoch 7/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 754078.5000 - mae: 282.6553 - val_loss: 842502.1250 - val_mae: 305.6246\n",
      "Epoch 8/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 765548.0000 - mae: 284.8369 - val_loss: 844282.0625 - val_mae: 306.2312\n",
      "Epoch 9/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 724592.4375 - mae: 281.0620 - val_loss: 843436.7500 - val_mae: 305.8676\n",
      "Epoch 10/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 709485.4375 - mae: 279.2105 - val_loss: 850366.1875 - val_mae: 309.8363\n",
      "Processing ./db/train_iq...\n",
      "Loaded 907297 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 823845.3125 - mae: 287.0675 - val_loss: 798720.8125 - val_mae: 279.8340\n",
      "Epoch 2/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 761129.6875 - mae: 278.6961 - val_loss: 799888.0000 - val_mae: 278.6640\n",
      "Epoch 3/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 770801.0000 - mae: 277.5565 - val_loss: 798992.3125 - val_mae: 278.9150\n",
      "Epoch 4/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 716917.0000 - mae: 274.5727 - val_loss: 801677.8125 - val_mae: 280.0565\n",
      "Epoch 5/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 750649.3750 - mae: 277.1620 - val_loss: 797725.2500 - val_mae: 279.2086\n",
      "Epoch 6/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 735790.1875 - mae: 275.8993 - val_loss: 803848.8125 - val_mae: 280.8552\n",
      "Epoch 7/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 720637.2500 - mae: 274.6812 - val_loss: 803646.7500 - val_mae: 279.7217\n",
      "Epoch 8/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 691126.2500 - mae: 272.7102 - val_loss: 805535.0000 - val_mae: 285.1298\n",
      "Epoch 9/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 701356.1250 - mae: 273.7217 - val_loss: 804737.3750 - val_mae: 282.7436\n",
      "Epoch 10/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 710620.3125 - mae: 274.1001 - val_loss: 804950.8125 - val_mae: 281.2314\n",
      "Processing ./db/train_ir...\n",
      "Loaded 913010 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 770396.3125 - mae: 275.8284 - val_loss: 657923.5000 - val_mae: 264.5472\n",
      "Epoch 2/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 767674.3750 - mae: 273.6145 - val_loss: 659997.4375 - val_mae: 265.7423\n",
      "Epoch 3/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 722624.5000 - mae: 269.2096 - val_loss: 663976.8750 - val_mae: 267.9189\n",
      "Epoch 4/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 724683.2500 - mae: 270.3691 - val_loss: 668398.0625 - val_mae: 269.1986\n",
      "Epoch 5/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 692644.2500 - mae: 267.6912 - val_loss: 669324.5625 - val_mae: 267.5052\n",
      "Epoch 6/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 695005.5000 - mae: 268.6097 - val_loss: 673250.0625 - val_mae: 268.1757\n",
      "Epoch 7/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 680540.7500 - mae: 266.8971 - val_loss: 674069.5625 - val_mae: 268.9149\n",
      "Epoch 8/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 670808.0625 - mae: 265.7886 - val_loss: 677649.9375 - val_mae: 271.5523\n",
      "Epoch 9/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 663012.8125 - mae: 265.9099 - val_loss: 679298.4375 - val_mae: 269.8795\n",
      "Epoch 10/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 667780.2500 - mae: 266.3163 - val_loss: 681425.1250 - val_mae: 270.3963\n",
      "Processing ./db/train_is...\n",
      "Loaded 911664 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 797099.6875 - mae: 287.0090 - val_loss: 562271.6250 - val_mae: 255.9175\n",
      "Epoch 2/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 762421.1875 - mae: 281.5756 - val_loss: 564507.8125 - val_mae: 256.6831\n",
      "Epoch 3/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 709512.3750 - mae: 277.5910 - val_loss: 567214.3125 - val_mae: 258.3820\n",
      "Epoch 4/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 683076.5625 - mae: 275.5496 - val_loss: 571010.5000 - val_mae: 259.3397\n",
      "Epoch 5/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 716456.0000 - mae: 278.0911 - val_loss: 575506.1250 - val_mae: 259.4481\n",
      "Epoch 6/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 684693.2500 - mae: 274.9627 - val_loss: 578415.4375 - val_mae: 262.1553\n",
      "Epoch 7/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 685565.8125 - mae: 276.1071 - val_loss: 577929.1250 - val_mae: 259.6836\n",
      "Epoch 8/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 644019.1250 - mae: 273.5916 - val_loss: 580310.6250 - val_mae: 262.1089\n",
      "Epoch 9/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 681077.5000 - mae: 275.0286 - val_loss: 583277.9375 - val_mae: 263.0911\n",
      "Epoch 10/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 637711.5625 - mae: 272.1343 - val_loss: 587419.6875 - val_mae: 264.9307\n",
      "Processing ./db/train_it...\n",
      "Loaded 911399 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 865355.5000 - mae: 293.4254 - val_loss: 933856.4375 - val_mae: 298.3456\n",
      "Epoch 2/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 797521.5625 - mae: 284.1222 - val_loss: 937782.5000 - val_mae: 300.1320\n",
      "Epoch 3/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 785782.1875 - mae: 281.4253 - val_loss: 937692.8750 - val_mae: 294.5583\n",
      "Epoch 4/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 787591.2500 - mae: 281.7702 - val_loss: 940053.0625 - val_mae: 297.1155\n",
      "Epoch 5/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 734450.1250 - mae: 278.6801 - val_loss: 946680.2500 - val_mae: 301.4425\n",
      "Epoch 6/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 737062.5625 - mae: 280.2610 - val_loss: 953008.0000 - val_mae: 302.2804\n",
      "Epoch 7/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 718275.5000 - mae: 277.1295 - val_loss: 952274.6250 - val_mae: 299.4974\n",
      "Epoch 8/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 710000.5000 - mae: 276.8104 - val_loss: 958957.1250 - val_mae: 305.6434\n",
      "Epoch 9/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 716375.5000 - mae: 278.7346 - val_loss: 959555.0000 - val_mae: 303.2227\n",
      "Epoch 10/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 704561.8750 - mae: 275.6839 - val_loss: 961986.6250 - val_mae: 311.1078\n",
      "Processing ./db/train_iu...\n",
      "Loaded 907668 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 813455.8125 - mae: 286.0075 - val_loss: 780926.3750 - val_mae: 280.1537\n",
      "Epoch 2/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 769204.3750 - mae: 278.6795 - val_loss: 778039.9375 - val_mae: 275.4154\n",
      "Epoch 3/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 751046.9375 - mae: 278.1111 - val_loss: 785504.0000 - val_mae: 276.3989\n",
      "Epoch 4/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 719553.6250 - mae: 275.4989 - val_loss: 785753.9375 - val_mae: 276.8588\n",
      "Epoch 5/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 690271.6250 - mae: 273.5114 - val_loss: 790787.2500 - val_mae: 282.1408\n",
      "Epoch 6/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 709180.0625 - mae: 275.2718 - val_loss: 789722.8750 - val_mae: 278.5051\n",
      "Epoch 7/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 672845.6875 - mae: 271.0426 - val_loss: 794084.7500 - val_mae: 276.9962\n",
      "Epoch 8/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 683698.8125 - mae: 272.7981 - val_loss: 793274.5625 - val_mae: 277.0009\n",
      "Epoch 9/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 675830.5625 - mae: 272.3954 - val_loss: 796712.1875 - val_mae: 278.1528\n",
      "Epoch 10/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 659060.6875 - mae: 270.2931 - val_loss: 797354.3125 - val_mae: 279.3775\n",
      "Processing ./db/train_iv...\n",
      "Loaded 906178 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 847828.9375 - mae: 286.0383 - val_loss: 559573.8125 - val_mae: 255.1563\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 823451.9375 - mae: 280.4094 - val_loss: 559140.1875 - val_mae: 253.5802\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 796391.0000 - mae: 277.8961 - val_loss: 561551.8750 - val_mae: 254.8156\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 796658.7500 - mae: 277.9975 - val_loss: 562748.5000 - val_mae: 254.9667\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 766762.5000 - mae: 277.2227 - val_loss: 565385.6250 - val_mae: 261.4523\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 759233.0000 - mae: 275.8727 - val_loss: 563538.4375 - val_mae: 256.8796\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 764475.1250 - mae: 275.7461 - val_loss: 565805.9375 - val_mae: 257.6344\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 779477.1875 - mae: 277.1451 - val_loss: 566566.1875 - val_mae: 258.8428\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 747391.3750 - mae: 275.4809 - val_loss: 568322.4375 - val_mae: 256.9557\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 752434.8125 - mae: 274.5213 - val_loss: 569764.7500 - val_mae: 258.0312\n",
      "Processing ./db/train_iw...\n",
      "Loaded 915587 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 758404.6875 - mae: 274.4590 - val_loss: 712929.0000 - val_mae: 266.1668\n",
      "Epoch 2/10\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 703017.7500 - mae: 268.4059 - val_loss: 710560.3750 - val_mae: 267.5850\n",
      "Epoch 3/10\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 695764.1875 - mae: 266.7182 - val_loss: 711995.0625 - val_mae: 267.7206\n",
      "Epoch 4/10\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 684482.3125 - mae: 265.7370 - val_loss: 712493.0000 - val_mae: 267.5593\n",
      "Epoch 5/10\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 670539.6250 - mae: 266.0368 - val_loss: 716264.0000 - val_mae: 268.8318\n",
      "Epoch 6/10\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 680701.4375 - mae: 266.7242 - val_loss: 717785.0000 - val_mae: 269.9626\n",
      "Epoch 7/10\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 644341.0625 - mae: 263.0284 - val_loss: 721694.9375 - val_mae: 270.3839\n",
      "Epoch 8/10\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 651959.6250 - mae: 265.0025 - val_loss: 722088.8750 - val_mae: 268.7468\n",
      "Epoch 9/10\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 638855.6250 - mae: 263.3112 - val_loss: 727075.0000 - val_mae: 272.1237\n",
      "Epoch 10/10\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 622023.5625 - mae: 263.0239 - val_loss: 730299.2500 - val_mae: 270.7307\n",
      "Processing ./db/train_ix...\n",
      "Loaded 905930 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 812730.6875 - mae: 283.6915 - val_loss: 805152.2500 - val_mae: 278.2989\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 753431.3125 - mae: 276.9401 - val_loss: 807996.8750 - val_mae: 278.7752\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 727795.8125 - mae: 274.5313 - val_loss: 809970.3750 - val_mae: 281.1391\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 737894.1875 - mae: 276.0687 - val_loss: 813680.1875 - val_mae: 280.0940\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 725535.1875 - mae: 275.4551 - val_loss: 813454.5625 - val_mae: 281.0667\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 744979.4375 - mae: 276.3457 - val_loss: 817540.6875 - val_mae: 282.2312\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 717662.0000 - mae: 275.9618 - val_loss: 813640.7500 - val_mae: 280.4883\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 708131.3125 - mae: 273.2166 - val_loss: 818668.0000 - val_mae: 282.8354\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 697118.1875 - mae: 274.0268 - val_loss: 821198.0000 - val_mae: 281.5089\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 690183.0000 - mae: 272.9841 - val_loss: 818169.3125 - val_mae: 284.4867\n",
      "Processing ./db/train_iy...\n",
      "Loaded 908877 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 777201.2500 - mae: 279.4256 - val_loss: 727925.9375 - val_mae: 281.7162\n",
      "Epoch 2/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 719051.9375 - mae: 273.0501 - val_loss: 726829.3750 - val_mae: 271.1490\n",
      "Epoch 3/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 723863.1875 - mae: 272.2281 - val_loss: 733686.2500 - val_mae: 281.2031\n",
      "Epoch 4/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 706127.3750 - mae: 272.2137 - val_loss: 732669.1250 - val_mae: 276.3672\n",
      "Epoch 5/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 696447.2500 - mae: 270.8417 - val_loss: 735921.6875 - val_mae: 273.7345\n",
      "Epoch 6/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 687107.0000 - mae: 270.3849 - val_loss: 738190.5000 - val_mae: 274.0796\n",
      "Epoch 7/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 704815.7500 - mae: 271.6409 - val_loss: 738618.0625 - val_mae: 275.8500\n",
      "Epoch 8/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 660715.0625 - mae: 267.8842 - val_loss: 742122.6875 - val_mae: 276.7594\n",
      "Epoch 9/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 695729.7500 - mae: 271.6356 - val_loss: 744869.6875 - val_mae: 276.0102\n",
      "Epoch 10/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 659414.1875 - mae: 268.7974 - val_loss: 747005.5000 - val_mae: 277.0617\n",
      "Processing ./db/train_iz...\n",
      "Loaded 911554 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 719092.1250 - mae: 271.5541 - val_loss: 762357.2500 - val_mae: 276.0007\n",
      "Epoch 2/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 683453.8750 - mae: 264.9490 - val_loss: 762046.9375 - val_mae: 276.7837\n",
      "Epoch 3/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 630171.0000 - mae: 260.5884 - val_loss: 762376.3125 - val_mae: 278.5216\n",
      "Epoch 4/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 635340.8750 - mae: 260.4771 - val_loss: 768696.8125 - val_mae: 281.7171\n",
      "Epoch 5/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 632690.3750 - mae: 259.9497 - val_loss: 770137.0000 - val_mae: 280.0468\n",
      "Epoch 6/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 605784.1250 - mae: 259.2830 - val_loss: 773730.1875 - val_mae: 279.6903\n",
      "Epoch 7/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 599858.7500 - mae: 258.1404 - val_loss: 774673.8125 - val_mae: 278.8186\n",
      "Epoch 8/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 594984.0625 - mae: 257.7108 - val_loss: 778613.1875 - val_mae: 279.2868\n",
      "Epoch 9/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 586176.1250 - mae: 256.7591 - val_loss: 784553.9375 - val_mae: 282.9921\n",
      "Epoch 10/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 586340.8125 - mae: 257.0094 - val_loss: 784334.1250 - val_mae: 282.0186\n",
      "Processing ./db/train_ja...\n",
      "Loaded 906821 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 792009.4375 - mae: 282.7826 - val_loss: 709668.7500 - val_mae: 277.3766\n",
      "Epoch 2/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 773560.0000 - mae: 280.4533 - val_loss: 708355.3125 - val_mae: 277.4006\n",
      "Epoch 3/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 738303.6875 - mae: 276.1537 - val_loss: 708406.3750 - val_mae: 275.1854\n",
      "Epoch 4/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 725506.7500 - mae: 275.5563 - val_loss: 709078.5625 - val_mae: 276.1634\n",
      "Epoch 5/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 722045.5000 - mae: 274.6015 - val_loss: 711356.0625 - val_mae: 276.1667\n",
      "Epoch 6/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 716629.5000 - mae: 274.0715 - val_loss: 713114.1875 - val_mae: 276.0427\n",
      "Epoch 7/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 705496.6250 - mae: 273.6873 - val_loss: 715589.0625 - val_mae: 277.9319\n",
      "Epoch 8/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 697631.1875 - mae: 272.6857 - val_loss: 715497.5625 - val_mae: 276.9524\n",
      "Epoch 9/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 677269.1250 - mae: 270.5091 - val_loss: 719374.0625 - val_mae: 278.5195\n",
      "Epoch 10/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 685960.2500 - mae: 271.9544 - val_loss: 721624.3125 - val_mae: 277.9840\n",
      "Processing ./db/train_jb...\n",
      "Loaded 902284 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 897773.5625 - mae: 294.4340 - val_loss: 880077.3125 - val_mae: 286.9610\n",
      "Epoch 2/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 851497.1875 - mae: 289.4243 - val_loss: 880676.6875 - val_mae: 289.1469\n",
      "Epoch 3/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 840147.8750 - mae: 288.4137 - val_loss: 881779.7500 - val_mae: 289.0437\n",
      "Epoch 4/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 831753.1875 - mae: 287.1947 - val_loss: 886707.3750 - val_mae: 290.6318\n",
      "Epoch 5/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 767545.3750 - mae: 282.8989 - val_loss: 890946.2500 - val_mae: 293.8142\n",
      "Epoch 6/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 796160.3750 - mae: 286.7329 - val_loss: 891659.7500 - val_mae: 291.4518\n",
      "Epoch 7/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 780844.6250 - mae: 284.5012 - val_loss: 894195.1250 - val_mae: 292.1566\n",
      "Epoch 8/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 786370.2500 - mae: 286.0076 - val_loss: 895982.1875 - val_mae: 291.4020\n",
      "Epoch 9/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 761264.0625 - mae: 283.8868 - val_loss: 899412.8125 - val_mae: 294.1027\n",
      "Epoch 10/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 782021.8750 - mae: 283.3217 - val_loss: 903360.1875 - val_mae: 293.2261\n",
      "Processing ./db/train_jc...\n",
      "Loaded 907452 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 776309.1875 - mae: 284.0811 - val_loss: 753883.7500 - val_mae: 265.4887\n",
      "Epoch 2/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 747838.8750 - mae: 277.8119 - val_loss: 750330.6875 - val_mae: 265.2906\n",
      "Epoch 3/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 729742.8750 - mae: 275.8124 - val_loss: 750503.5625 - val_mae: 265.7411\n",
      "Epoch 4/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 707982.5000 - mae: 274.8554 - val_loss: 749707.3750 - val_mae: 267.2199\n",
      "Epoch 5/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 708842.2500 - mae: 275.4073 - val_loss: 749267.4375 - val_mae: 265.7733\n",
      "Epoch 6/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 682643.5000 - mae: 273.3075 - val_loss: 752570.7500 - val_mae: 275.4022\n",
      "Epoch 7/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 682480.1875 - mae: 272.7148 - val_loss: 753045.7500 - val_mae: 267.7137\n",
      "Epoch 8/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 686408.0000 - mae: 272.3946 - val_loss: 756575.4375 - val_mae: 273.2342\n",
      "Epoch 9/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 682322.3750 - mae: 272.8064 - val_loss: 754738.5625 - val_mae: 268.6483\n",
      "Epoch 10/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 640240.5000 - mae: 269.2496 - val_loss: 756743.5625 - val_mae: 267.1732\n",
      "Processing ./db/train_jd...\n",
      "Loaded 902844 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 911926.9375 - mae: 290.7188 - val_loss: 1171548.6250 - val_mae: 322.9246\n",
      "Epoch 2/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 826475.0000 - mae: 282.3051 - val_loss: 1164553.0000 - val_mae: 325.5848\n",
      "Epoch 3/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 832221.7500 - mae: 282.5348 - val_loss: 1170475.2500 - val_mae: 331.9147\n",
      "Epoch 4/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 787997.5625 - mae: 280.5645 - val_loss: 1174442.5000 - val_mae: 333.1168\n",
      "Epoch 5/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 817206.2500 - mae: 281.0527 - val_loss: 1181460.0000 - val_mae: 334.6194\n",
      "Epoch 6/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 758948.7500 - mae: 278.3098 - val_loss: 1193111.1250 - val_mae: 333.7679\n",
      "Epoch 7/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 771059.2500 - mae: 279.3267 - val_loss: 1194699.2500 - val_mae: 336.6467\n",
      "Epoch 8/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 764594.0000 - mae: 278.8344 - val_loss: 1200491.2500 - val_mae: 338.6427\n",
      "Epoch 9/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 753379.4375 - mae: 278.4540 - val_loss: 1202276.3750 - val_mae: 341.2536\n",
      "Epoch 10/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 755987.7500 - mae: 279.0774 - val_loss: 1207401.3750 - val_mae: 338.5629\n",
      "Processing ./db/train_je...\n",
      "Loaded 899720 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 866815.8125 - mae: 293.7529 - val_loss: 768512.6875 - val_mae: 285.2901\n",
      "Epoch 2/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 818335.3125 - mae: 287.6204 - val_loss: 769245.6875 - val_mae: 282.3375\n",
      "Epoch 3/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 816889.4375 - mae: 287.6834 - val_loss: 770463.7500 - val_mae: 284.2708\n",
      "Epoch 4/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 779062.1875 - mae: 284.0289 - val_loss: 772029.0000 - val_mae: 284.9456\n",
      "Epoch 5/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 770793.6250 - mae: 283.4100 - val_loss: 775031.1875 - val_mae: 284.9105\n",
      "Epoch 6/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 794645.5625 - mae: 284.7155 - val_loss: 777082.8125 - val_mae: 286.7393\n",
      "Epoch 7/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 774856.1875 - mae: 282.9318 - val_loss: 777851.1875 - val_mae: 286.1589\n",
      "Epoch 8/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 781159.5000 - mae: 283.4925 - val_loss: 781344.5625 - val_mae: 286.2259\n",
      "Epoch 9/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 761607.1250 - mae: 282.7853 - val_loss: 782644.9375 - val_mae: 287.6553\n",
      "Epoch 10/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 762942.5625 - mae: 283.8083 - val_loss: 783843.8750 - val_mae: 288.0784\n",
      "Processing ./db/train_jf...\n",
      "Loaded 901139 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 939151.1250 - mae: 290.6500 - val_loss: 789063.5625 - val_mae: 282.8851\n",
      "Epoch 2/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 851393.5000 - mae: 283.1281 - val_loss: 786007.3750 - val_mae: 278.5539\n",
      "Epoch 3/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 853972.2500 - mae: 284.7799 - val_loss: 784851.1250 - val_mae: 276.5907\n",
      "Epoch 4/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 816473.5000 - mae: 282.6324 - val_loss: 785086.1875 - val_mae: 277.2261\n",
      "Epoch 5/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 834157.4375 - mae: 284.1974 - val_loss: 788400.6875 - val_mae: 284.8242\n",
      "Epoch 6/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 804211.1875 - mae: 282.7508 - val_loss: 789840.9375 - val_mae: 280.7403\n",
      "Epoch 7/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 797283.6875 - mae: 283.1145 - val_loss: 792407.2500 - val_mae: 287.5237\n",
      "Epoch 8/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 761684.0625 - mae: 279.2651 - val_loss: 799143.3750 - val_mae: 293.8980\n",
      "Epoch 9/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 787920.1250 - mae: 281.3046 - val_loss: 804852.6875 - val_mae: 302.2148\n",
      "Epoch 10/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 781656.1875 - mae: 283.1608 - val_loss: 797914.6250 - val_mae: 285.2820\n",
      "Processing ./db/train_jg...\n",
      "Loaded 902299 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 829139.1875 - mae: 289.8151 - val_loss: 1119252.8750 - val_mae: 328.0150\n",
      "Epoch 2/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 782885.0000 - mae: 283.9637 - val_loss: 1124587.5000 - val_mae: 330.1537\n",
      "Epoch 3/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 784078.0625 - mae: 283.3832 - val_loss: 1130516.3750 - val_mae: 328.1350\n",
      "Epoch 4/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 763482.3125 - mae: 281.1812 - val_loss: 1128492.5000 - val_mae: 323.4430\n",
      "Epoch 5/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 718233.8125 - mae: 277.0959 - val_loss: 1143906.1250 - val_mae: 329.9232\n",
      "Epoch 6/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 706173.5625 - mae: 276.1825 - val_loss: 1148509.7500 - val_mae: 327.1125\n",
      "Epoch 7/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 706707.5000 - mae: 278.2755 - val_loss: 1154757.7500 - val_mae: 327.0906\n",
      "Epoch 8/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 710006.4375 - mae: 276.9255 - val_loss: 1160289.1250 - val_mae: 327.4250\n",
      "Epoch 9/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 685946.6875 - mae: 274.3611 - val_loss: 1170615.5000 - val_mae: 336.3671\n",
      "Epoch 10/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 678826.1250 - mae: 275.3034 - val_loss: 1177397.6250 - val_mae: 332.7784\n",
      "Processing ./db/train_jh...\n",
      "Loaded 903619 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 901527.8125 - mae: 295.9284 - val_loss: 803405.6250 - val_mae: 290.0554\n",
      "Epoch 2/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 838602.8750 - mae: 289.6068 - val_loss: 801335.7500 - val_mae: 291.7271\n",
      "Epoch 3/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 836701.4375 - mae: 288.9623 - val_loss: 801477.5625 - val_mae: 289.7418\n",
      "Epoch 4/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 805814.1875 - mae: 287.2493 - val_loss: 805205.4375 - val_mae: 293.0338\n",
      "Epoch 5/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 785488.2500 - mae: 286.8138 - val_loss: 805757.5625 - val_mae: 293.3847\n",
      "Epoch 6/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 786861.2500 - mae: 285.3822 - val_loss: 808088.4375 - val_mae: 294.8837\n",
      "Epoch 7/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 770404.8125 - mae: 283.5364 - val_loss: 813113.6875 - val_mae: 293.2308\n",
      "Epoch 8/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 754182.8750 - mae: 282.7875 - val_loss: 813344.3125 - val_mae: 293.0042\n",
      "Epoch 9/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 766666.0625 - mae: 283.9240 - val_loss: 813908.5000 - val_mae: 294.5531\n",
      "Epoch 10/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 749485.5000 - mae: 282.8291 - val_loss: 814213.5625 - val_mae: 292.8874\n",
      "Processing ./db/train_ji...\n",
      "Loaded 906123 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 759740.0625 - mae: 277.3688 - val_loss: 693757.4375 - val_mae: 272.5802\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 716976.0000 - mae: 272.1006 - val_loss: 689281.8750 - val_mae: 270.5392\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 706596.7500 - mae: 272.3900 - val_loss: 692347.8125 - val_mae: 270.5807\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 679785.3125 - mae: 270.1508 - val_loss: 694659.0625 - val_mae: 272.5141\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 681346.9375 - mae: 270.0193 - val_loss: 698797.8750 - val_mae: 272.8874\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 676033.0000 - mae: 268.1102 - val_loss: 698163.6250 - val_mae: 273.6794\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 675580.6875 - mae: 268.1865 - val_loss: 701359.8750 - val_mae: 271.6341\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 655317.6875 - mae: 267.7816 - val_loss: 704420.1875 - val_mae: 272.9859\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 659118.6250 - mae: 267.7856 - val_loss: 706199.2500 - val_mae: 273.6485\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 659356.4375 - mae: 266.9922 - val_loss: 707202.0000 - val_mae: 272.9796\n",
      "Processing ./db/train_jj...\n",
      "Loaded 905514 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 868611.8750 - mae: 287.1726 - val_loss: 5753667.0000 - val_mae: 299.2519\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 775935.1875 - mae: 278.3498 - val_loss: 5950265.5000 - val_mae: 297.3469\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 755425.0000 - mae: 276.5940 - val_loss: 6018758.0000 - val_mae: 301.3464\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 740948.0625 - mae: 276.2119 - val_loss: 6064279.5000 - val_mae: 299.6959\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 728801.1250 - mae: 274.7261 - val_loss: 6085659.5000 - val_mae: 300.4978\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 707570.0000 - mae: 273.5237 - val_loss: 6040307.0000 - val_mae: 300.9232\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 716881.0000 - mae: 273.7224 - val_loss: 5973171.5000 - val_mae: 301.1181\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 704356.3750 - mae: 272.9822 - val_loss: 5992939.0000 - val_mae: 302.4952\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 702874.2500 - mae: 272.6156 - val_loss: 5813485.5000 - val_mae: 307.3263\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 709308.1250 - mae: 272.9783 - val_loss: 5820004.0000 - val_mae: 308.8069\n",
      "Processing ./db/train_jk...\n",
      "Loaded 904400 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 933102.9375 - mae: 302.6513 - val_loss: 726174.5000 - val_mae: 267.8278\n",
      "Epoch 2/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 868906.4375 - mae: 293.1851 - val_loss: 725268.2500 - val_mae: 267.3877\n",
      "Epoch 3/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 844939.1875 - mae: 291.0741 - val_loss: 727675.7500 - val_mae: 267.6235\n",
      "Epoch 4/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 844279.0625 - mae: 291.7002 - val_loss: 731637.1875 - val_mae: 269.0701\n",
      "Epoch 5/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 815496.5625 - mae: 289.2070 - val_loss: 734656.1250 - val_mae: 269.3024\n",
      "Epoch 6/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 832442.8750 - mae: 290.3582 - val_loss: 738126.8750 - val_mae: 272.6911\n",
      "Epoch 7/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 825158.9375 - mae: 290.8753 - val_loss: 740967.1875 - val_mae: 271.0041\n",
      "Epoch 8/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 766241.6250 - mae: 286.5961 - val_loss: 743847.5625 - val_mae: 276.3387\n",
      "Epoch 9/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 783594.1875 - mae: 287.3588 - val_loss: 748157.5625 - val_mae: 273.2244\n",
      "Epoch 10/10\n",
      "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 787558.1250 - mae: 287.0508 - val_loss: 751294.1875 - val_mae: 273.1847\n",
      "Processing ./db/train_jl...\n",
      "Loaded 906281 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 907572.6875 - mae: 297.0249 - val_loss: 726752.0625 - val_mae: 276.5852\n",
      "Epoch 2/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 857479.3125 - mae: 289.5407 - val_loss: 726155.5625 - val_mae: 277.4135\n",
      "Epoch 3/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 815821.5000 - mae: 288.2689 - val_loss: 733218.2500 - val_mae: 295.1198\n",
      "Epoch 4/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 819515.5000 - mae: 287.3086 - val_loss: 729675.3125 - val_mae: 279.3811\n",
      "Epoch 5/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 799867.1875 - mae: 286.4440 - val_loss: 730779.8750 - val_mae: 279.5525\n",
      "Epoch 6/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 803898.4375 - mae: 286.9922 - val_loss: 733538.8125 - val_mae: 279.8415\n",
      "Epoch 7/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 774580.8125 - mae: 283.3729 - val_loss: 746499.5000 - val_mae: 303.9627\n",
      "Epoch 8/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 780892.5000 - mae: 285.8176 - val_loss: 740247.2500 - val_mae: 285.0682\n",
      "Epoch 9/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 762814.8125 - mae: 283.3635 - val_loss: 743315.8125 - val_mae: 281.6452\n",
      "Epoch 10/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 734057.0625 - mae: 281.2415 - val_loss: 747229.2500 - val_mae: 283.6034\n",
      "Processing ./db/train_jm...\n",
      "Loaded 906029 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 770417.6875 - mae: 286.4615 - val_loss: 966701.0000 - val_mae: 314.6566\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 758774.1250 - mae: 285.5363 - val_loss: 960001.0625 - val_mae: 304.7186\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 732125.5625 - mae: 280.1682 - val_loss: 959120.8750 - val_mae: 308.7301\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 754364.3125 - mae: 280.4737 - val_loss: 961322.5000 - val_mae: 308.9834\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 717491.6250 - mae: 277.3538 - val_loss: 964129.3750 - val_mae: 311.6145\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 702683.3750 - mae: 277.2757 - val_loss: 963333.9375 - val_mae: 308.0909\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 713719.6250 - mae: 278.5110 - val_loss: 966294.8750 - val_mae: 307.3560\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 687349.8125 - mae: 275.2297 - val_loss: 967196.0625 - val_mae: 307.9018\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 703730.1875 - mae: 275.8832 - val_loss: 969605.6250 - val_mae: 309.8221\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 680684.1875 - mae: 274.5287 - val_loss: 968842.7500 - val_mae: 306.3623\n",
      "Processing ./db/train_jn...\n",
      "Loaded 896185 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 816100.6875 - mae: 289.3768 - val_loss: 853339.2500 - val_mae: 284.5354\n",
      "Epoch 2/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 736050.8125 - mae: 280.3375 - val_loss: 855563.9375 - val_mae: 285.3916\n",
      "Epoch 3/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 739439.9375 - mae: 279.2771 - val_loss: 858528.5000 - val_mae: 292.3065\n",
      "Epoch 4/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 699733.5625 - mae: 276.1111 - val_loss: 859669.4375 - val_mae: 295.4600\n",
      "Epoch 5/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 728184.5625 - mae: 280.1141 - val_loss: 858025.8125 - val_mae: 285.2780\n",
      "Epoch 6/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 694410.8125 - mae: 274.9167 - val_loss: 860166.0000 - val_mae: 287.7156\n",
      "Epoch 7/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 686080.2500 - mae: 274.4533 - val_loss: 860381.5625 - val_mae: 290.6873\n",
      "Epoch 8/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 666063.6875 - mae: 272.8661 - val_loss: 861141.2500 - val_mae: 290.7293\n",
      "Epoch 9/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 649645.8125 - mae: 272.9266 - val_loss: 863489.5625 - val_mae: 290.9198\n",
      "Epoch 10/10\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 667017.4375 - mae: 273.2527 - val_loss: 862914.9375 - val_mae: 288.3189\n",
      "Processing ./db/train_jo...\n",
      "Loaded 899478 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 924327.2500 - mae: 302.4921 - val_loss: 748801.8125 - val_mae: 269.0248\n",
      "Epoch 2/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 887029.2500 - mae: 296.8030 - val_loss: 746438.3750 - val_mae: 272.1411\n",
      "Epoch 3/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 842052.9375 - mae: 294.8581 - val_loss: 747105.3125 - val_mae: 272.6920\n",
      "Epoch 4/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 848976.1250 - mae: 293.4059 - val_loss: 749139.5000 - val_mae: 273.1649\n",
      "Epoch 5/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 800229.4375 - mae: 291.6201 - val_loss: 751497.5000 - val_mae: 273.5791\n",
      "Epoch 6/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 818439.0000 - mae: 293.0099 - val_loss: 749159.8750 - val_mae: 272.7313\n",
      "Epoch 7/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 787100.6250 - mae: 290.6988 - val_loss: 751338.5625 - val_mae: 273.9489\n",
      "Epoch 8/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 776146.1250 - mae: 289.1339 - val_loss: 754382.1250 - val_mae: 273.1595\n",
      "Epoch 9/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 792276.8750 - mae: 289.7653 - val_loss: 754960.8750 - val_mae: 277.8917\n",
      "Epoch 10/10\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 762530.8750 - mae: 288.3608 - val_loss: 756790.9375 - val_mae: 273.5121\n",
      "Processing ./db/train_jp...\n",
      "Loaded 908874 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 775597.6250 - mae: 278.4668 - val_loss: 917590.3750 - val_mae: 297.6405\n",
      "Epoch 2/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 718312.0625 - mae: 271.7838 - val_loss: 923126.2500 - val_mae: 300.3704\n",
      "Epoch 3/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 721880.6250 - mae: 273.8598 - val_loss: 927490.2500 - val_mae: 301.0105\n",
      "Epoch 4/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 739303.1250 - mae: 274.3951 - val_loss: 927401.5625 - val_mae: 299.3266\n",
      "Epoch 5/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 711832.5000 - mae: 271.7264 - val_loss: 927240.5625 - val_mae: 299.0402\n",
      "Epoch 6/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 652572.8125 - mae: 267.3219 - val_loss: 933680.6875 - val_mae: 299.9535\n",
      "Epoch 7/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 682970.1875 - mae: 269.1758 - val_loss: 935462.2500 - val_mae: 298.2775\n",
      "Epoch 8/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 679767.8750 - mae: 269.1228 - val_loss: 944260.6250 - val_mae: 313.5675\n",
      "Epoch 9/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 643184.1875 - mae: 266.9259 - val_loss: 941557.3750 - val_mae: 299.4409\n",
      "Epoch 10/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 636627.4375 - mae: 265.7058 - val_loss: 946803.1875 - val_mae: 305.1380\n",
      "Processing ./db/train_jq...\n",
      "Loaded 905621 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 822416.5000 - mae: 290.2316 - val_loss: 993163.5000 - val_mae: 309.4388\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 741054.9375 - mae: 276.4533 - val_loss: 990284.6250 - val_mae: 307.8748\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 758781.0000 - mae: 275.7761 - val_loss: 993245.6250 - val_mae: 307.1525\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 738384.5000 - mae: 274.5580 - val_loss: 994136.2500 - val_mae: 308.9445\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 675035.6875 - mae: 270.3109 - val_loss: 998209.2500 - val_mae: 308.7046\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 699530.5000 - mae: 272.4071 - val_loss: 998519.8125 - val_mae: 310.2766\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 697794.0625 - mae: 271.9108 - val_loss: 998259.4375 - val_mae: 312.2884\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 675906.5625 - mae: 270.9999 - val_loss: 1002939.0625 - val_mae: 311.6081\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 659258.5000 - mae: 269.0175 - val_loss: 1009722.5000 - val_mae: 313.2339\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 698001.2500 - mae: 272.0079 - val_loss: 1013580.7500 - val_mae: 314.3618\n",
      "Processing ./db/train_jr...\n",
      "Loaded 901171 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 838407.9375 - mae: 291.1812 - val_loss: 808380.6875 - val_mae: 322.7865\n",
      "Epoch 2/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 776286.6875 - mae: 286.8722 - val_loss: 785443.4375 - val_mae: 277.7751\n",
      "Epoch 3/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 747092.2500 - mae: 281.2549 - val_loss: 793279.1875 - val_mae: 287.2402\n",
      "Epoch 4/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 719582.9375 - mae: 280.4777 - val_loss: 786075.0000 - val_mae: 276.8346\n",
      "Epoch 5/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 747253.3125 - mae: 281.2071 - val_loss: 786463.7500 - val_mae: 279.6568\n",
      "Epoch 6/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 732793.6250 - mae: 280.5181 - val_loss: 790268.0625 - val_mae: 278.2300\n",
      "Epoch 7/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 760082.5000 - mae: 281.3601 - val_loss: 790452.8750 - val_mae: 277.7145\n",
      "Epoch 8/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 704328.9375 - mae: 277.6816 - val_loss: 790581.5000 - val_mae: 278.6546\n",
      "Epoch 9/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 675274.3750 - mae: 275.7112 - val_loss: 795611.8750 - val_mae: 278.9365\n",
      "Epoch 10/10\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 704711.5000 - mae: 277.8876 - val_loss: 795744.5000 - val_mae: 280.2652\n",
      "Processing ./db/train_js...\n",
      "Loaded 906885 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 806737.3125 - mae: 291.9031 - val_loss: 705622.3125 - val_mae: 274.6190\n",
      "Epoch 2/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 706912.2500 - mae: 275.9581 - val_loss: 700715.6875 - val_mae: 270.4640\n",
      "Epoch 3/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 706692.7500 - mae: 275.2305 - val_loss: 703024.3750 - val_mae: 272.9233\n",
      "Epoch 4/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 694809.9375 - mae: 273.1994 - val_loss: 703792.3750 - val_mae: 274.4319\n",
      "Epoch 5/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 689108.6250 - mae: 272.6741 - val_loss: 703215.1875 - val_mae: 271.7310\n",
      "Epoch 6/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 675510.2500 - mae: 272.2534 - val_loss: 702362.5000 - val_mae: 271.9389\n",
      "Epoch 7/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 660414.8125 - mae: 271.3183 - val_loss: 707305.1875 - val_mae: 274.3604\n",
      "Epoch 8/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 662576.1875 - mae: 271.7860 - val_loss: 705483.2500 - val_mae: 271.3210\n",
      "Epoch 9/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 648735.1250 - mae: 269.8169 - val_loss: 708977.1250 - val_mae: 274.0575\n",
      "Epoch 10/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 638799.6875 - mae: 268.7682 - val_loss: 708769.1875 - val_mae: 273.1887\n",
      "Processing ./db/train_jt...\n",
      "Loaded 904963 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 1407997.8750 - mae: 292.2282 - val_loss: 878780.5000 - val_mae: 289.8683\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 905557.0625 - mae: 279.6601 - val_loss: 888138.9375 - val_mae: 291.0397\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 817490.7500 - mae: 276.1248 - val_loss: 888504.9375 - val_mae: 293.6206\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 869385.8125 - mae: 279.1709 - val_loss: 895849.5625 - val_mae: 311.3473\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 820873.3125 - mae: 282.1503 - val_loss: 897169.5000 - val_mae: 292.4426\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 733907.3125 - mae: 273.4710 - val_loss: 939655.5000 - val_mae: 386.5565\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 745658.8750 - mae: 284.6487 - val_loss: 938106.0625 - val_mae: 373.3462\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 767095.1250 - mae: 286.9445 - val_loss: 897613.6875 - val_mae: 293.9906\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 715076.2500 - mae: 271.5173 - val_loss: 898585.3750 - val_mae: 294.2915\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 728993.3750 - mae: 273.2875 - val_loss: 902252.8125 - val_mae: 304.8899\n",
      "Processing ./db/train_ju...\n",
      "Loaded 908252 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 775684.2500 - mae: 281.0661 - val_loss: 762153.5000 - val_mae: 274.9156\n",
      "Epoch 2/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 744585.2500 - mae: 275.3833 - val_loss: 759763.2500 - val_mae: 275.7309\n",
      "Epoch 3/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 668795.5625 - mae: 269.1792 - val_loss: 763094.8750 - val_mae: 280.6851\n",
      "Epoch 4/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 672138.5000 - mae: 268.5585 - val_loss: 762578.2500 - val_mae: 275.1980\n",
      "Epoch 5/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 655726.1875 - mae: 268.6695 - val_loss: 762167.9375 - val_mae: 276.0820\n",
      "Epoch 6/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 694540.1875 - mae: 270.5317 - val_loss: 766856.5625 - val_mae: 276.4725\n",
      "Epoch 7/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 658672.1875 - mae: 268.0122 - val_loss: 768263.5000 - val_mae: 280.9750\n",
      "Epoch 8/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 644142.6250 - mae: 265.7880 - val_loss: 770428.8125 - val_mae: 282.3874\n",
      "Epoch 9/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 628911.8125 - mae: 265.7952 - val_loss: 770349.8750 - val_mae: 277.5444\n",
      "Epoch 10/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 642634.1875 - mae: 266.7584 - val_loss: 772898.0625 - val_mae: 278.7424\n",
      "Processing ./db/train_jv...\n",
      "Loaded 909163 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 719247.9375 - mae: 273.3043 - val_loss: 729530.2500 - val_mae: 278.2436\n",
      "Epoch 2/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 682555.5625 - mae: 268.6132 - val_loss: 728879.0625 - val_mae: 275.4145\n",
      "Epoch 3/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 667104.2500 - mae: 267.0197 - val_loss: 728669.9375 - val_mae: 275.3191\n",
      "Epoch 4/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 640071.6875 - mae: 264.2033 - val_loss: 733958.0000 - val_mae: 280.7255\n",
      "Epoch 5/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 635160.3750 - mae: 264.8949 - val_loss: 734689.1875 - val_mae: 278.6090\n",
      "Epoch 6/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 636507.1250 - mae: 264.2042 - val_loss: 741446.1875 - val_mae: 276.7574\n",
      "Epoch 7/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 626316.9375 - mae: 263.9898 - val_loss: 740841.0000 - val_mae: 278.5649\n",
      "Epoch 8/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 631022.4375 - mae: 264.5926 - val_loss: 741992.8125 - val_mae: 278.2743\n",
      "Epoch 9/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 622605.4375 - mae: 263.0902 - val_loss: 744417.3125 - val_mae: 279.6309\n",
      "Epoch 10/10\n",
      "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 603737.0000 - mae: 261.6727 - val_loss: 745752.2500 - val_mae: 279.4530\n",
      "Processing ./db/train_jw...\n",
      "Loaded 903376 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 909360.4375 - mae: 296.7288 - val_loss: 756796.3750 - val_mae: 290.5749\n",
      "Epoch 2/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 856283.6250 - mae: 289.6813 - val_loss: 754717.7500 - val_mae: 289.1813\n",
      "Epoch 3/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 827630.2500 - mae: 285.8814 - val_loss: 759979.1875 - val_mae: 291.3095\n",
      "Epoch 4/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 764295.2500 - mae: 281.3346 - val_loss: 763081.9375 - val_mae: 291.1046\n",
      "Epoch 5/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 794249.8125 - mae: 284.6879 - val_loss: 765440.4375 - val_mae: 293.7005\n",
      "Epoch 6/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 781644.9375 - mae: 283.8234 - val_loss: 769303.7500 - val_mae: 291.9890\n",
      "Epoch 7/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 796886.9375 - mae: 285.0721 - val_loss: 773333.8750 - val_mae: 294.8893\n",
      "Epoch 8/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 792593.0625 - mae: 284.1255 - val_loss: 774281.9375 - val_mae: 294.8197\n",
      "Epoch 9/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 765057.0000 - mae: 283.4860 - val_loss: 775546.1250 - val_mae: 295.0055\n",
      "Epoch 10/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 750220.5625 - mae: 281.0546 - val_loss: 778595.1875 - val_mae: 297.0422\n",
      "Processing ./db/train_jx...\n",
      "Loaded 902859 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 858344.3125 - mae: 298.0640 - val_loss: 773770.0000 - val_mae: 280.6699\n",
      "Epoch 2/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 807829.5625 - mae: 289.5252 - val_loss: 776527.3750 - val_mae: 278.0206\n",
      "Epoch 3/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 788825.7500 - mae: 286.3893 - val_loss: 780168.4375 - val_mae: 287.1266\n",
      "Epoch 4/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 750315.5625 - mae: 283.2975 - val_loss: 779466.5625 - val_mae: 278.5168\n",
      "Epoch 5/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 759540.6875 - mae: 282.9893 - val_loss: 781913.1875 - val_mae: 278.5050\n",
      "Epoch 6/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 760357.6875 - mae: 282.9678 - val_loss: 782975.0625 - val_mae: 277.1725\n",
      "Epoch 7/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 734962.9375 - mae: 280.7962 - val_loss: 785195.7500 - val_mae: 276.6687\n",
      "Epoch 8/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 739723.9375 - mae: 281.2003 - val_loss: 784952.9375 - val_mae: 277.6824\n",
      "Epoch 9/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 717578.6875 - mae: 279.7132 - val_loss: 787768.5000 - val_mae: 277.7643\n",
      "Epoch 10/10\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 722323.2500 - mae: 280.5129 - val_loss: 791396.2500 - val_mae: 277.9734\n",
      "Processing ./db/train_jy...\n",
      "Loaded 913336 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 656817.0625 - mae: 269.7089 - val_loss: 690952.4375 - val_mae: 261.3029\n",
      "Epoch 2/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 641777.6250 - mae: 266.5251 - val_loss: 688405.4375 - val_mae: 264.8415\n",
      "Epoch 3/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 631603.5000 - mae: 264.0184 - val_loss: 692761.5625 - val_mae: 263.2416\n",
      "Epoch 4/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 623107.8125 - mae: 263.0963 - val_loss: 693747.4375 - val_mae: 263.8122\n",
      "Epoch 5/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 600978.6250 - mae: 260.3474 - val_loss: 697667.4375 - val_mae: 260.1660\n",
      "Epoch 6/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 607847.6250 - mae: 260.7996 - val_loss: 700276.5000 - val_mae: 261.2560\n",
      "Epoch 7/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 585425.2500 - mae: 259.4752 - val_loss: 705725.2500 - val_mae: 262.6541\n",
      "Epoch 8/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 583925.9375 - mae: 260.1253 - val_loss: 715863.7500 - val_mae: 266.6614\n",
      "Epoch 9/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 585021.1875 - mae: 259.7613 - val_loss: 714917.2500 - val_mae: 263.9435\n",
      "Epoch 10/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 589834.3125 - mae: 260.4793 - val_loss: 713429.7500 - val_mae: 264.1840\n",
      "Processing ./db/train_jz...\n",
      "Loaded 907700 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 866264.4375 - mae: 305.4030 - val_loss: 884994.1250 - val_mae: 289.5966\n",
      "Epoch 2/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 725207.0625 - mae: 280.6768 - val_loss: 884042.6250 - val_mae: 285.6266\n",
      "Epoch 3/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 724426.8750 - mae: 279.0221 - val_loss: 883130.4375 - val_mae: 285.2605\n",
      "Epoch 4/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 704621.6875 - mae: 276.5040 - val_loss: 884556.5000 - val_mae: 285.4748\n",
      "Epoch 5/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 699907.9375 - mae: 274.9663 - val_loss: 888311.2500 - val_mae: 287.2169\n",
      "Epoch 6/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 676122.5625 - mae: 274.4091 - val_loss: 889146.3125 - val_mae: 286.1281\n",
      "Epoch 7/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 685092.8750 - mae: 274.5137 - val_loss: 892722.9375 - val_mae: 286.0237\n",
      "Epoch 8/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 670865.9375 - mae: 274.0715 - val_loss: 894112.8125 - val_mae: 288.6518\n",
      "Epoch 9/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 686399.8125 - mae: 274.0029 - val_loss: 896598.8125 - val_mae: 286.4920\n",
      "Epoch 10/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 665409.5625 - mae: 274.1225 - val_loss: 903659.8125 - val_mae: 303.6247\n",
      "Processing ./db/train_ka...\n",
      "Loaded 906241 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 887829.6875 - mae: 294.0518 - val_loss: 741912.0000 - val_mae: 279.5565\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 838801.0625 - mae: 288.2540 - val_loss: 737940.6250 - val_mae: 279.6002\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 854836.0625 - mae: 289.1162 - val_loss: 732388.9375 - val_mae: 276.7668\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 804712.8125 - mae: 285.5933 - val_loss: 736099.6875 - val_mae: 278.3372\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 799481.6875 - mae: 284.2708 - val_loss: 737787.5000 - val_mae: 279.6714\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 818991.0625 - mae: 286.2295 - val_loss: 738161.1875 - val_mae: 281.8521\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 777443.0000 - mae: 283.8314 - val_loss: 742430.1875 - val_mae: 282.7537\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 767919.8125 - mae: 283.3308 - val_loss: 746315.3125 - val_mae: 283.6765\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 770433.3750 - mae: 282.5065 - val_loss: 748211.6250 - val_mae: 284.9500\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 764104.9375 - mae: 282.8630 - val_loss: 747228.8125 - val_mae: 284.7115\n",
      "Processing ./db/train_kb...\n",
      "Loaded 907916 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 736711.2500 - mae: 287.2128 - val_loss: 749137.6250 - val_mae: 277.4402\n",
      "Epoch 2/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 697405.3750 - mae: 278.4802 - val_loss: 750716.8750 - val_mae: 278.7924\n",
      "Epoch 3/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 667958.1250 - mae: 274.7483 - val_loss: 750990.1875 - val_mae: 276.9388\n",
      "Epoch 4/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 644159.5625 - mae: 272.9628 - val_loss: 753586.5625 - val_mae: 282.7106\n",
      "Epoch 5/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 644443.9375 - mae: 272.6813 - val_loss: 752846.5625 - val_mae: 277.5366\n",
      "Epoch 6/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 649406.0625 - mae: 272.8416 - val_loss: 759299.5625 - val_mae: 276.4895\n",
      "Epoch 7/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 649819.2500 - mae: 272.4433 - val_loss: 758904.2500 - val_mae: 280.4187\n",
      "Epoch 8/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 615942.6875 - mae: 269.6975 - val_loss: 760202.1250 - val_mae: 278.9515\n",
      "Epoch 9/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 634265.6250 - mae: 271.7525 - val_loss: 765171.6875 - val_mae: 278.1530\n",
      "Epoch 10/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 611766.2500 - mae: 270.7127 - val_loss: 765097.3750 - val_mae: 278.5669\n",
      "Processing ./db/train_kc...\n",
      "Loaded 911451 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 846285.5625 - mae: 288.3847 - val_loss: 822821.3125 - val_mae: 283.1231\n",
      "Epoch 2/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 784448.3125 - mae: 281.4721 - val_loss: 822772.1250 - val_mae: 284.1776\n",
      "Epoch 3/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 748055.3750 - mae: 279.7005 - val_loss: 826054.1875 - val_mae: 286.8591\n",
      "Epoch 4/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 738872.3125 - mae: 278.8640 - val_loss: 828921.8750 - val_mae: 285.5461\n",
      "Epoch 5/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 714482.5000 - mae: 277.9328 - val_loss: 828812.8125 - val_mae: 285.3181\n",
      "Epoch 6/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 745761.4375 - mae: 279.8979 - val_loss: 831751.9375 - val_mae: 285.3537\n",
      "Epoch 7/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 704977.5000 - mae: 276.5575 - val_loss: 832746.1875 - val_mae: 289.3216\n",
      "Epoch 8/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 704184.0000 - mae: 276.1108 - val_loss: 836297.6250 - val_mae: 293.0063\n",
      "Epoch 9/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 684228.1250 - mae: 276.1383 - val_loss: 843229.3750 - val_mae: 301.8489\n",
      "Epoch 10/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 698063.2500 - mae: 276.9026 - val_loss: 841893.1875 - val_mae: 288.2422\n",
      "Processing ./db/train_kd...\n",
      "Loaded 910550 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 782331.8125 - mae: 284.6261 - val_loss: 737057.7500 - val_mae: 271.4411\n",
      "Epoch 2/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 762933.6875 - mae: 280.0833 - val_loss: 733065.8750 - val_mae: 271.4325\n",
      "Epoch 3/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 699019.0000 - mae: 273.9437 - val_loss: 733491.1250 - val_mae: 269.3116\n",
      "Epoch 4/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 719778.6875 - mae: 275.6111 - val_loss: 734906.2500 - val_mae: 271.2833\n",
      "Epoch 5/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 697701.9375 - mae: 274.2062 - val_loss: 739460.6875 - val_mae: 278.2868\n",
      "Epoch 6/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 670540.3750 - mae: 271.6522 - val_loss: 738687.7500 - val_mae: 271.5714\n",
      "Epoch 7/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 681340.8125 - mae: 273.0948 - val_loss: 745787.5000 - val_mae: 274.4929\n",
      "Epoch 8/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 669962.0000 - mae: 271.9704 - val_loss: 745986.3125 - val_mae: 270.7958\n",
      "Epoch 9/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 646407.3750 - mae: 270.1395 - val_loss: 748521.0625 - val_mae: 274.4393\n",
      "Epoch 10/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 659390.1875 - mae: 271.5732 - val_loss: 750401.7500 - val_mae: 272.2505\n",
      "Processing ./db/train_ke...\n",
      "Loaded 911069 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 811089.9375 - mae: 289.8123 - val_loss: 758279.8750 - val_mae: 288.0851\n",
      "Epoch 2/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 742265.6250 - mae: 277.6598 - val_loss: 756233.6875 - val_mae: 288.4197\n",
      "Epoch 3/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 733258.4375 - mae: 275.7131 - val_loss: 756551.5000 - val_mae: 286.2472\n",
      "Epoch 4/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 726728.0000 - mae: 276.3053 - val_loss: 757964.5000 - val_mae: 285.2513\n",
      "Epoch 5/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 711370.5000 - mae: 272.5463 - val_loss: 759073.7500 - val_mae: 290.6292\n",
      "Epoch 6/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 684187.8125 - mae: 270.6221 - val_loss: 756813.5625 - val_mae: 286.4189\n",
      "Epoch 7/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 670554.3125 - mae: 270.4272 - val_loss: 759250.0625 - val_mae: 292.3271\n",
      "Epoch 8/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 697022.6250 - mae: 271.7235 - val_loss: 759412.2500 - val_mae: 287.6766\n",
      "Epoch 9/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 697192.0000 - mae: 271.5458 - val_loss: 763012.5625 - val_mae: 290.2696\n",
      "Epoch 10/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 683664.4375 - mae: 270.4016 - val_loss: 763687.3125 - val_mae: 288.6588\n",
      "Processing ./db/train_kf...\n",
      "Loaded 908437 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 800514.0625 - mae: 280.6882 - val_loss: 731875.2500 - val_mae: 276.0374\n",
      "Epoch 2/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 763465.5000 - mae: 276.6577 - val_loss: 731972.3125 - val_mae: 276.5111\n",
      "Epoch 3/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 777979.0000 - mae: 276.9412 - val_loss: 733169.2500 - val_mae: 275.9652\n",
      "Epoch 4/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 725799.1250 - mae: 274.5110 - val_loss: 737658.6250 - val_mae: 279.6662\n",
      "Epoch 5/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 746233.8750 - mae: 275.4138 - val_loss: 738407.5625 - val_mae: 279.2768\n",
      "Epoch 6/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 723847.5000 - mae: 274.5333 - val_loss: 742556.6250 - val_mae: 280.3023\n",
      "Epoch 7/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 691136.0000 - mae: 272.3924 - val_loss: 742997.5625 - val_mae: 279.8356\n",
      "Epoch 8/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 707386.6875 - mae: 272.6831 - val_loss: 745730.3750 - val_mae: 284.0512\n",
      "Epoch 9/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 681002.9375 - mae: 272.3829 - val_loss: 748025.6875 - val_mae: 281.7217\n",
      "Epoch 10/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 692401.2500 - mae: 272.5513 - val_loss: 750495.0000 - val_mae: 282.0613\n",
      "Processing ./db/train_kg...\n",
      "Loaded 911327 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 862629.6875 - mae: 287.6860 - val_loss: 893214.5000 - val_mae: 296.3799\n",
      "Epoch 2/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 713389.5625 - mae: 272.2505 - val_loss: 894094.3125 - val_mae: 297.3930\n",
      "Epoch 3/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 686399.5000 - mae: 270.2634 - val_loss: 893138.5000 - val_mae: 296.2582\n",
      "Epoch 4/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 677883.7500 - mae: 269.0251 - val_loss: 897733.9375 - val_mae: 297.1186\n",
      "Epoch 5/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 655384.7500 - mae: 267.3187 - val_loss: 897412.1250 - val_mae: 296.4449\n",
      "Epoch 6/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 633579.8750 - mae: 264.6017 - val_loss: 902549.8125 - val_mae: 302.9281\n",
      "Epoch 7/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 651599.2500 - mae: 267.3825 - val_loss: 903037.1875 - val_mae: 300.5246\n",
      "Epoch 8/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 647807.5625 - mae: 266.5208 - val_loss: 905600.9375 - val_mae: 302.5404\n",
      "Epoch 9/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 635284.8125 - mae: 266.4372 - val_loss: 908371.7500 - val_mae: 299.3843\n",
      "Epoch 10/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 623606.3125 - mae: 265.3392 - val_loss: 910483.7500 - val_mae: 300.3230\n",
      "Processing ./db/train_kh...\n",
      "Loaded 908200 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1080599.6250 - mae: 317.1133 - val_loss: 831616.1875 - val_mae: 292.3529\n",
      "Epoch 2/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1009658.7500 - mae: 310.4025 - val_loss: 835185.7500 - val_mae: 293.6287\n",
      "Epoch 3/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 964754.7500 - mae: 307.9187 - val_loss: 837057.6875 - val_mae: 292.8971\n",
      "Epoch 4/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 950625.5000 - mae: 307.5494 - val_loss: 838373.0000 - val_mae: 292.2799\n",
      "Epoch 5/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 948743.3750 - mae: 306.9519 - val_loss: 841538.1250 - val_mae: 294.8258\n",
      "Epoch 6/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 908115.7500 - mae: 303.8375 - val_loss: 843638.0000 - val_mae: 292.8167\n",
      "Epoch 7/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 900891.9375 - mae: 302.2223 - val_loss: 847205.2500 - val_mae: 294.6279\n",
      "Epoch 8/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 885282.3125 - mae: 300.8804 - val_loss: 850843.1875 - val_mae: 297.0150\n",
      "Epoch 9/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 870396.3750 - mae: 300.3988 - val_loss: 850191.7500 - val_mae: 295.2963\n",
      "Epoch 10/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 880354.5625 - mae: 301.4418 - val_loss: 852182.6875 - val_mae: 294.9365\n",
      "Processing ./db/train_ki...\n",
      "Loaded 914443 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 733637.9375 - mae: 282.0573 - val_loss: 844607.5000 - val_mae: 301.3287\n",
      "Epoch 2/10\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 694289.7500 - mae: 273.8011 - val_loss: 840305.8125 - val_mae: 296.9743\n",
      "Epoch 3/10\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 692729.4375 - mae: 272.7276 - val_loss: 840994.6875 - val_mae: 295.2153\n",
      "Epoch 4/10\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 677263.1250 - mae: 269.2845 - val_loss: 841890.3750 - val_mae: 297.3055\n",
      "Epoch 5/10\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 659927.1250 - mae: 268.2488 - val_loss: 843365.5625 - val_mae: 296.3235\n",
      "Epoch 6/10\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 654069.5625 - mae: 268.8509 - val_loss: 846210.3125 - val_mae: 301.1614\n",
      "Epoch 7/10\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 646148.8125 - mae: 267.8938 - val_loss: 847179.6875 - val_mae: 298.4439\n",
      "Epoch 8/10\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 620298.3125 - mae: 265.3890 - val_loss: 846999.1250 - val_mae: 297.5364\n",
      "Epoch 9/10\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 608365.6250 - mae: 264.4461 - val_loss: 852218.5625 - val_mae: 301.5103\n",
      "Epoch 10/10\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 621003.7500 - mae: 266.1245 - val_loss: 852197.9375 - val_mae: 299.1741\n",
      "Processing ./db/train_kj...\n",
      "Loaded 912464 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 849823.0625 - mae: 283.4275 - val_loss: 760847.5000 - val_mae: 278.3348\n",
      "Epoch 2/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 786029.1875 - mae: 277.2363 - val_loss: 759584.1875 - val_mae: 278.6093\n",
      "Epoch 3/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 775667.9375 - mae: 275.9893 - val_loss: 759661.8750 - val_mae: 281.1111\n",
      "Epoch 4/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 755088.3125 - mae: 273.4635 - val_loss: 763012.6875 - val_mae: 284.0543\n",
      "Epoch 5/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 765762.4375 - mae: 274.5662 - val_loss: 765811.3125 - val_mae: 286.1202\n",
      "Epoch 6/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 738295.0625 - mae: 273.3107 - val_loss: 766729.8750 - val_mae: 289.2850\n",
      "Epoch 7/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 709077.9375 - mae: 272.5108 - val_loss: 765670.7500 - val_mae: 282.2071\n",
      "Epoch 8/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 709202.5625 - mae: 271.0598 - val_loss: 768045.1250 - val_mae: 281.6450\n",
      "Epoch 9/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 694784.8125 - mae: 269.5821 - val_loss: 768560.2500 - val_mae: 282.5716\n",
      "Epoch 10/10\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 684486.8125 - mae: 271.6944 - val_loss: 773175.5625 - val_mae: 283.0141\n",
      "Processing ./db/train_kk...\n",
      "Loaded 908362 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 853258.9375 - mae: 298.4777 - val_loss: 930785.5625 - val_mae: 285.1401\n",
      "Epoch 2/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 860580.8750 - mae: 294.7702 - val_loss: 930723.1875 - val_mae: 284.6606\n",
      "Epoch 3/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 801132.0000 - mae: 289.4911 - val_loss: 936437.2500 - val_mae: 285.8672\n",
      "Epoch 4/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 794350.5000 - mae: 288.7885 - val_loss: 937443.3125 - val_mae: 285.7794\n",
      "Epoch 5/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 769568.6875 - mae: 286.9545 - val_loss: 941084.7500 - val_mae: 285.9261\n",
      "Epoch 6/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 761181.5000 - mae: 285.2075 - val_loss: 944149.5625 - val_mae: 285.6140\n",
      "Epoch 7/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 767729.3750 - mae: 286.1180 - val_loss: 949113.3750 - val_mae: 287.3644\n",
      "Epoch 8/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 758852.3125 - mae: 285.1292 - val_loss: 953855.1250 - val_mae: 292.6041\n",
      "Epoch 9/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 741760.5000 - mae: 284.8373 - val_loss: 957216.2500 - val_mae: 290.9289\n",
      "Epoch 10/10\n",
      "\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 729494.7500 - mae: 282.4725 - val_loss: 959253.6875 - val_mae: 287.6293\n",
      "Processing ./db/train_kl...\n",
      "Loaded 912679 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 754249.8750 - mae: 274.6932 - val_loss: 751996.1250 - val_mae: 274.9781\n",
      "Epoch 2/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 715420.9375 - mae: 270.3017 - val_loss: 752728.7500 - val_mae: 279.0816\n",
      "Epoch 3/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 698570.3750 - mae: 268.9057 - val_loss: 757725.6875 - val_mae: 286.2726\n",
      "Epoch 4/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 688461.7500 - mae: 269.3121 - val_loss: 755770.3125 - val_mae: 275.5718\n",
      "Epoch 5/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 689516.8750 - mae: 267.2975 - val_loss: 759416.8125 - val_mae: 277.6416\n",
      "Epoch 6/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 664169.5625 - mae: 266.0818 - val_loss: 761957.4375 - val_mae: 279.5109\n",
      "Epoch 7/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 674512.5625 - mae: 266.9351 - val_loss: 873216.7500 - val_mae: 457.7514\n",
      "Epoch 8/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 649310.0000 - mae: 276.5127 - val_loss: 764178.1250 - val_mae: 278.7976\n",
      "Epoch 9/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 612000.1250 - mae: 261.8849 - val_loss: 770980.7500 - val_mae: 290.6404\n",
      "Epoch 10/10\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 648986.4375 - mae: 266.2034 - val_loss: 768747.9375 - val_mae: 279.1692\n",
      "Processing ./db/train_km...\n",
      "Loaded 910757 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 818589.0000 - mae: 283.1726 - val_loss: 810273.0625 - val_mae: 284.0769\n",
      "Epoch 2/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 779539.5625 - mae: 277.5429 - val_loss: 807781.8750 - val_mae: 282.1223\n",
      "Epoch 3/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 758462.7500 - mae: 276.0807 - val_loss: 806690.7500 - val_mae: 283.1084\n",
      "Epoch 4/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 742463.6875 - mae: 276.0350 - val_loss: 807398.2500 - val_mae: 284.2332\n",
      "Epoch 5/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 720406.1875 - mae: 273.1963 - val_loss: 809074.4375 - val_mae: 285.0190\n",
      "Epoch 6/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 725188.1250 - mae: 274.1338 - val_loss: 812123.8750 - val_mae: 285.5309\n",
      "Epoch 7/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 714465.6875 - mae: 273.8637 - val_loss: 814574.5625 - val_mae: 286.7351\n",
      "Epoch 8/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 695941.8750 - mae: 271.9659 - val_loss: 814356.8125 - val_mae: 287.1678\n",
      "Epoch 9/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 694077.2500 - mae: 272.0606 - val_loss: 817439.9375 - val_mae: 287.1313\n",
      "Epoch 10/10\n",
      "\u001b[1m712/712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 690496.7500 - mae: 272.2226 - val_loss: 818796.9375 - val_mae: 287.5443\n",
      "Processing ./db/train_kn...\n",
      "Loaded 907480 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 779066.8125 - mae: 284.9482 - val_loss: 993022.6250 - val_mae: 295.2582\n",
      "Epoch 2/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 745737.8750 - mae: 277.4040 - val_loss: 989850.7500 - val_mae: 298.4911\n",
      "Epoch 3/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 747416.0000 - mae: 278.4059 - val_loss: 991065.0000 - val_mae: 295.6601\n",
      "Epoch 4/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 714679.3750 - mae: 277.0534 - val_loss: 990943.6875 - val_mae: 296.8485\n",
      "Epoch 5/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 698414.0000 - mae: 274.2384 - val_loss: 990896.4375 - val_mae: 299.3029\n",
      "Epoch 6/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 664542.3750 - mae: 272.3978 - val_loss: 995798.0625 - val_mae: 296.1710\n",
      "Epoch 7/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 677752.4375 - mae: 273.1009 - val_loss: 991699.8750 - val_mae: 301.0321\n",
      "Epoch 8/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 662954.1875 - mae: 271.2393 - val_loss: 992582.1250 - val_mae: 297.4828\n",
      "Epoch 9/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 670740.3750 - mae: 271.4191 - val_loss: 996536.5625 - val_mae: 298.5105\n",
      "Epoch 10/10\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 652289.0000 - mae: 270.1317 - val_loss: 998030.3750 - val_mae: 299.0505\n",
      "Processing ./db/train_ko...\n",
      "Loaded 335470 samples\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 867020.5625 - mae: 289.7943 - val_loss: 631528.4375 - val_mae: 275.3354\n",
      "Epoch 2/10\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 844046.7500 - mae: 285.7479 - val_loss: 627338.4375 - val_mae: 272.5376\n",
      "Epoch 3/10\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 816503.8125 - mae: 280.8232 - val_loss: 627269.0000 - val_mae: 274.5452\n",
      "Epoch 4/10\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 795093.1250 - mae: 281.3406 - val_loss: 628628.5625 - val_mae: 278.8586\n",
      "Epoch 5/10\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 762621.6875 - mae: 280.3788 - val_loss: 628209.6250 - val_mae: 276.4388\n",
      "Epoch 6/10\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 736003.6250 - mae: 277.3165 - val_loss: 629467.2500 - val_mae: 278.2027\n",
      "Epoch 7/10\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 716855.0625 - mae: 276.8386 - val_loss: 632452.2500 - val_mae: 283.1869\n",
      "Epoch 8/10\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 687729.6875 - mae: 273.6002 - val_loss: 633135.5000 - val_mae: 280.8096\n",
      "Epoch 9/10\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 696353.0000 - mae: 274.6267 - val_loss: 632847.1875 - val_mae: 278.8773\n",
      "Epoch 10/10\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 691913.1250 - mae: 273.0532 - val_loss: 634884.1875 - val_mae: 281.5604\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(781,)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')  # Regression output\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "if os.path.exists(\"chess_nn_model.json\"):\n",
    "    with open(\"chess_nn_model.json\", \"r\") as f:\n",
    "        weights_list = json.load(f)\n",
    "    weights = [np.array(w) for w in weights_list]\n",
    "    model.set_weights(weights)\n",
    "    print(\"Loaded model weights from chess_nn_model.json\")\n",
    "else:\n",
    "    for i in string.ascii_lowercase:\n",
    "        flag = True\n",
    "        for j in string.ascii_lowercase:\n",
    "            filename = f\"./db/train_{i}{j}\"\n",
    "            if not os.path.exists(filename):\n",
    "                flag = False\n",
    "                break\n",
    "\n",
    "            print(f\"Processing {filename}...\")\n",
    "\n",
    "            X, y = [], []\n",
    "            with open(filename) as f:\n",
    "                for line in f:\n",
    "                    obj = json.loads(line)\n",
    "                    fen = obj['fen']\n",
    "                    cp = obj['evals'][0]['pvs'][0].get('cp')\n",
    "                    if cp is None:  # skip mates for now\n",
    "                        continue\n",
    "                    X.append(encode_fen(fen))\n",
    "                    y.append(cp)\n",
    "\n",
    "            print(f\"Loaded {len(X)} samples\")\n",
    "\n",
    "            X = np.array(X)\n",
    "            y = np.array(y)\n",
    "            print(\"Starting training...\")\n",
    "            model.fit(X, y, batch_size=1024, epochs=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "        if not flag:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92067122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">650,117</span> (2.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m650,117\u001b[0m (2.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,705</span> (846.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m216,705\u001b[0m (846.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">433,412</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m433,412\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Predicted evaluation for example position: -117.77\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "example_fen = \"rb3rk1/1p3ppp/pn2p3/1Q6/8/P1NP4/1Pq2PPP/R1B2RK1 w - - 0 17\"\n",
    "example_input = encode_fen(example_fen).reshape(1, -1)\n",
    "pred = model.predict(example_input)\n",
    "print(f\"Predicted evaluation for example position: {pred[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91767e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights to file\n",
    "weights = model.get_weights()\n",
    "weights_list = [w.tolist() for w in weights]\n",
    "with open(\"chess_nn_model.json\", \"w\") as f:\n",
    "    json.dump(weights_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
